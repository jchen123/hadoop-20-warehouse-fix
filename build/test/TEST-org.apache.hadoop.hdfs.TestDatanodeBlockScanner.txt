Testsuite: org.apache.hadoop.hdfs.TestDatanodeBlockScanner
Tests run: 4, Failures: 0, Errors: 0, Time elapsed: 470.719 sec
------------- Standard Output ---------------
2011-08-09 19:02:58,544 WARN  conf.Configuration (Configuration.java:<clinit>(191)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2011-08-09 19:02:58,890 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:02:58,893 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:02:58,893 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:02:58,894 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:02:58,927 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:02:58,927 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:02:58,927 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:02:59,071 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:02:59,147 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:02:59,150 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:02:59,181 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:02:59,184 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:02:59,184 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:02:59,195 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:02:59,217 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 19:02:59,289 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:02:59,289 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:02:59,290 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:02:59,290 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:02:59,290 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:02:59,363 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:02:59,364 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:02:59,364 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:02:59,365 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:02:59,390 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:02:59,391 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:02:59,400 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:02:59,407 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:02:59,408 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:02:59,409 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:02:59,411 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:02:59,412 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:02:59,413 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:02:59,414 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:02:59,414 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 52 msecs
2011-08-09 19:02:59,416 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:02:59,425 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:02:59,426 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:02:59,426 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:02:59,427 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:02:59,427 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:02:59,453 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:02:59,458 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=57736
2011-08-09 19:02:59,462 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:57736
2011-08-09 19:02:59,463 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:02:59,463 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57736: starting
2011-08-09 19:02:59,464 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57736: starting
2011-08-09 19:02:59,465 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57736: starting
2011-08-09 19:02:59,466 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57736: starting
2011-08-09 19:02:59,466 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 57736: starting
2011-08-09 19:02:59,475 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 57736: starting
2011-08-09 19:02:59,476 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 57736: starting
2011-08-09 19:02:59,476 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 57736: starting
2011-08-09 19:02:59,477 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 57736: starting
2011-08-09 19:02:59,477 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 57736: starting
2011-08-09 19:02:59,491 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 57736: starting
2011-08-09 19:02:59,579 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:02:59,581 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:02:59,581 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:02:59,581 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:02:59,588 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:02:59,691 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 19:02:59,771 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:02:59,830 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:02:59,831 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57163 webServer.getConnectors()[0].getLocalPort() returned 57163
2011-08-09 19:02:59,831 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57163
2011-08-09 19:02:59,832 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:03:00,341 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57163
2011-08-09 19:03:00,341 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:57163
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:03:00,420 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:03:00,420 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:03:00,438 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:03:00,439 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:03:00,566 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:03:00,568 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48836
2011-08-09 19:03:00,571 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:03:00,576 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:03:00,579 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:03:00,586 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 51105 webServer.getConnectors()[0].getLocalPort() returned 51105
2011-08-09 19:03:00,587 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 51105
2011-08-09 19:03:00,587 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:03:00,857 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:51105
2011-08-09 19:03:00,859 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:03:00,867 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:03:00,870 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=47698
2011-08-09 19:03:00,872 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:03:00,872 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47698: starting
2011-08-09 19:03:00,873 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47698: starting
2011-08-09 19:03:00,874 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47698: starting
2011-08-09 19:03:00,874 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48836, storageID=, infoPort=51105, ipcPort=47698)
2011-08-09 19:03:00,874 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47698: starting
2011-08-09 19:09:12,160 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48836 storage DS-858804506-10.0.62.238-48836-1312909752112
2011-08-09 19:09:12,164 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48836
2011-08-09 19:09:12,172 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-858804506-10.0.62.238-48836-1312909752112 is assigned to data-node 127.0.0.1:48836
2011-08-09 19:09:12,173 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48836, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=51105, ipcPort=47698)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:12,173 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:09:12,181 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:12,183 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48836 0 blocks shortCircuit first report.
2011-08-09 19:09:12,185 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:09:12,185 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:12,186 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:12,213 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:09:12,222 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/testBlockVerification	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:09:12,242 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/testBlockVerification/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:09:12,251 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/testBlockVerification/file1. blk_-4452961083937750378_1001
2011-08-09 19:09:12,368 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4452961083937750378_1001 src: /127.0.0.1:49160 dest: /127.0.0.1:48836
2011-08-09 19:09:12,389 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48836 is added to blk_-4452961083937750378_1001 size 10
2011-08-09 19:09:12,398 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:49160, dest: /127.0.0.1:48836, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_-1318945089, offset: 0, srvID: DS-858804506-10.0.62.238-48836-1312909752112, blockid: blk_-4452961083937750378_1001, duration: 2483943
2011-08-09 19:09:12,403 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4452961083937750378_1001 terminating
2011-08-09 19:09:12,404 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/testBlockVerification/file1 is closed by DFSClient_-1318945089
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:09:12,414 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:12,415 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47698
2011-08-09 19:09:12,416 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47698: exiting
2011-08-09 19:09:12,416 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47698
2011-08-09 19:09:12,417 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47698: exiting
2011-08-09 19:09:12,417 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47698: exiting
2011-08-09 19:09:12,418 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48836, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=51105, ipcPort=47698):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:12,417 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:12,418 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:09:12,419 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:12,420 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48836, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=51105, ipcPort=47698):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:12,420 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47698
2011-08-09 19:09:12,420 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:12,421 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:12,421 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:12,422 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:12,433 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:12,445 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:09:12,445 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:09:12,447 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:09:12,447 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57736
2011-08-09 19:09:12,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57736: exiting
2011-08-09 19:09:12,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57736: exiting
2011-08-09 19:09:12,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57736: exiting
2011-08-09 19:09:12,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 57736: exiting
2011-08-09 19:09:12,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 57736: exiting
2011-08-09 19:09:12,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 57736: exiting
2011-08-09 19:09:12,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 57736: exiting
2011-08-09 19:09:12,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 57736: exiting
2011-08-09 19:09:12,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 57736: exiting
2011-08-09 19:09:12,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 57736: exiting
2011-08-09 19:09:12,450 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57736
2011-08-09 19:09:12,452 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:12,453 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:09:12,456 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:12,457 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:12,457 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:12,457 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:12,457 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:12,539 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:09:12,540 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:12,540 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:12,541 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:12,545 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:12,546 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:09:12,547 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:12,552 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:09:12,552 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:09:12,553 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:09:12,558 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 415 edits # 5 loaded in 0 seconds.
2011-08-09 19:09:12,559 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,603 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,608 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,613 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,613 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 363 saved in 0 seconds.
2011-08-09 19:09:12,622 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,633 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 363 saved in 0 seconds.
2011-08-09 19:09:12,633 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,637 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,638 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:12,653 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:09:12,653 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 114 msecs
2011-08-09 19:09:12,653 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:09:12,657 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 1
2011-08-09 19:09:12,658 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:09:12,658 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:09:12,658 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:09:12,666 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 1.Safe mode will be turned off automatically.
2011-08-09 19:09:12,666 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:09:12,709 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:09:12,717 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:12,720 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=41375
2011-08-09 19:09:12,720 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:41375
2011-08-09 19:09:12,721 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:12,744 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41375: starting
2011-08-09 19:09:12,745 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41375: starting
2011-08-09 19:09:12,745 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41375: starting
2011-08-09 19:09:12,745 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 41375: starting
2011-08-09 19:09:12,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 41375: starting
2011-08-09 19:09:12,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 41375: starting
2011-08-09 19:09:12,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 41375: starting
2011-08-09 19:09:12,747 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 41375: starting
2011-08-09 19:09:12,747 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 41375: starting
2011-08-09 19:09:12,748 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41375: starting
2011-08-09 19:09:12,773 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 41375: starting
2011-08-09 19:09:12,791 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:09:12,792 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:12,794 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:12,794 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 54559 webServer.getConnectors()[0].getLocalPort() returned 54559
2011-08-09 19:09:12,794 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 54559
2011-08-09 19:09:12,794 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:12,970 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:54559
2011-08-09 19:09:12,970 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:54559
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:09:13,182 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:13,187 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40145
2011-08-09 19:09:13,188 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:13,195 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:13,197 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:13,198 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 37277 webServer.getConnectors()[0].getLocalPort() returned 37277
2011-08-09 19:09:13,199 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 37277
2011-08-09 19:09:13,200 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:13,401 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:37277
2011-08-09 19:09:13,403 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:13,408 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:13,410 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=59760
2011-08-09 19:09:13,412 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:13,412 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 59760: starting
2011-08-09 19:09:13,454 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 59760: starting
2011-08-09 19:09:13,455 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 59760: starting
2011-08-09 19:09:13,456 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 59760: starting
2011-08-09 19:09:13,456 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40145, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=37277, ipcPort=59760)
2011-08-09 19:09:13,459 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40145 storage DS-858804506-10.0.62.238-48836-1312909752112
2011-08-09 19:09:13,460 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40145
2011-08-09 19:09:13,461 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40145, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=37277, ipcPort=59760)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:13,462 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:09:13,468 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:13,474 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40145 1 blocks shortCircuit first report.
2011-08-09 19:09:13,475 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:09:13,476 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:09:13,476 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 1 datanodes
2011-08-09 19:09:13,477 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:09:13,478 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 11 msecs
2011-08-09 19:09:13,478 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:13,479 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:13,484 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_-4452961083937750378_1001
2011-08-09 19:09:13,510 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:13,518 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:40145, dest: /127.0.0.1:58645, bytes: 14, op: HDFS_READ, cliID: DFSClient_1027787236, offset: 0, srvID: DS-858804506-10.0.62.238-48836-1312909752112, blockid: blk_-4452961083937750378_1001, duration: 1452576
2011-08-09 19:09:13,677 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/testBlockVerification	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:09:13,681 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/testBlockVerification/file2	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:09:13,686 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/testBlockVerification/file2. blk_-1009689306048645054_1002
2011-08-09 19:09:13,688 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1009689306048645054_1002 src: /127.0.0.1:58647 dest: /127.0.0.1:40145
2011-08-09 19:09:13,691 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:58647, dest: /127.0.0.1:40145, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_1027787236, offset: 0, srvID: DS-858804506-10.0.62.238-48836-1312909752112, blockid: blk_-1009689306048645054_1002, duration: 812794
2011-08-09 19:09:13,691 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1009689306048645054_1002 terminating
2011-08-09 19:09:13,727 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:40145 is added to blk_-1009689306048645054_1002 size 10
2011-08-09 19:09:13,729 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/testBlockVerification/file2 is closed by DFSClient_1027787236
2011-08-09 19:09:13,733 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file2	dst=null	perm=null
2011-08-09 19:09:13,736 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:40145, dest: /127.0.0.1:58648, bytes: 14, op: HDFS_READ, cliID: DFSClient_1027787236, offset: 0, srvID: DS-858804506-10.0.62.238-48836-1312909752112, blockid: blk_-1009689306048645054_1002, duration: 402764
2011-08-09 19:09:13,737 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file2	dst=null	perm=null
2011-08-09 19:09:13,740 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:40145, dest: /127.0.0.1:58649, bytes: 14, op: HDFS_READ, cliID: DFSClient_1027787236, offset: 0, srvID: DS-858804506-10.0.62.238-48836-1312909752112, blockid: blk_-1009689306048645054_1002, duration: 275869
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:09:13,781 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:13,882 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59760
2011-08-09 19:09:13,882 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 59760: exiting
2011-08-09 19:09:13,882 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 59760: exiting
2011-08-09 19:09:13,883 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 59760
2011-08-09 19:09:13,883 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 59760: exiting
2011-08-09 19:09:13,885 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:09:13,885 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:13,893 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40145, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=37277, ipcPort=59760):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:14,487 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:14,892 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:14,892 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40145, storageID=DS-858804506-10.0.62.238-48836-1312909752112, infoPort=37277, ipcPort=59760):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:14,893 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59760
2011-08-09 19:09:14,893 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:14,894 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:14,894 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:14,895 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:14,934 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:15,036 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:09:15,037 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:09:15,038 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:12  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:09:15,041 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41375
2011-08-09 19:09:15,041 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41375: exiting
2011-08-09 19:09:15,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41375: exiting
2011-08-09 19:09:15,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41375: exiting
2011-08-09 19:09:15,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 41375: exiting
2011-08-09 19:09:15,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 41375: exiting
2011-08-09 19:09:15,043 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 41375: exiting
2011-08-09 19:09:15,043 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 41375: exiting
2011-08-09 19:09:15,043 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 41375: exiting
2011-08-09 19:09:15,043 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41375
2011-08-09 19:09:15,044 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 41375: exiting
2011-08-09 19:09:15,044 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 41375: exiting
2011-08-09 19:09:15,045 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:15,111 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:15,111 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:15,111 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:15,112 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:15,152 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:15,152 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:15,152 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:15,153 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:15,178 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:15,178 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:15,190 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:09:15,193 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:15,193 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:15,227 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:09:15,228 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:09:15,242 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:15,242 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:15,242 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:15,243 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:15,243 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:15,247 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:09:15,248 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:15,248 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:15,248 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:15,391 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:15,391 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:09:15,392 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:15,401 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:09:15,402 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:09:15,402 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:09:15,403 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:09:15,403 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:15,404 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:15,405 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:09:15,405 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 158 msecs
2011-08-09 19:09:15,405 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:09:15,409 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:09:15,410 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:09:15,410 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:09:15,410 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:09:15,410 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:09:15,420 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:15,425 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=60625
2011-08-09 19:09:15,426 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:60625
2011-08-09 19:09:15,426 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:15,427 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60625: starting
2011-08-09 19:09:15,428 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60625: starting
2011-08-09 19:09:15,428 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60625: starting
2011-08-09 19:09:15,428 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60625: starting
2011-08-09 19:09:15,429 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 60625: starting
2011-08-09 19:09:15,429 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 60625: starting
2011-08-09 19:09:15,429 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 60625: starting
2011-08-09 19:09:15,429 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 60625: starting
2011-08-09 19:09:15,430 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 60625: starting
2011-08-09 19:09:15,438 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 60625: starting
2011-08-09 19:09:15,438 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 60625: starting
2011-08-09 19:09:15,471 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:09:15,472 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:09:15,472 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:09:15,472 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:09:15,473 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:09:15,475 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:15,476 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:15,476 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57731 webServer.getConnectors()[0].getLocalPort() returned 57731
2011-08-09 19:09:15,476 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57731
2011-08-09 19:09:15,477 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:15,694 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57731
2011-08-09 19:09:15,694 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:57731
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:09:15,745 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:09:15,745 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:15,762 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:09:15,762 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:15,933 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:15,935 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 58348
2011-08-09 19:09:15,935 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:15,938 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:15,939 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:15,939 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39187 webServer.getConnectors()[0].getLocalPort() returned 39187
2011-08-09 19:09:15,939 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39187
2011-08-09 19:09:15,940 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:16,076 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39187
2011-08-09 19:09:16,078 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:16,086 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:16,113 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=50878
2011-08-09 19:09:16,133 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:16,135 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50878: starting
2011-08-09 19:09:16,137 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50878: starting
2011-08-09 19:09:16,137 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50878: starting
2011-08-09 19:09:16,138 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:58348, storageID=, infoPort=39187, ipcPort=50878)
2011-08-09 19:09:16,139 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50878: starting
2011-08-09 19:09:16,156 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:58348 storage DS-175622314-10.0.62.238-58348-1312909756145
2011-08-09 19:09:16,156 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:58348
2011-08-09 19:09:16,169 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-175622314-10.0.62.238-58348-1312909756145 is assigned to data-node 127.0.0.1:58348
2011-08-09 19:09:16,169 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:58348, storageID=DS-175622314-10.0.62.238-58348-1312909756145, infoPort=39187, ipcPort=50878)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:09:16,171 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 1000msec Initial delay: 0msec
2011-08-09 19:09:16,225 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,228 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:58348 0 blocks shortCircuit first report.
2011-08-09 19:09:16,232 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 8 msecs
2011-08-09 19:09:16,232 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:16,234 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:09:16,234 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:16,235 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:09:16,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:16,360 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:16,362 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38277
2011-08-09 19:09:16,362 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:16,365 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:16,365 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:16,366 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35454 webServer.getConnectors()[0].getLocalPort() returned 35454
2011-08-09 19:09:16,366 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35454
2011-08-09 19:09:16,366 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:16,465 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35454
2011-08-09 19:09:16,467 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:16,471 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:16,473 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36192
2011-08-09 19:09:16,474 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:16,476 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36192: starting
2011-08-09 19:09:16,517 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36192: starting
2011-08-09 19:09:16,518 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36192: starting
2011-08-09 19:09:16,519 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36192: starting
2011-08-09 19:09:16,519 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38277, storageID=, infoPort=35454, ipcPort=36192)
2011-08-09 19:09:16,525 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38277 storage DS-1820013218-10.0.62.238-38277-1312909756522
2011-08-09 19:09:16,526 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38277
2011-08-09 19:09:16,533 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1820013218-10.0.62.238-38277-1312909756522 is assigned to data-node 127.0.0.1:38277
2011-08-09 19:09:16,534 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38277, storageID=DS-1820013218-10.0.62.238-38277-1312909756522, infoPort=35454, ipcPort=36192)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:09:16,535 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 1000msec Initial delay: 0msec
2011-08-09 19:09:16,581 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,583 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38277 0 blocks shortCircuit first report.
2011-08-09 19:09:16,584 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:09:16,585 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:16,586 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,586 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:09:16,587 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:16,603 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:09:16,603 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:16,734 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:16,735 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 50867
2011-08-09 19:09:16,746 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:16,757 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:16,757 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:16,758 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44231 webServer.getConnectors()[0].getLocalPort() returned 44231
2011-08-09 19:09:16,758 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44231
2011-08-09 19:09:16,758 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:16,827 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44231
2011-08-09 19:09:16,828 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:16,832 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:16,835 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=51546
2011-08-09 19:09:16,836 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:16,836 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51546: starting
2011-08-09 19:09:16,879 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51546: starting
2011-08-09 19:09:16,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51546: starting
2011-08-09 19:09:16,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51546: starting
2011-08-09 19:09:16,880 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:50867, storageID=, infoPort=44231, ipcPort=51546)
2011-08-09 19:09:16,885 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:50867 storage DS-863774097-10.0.62.238-50867-1312909756883
2011-08-09 19:09:16,886 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:50867
2011-08-09 19:09:16,892 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-863774097-10.0.62.238-50867-1312909756883 is assigned to data-node 127.0.0.1:50867
2011-08-09 19:09:16,893 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:50867, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=44231, ipcPort=51546)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:16,894 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 1000msec Initial delay: 0msec
2011-08-09 19:09:16,898 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,899 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:50867 0 blocks shortCircuit first report.
2011-08-09 19:09:16,901 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:09:16,902 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:16,906 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:16,924 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/testBlockVerification	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:09:16,930 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/testBlockVerification/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:09:16,934 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/testBlockVerification/file1. blk_443865646643972643_1001
2011-08-09 19:09:16,936 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_443865646643972643_1001 src: /127.0.0.1:38328 dest: /127.0.0.1:50867
2011-08-09 19:09:16,938 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_443865646643972643_1001 src: /127.0.0.1:33717 dest: /127.0.0.1:58348
2011-08-09 19:09:16,940 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_443865646643972643_1001 src: /127.0.0.1:35732 dest: /127.0.0.1:38277
2011-08-09 19:09:16,989 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:35732, dest: /127.0.0.1:38277, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_187331748, offset: 0, srvID: DS-1820013218-10.0.62.238-38277-1312909756522, blockid: blk_443865646643972643_1001, duration: 45586234
2011-08-09 19:09:16,991 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:38277 is added to blk_443865646643972643_1001 size 1024
2011-08-09 19:09:16,991 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_443865646643972643_1001 terminating
2011-08-09 19:09:16,996 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:33717, dest: /127.0.0.1:58348, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_187331748, offset: 0, srvID: DS-175622314-10.0.62.238-58348-1312909756145, blockid: blk_443865646643972643_1001, duration: 50714538
2011-08-09 19:09:16,996 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_443865646643972643_1001 terminating
2011-08-09 19:09:16,997 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:58348 is added to blk_443865646643972643_1001 size 1024
2011-08-09 19:09:17,001 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:17,003 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 3 msecs
2011-08-09 19:09:17,004 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:38328, dest: /127.0.0.1:50867, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_187331748, offset: 0, srvID: DS-863774097-10.0.62.238-50867-1312909756883, blockid: blk_443865646643972643_1001, duration: 55202503
2011-08-09 19:09:17,005 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_443865646643972643_1001 terminating
2011-08-09 19:09:17,006 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50867 is added to blk_443865646643972643_1001 size 1024
2011-08-09 19:09:17,010 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/testBlockVerification/file1 is closed by DFSClient_187331748
2011-08-09 19:09:17,013 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:17,016 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:38277, dest: /127.0.0.1:35733, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-1820013218-10.0.62.238-38277-1312909756522, blockid: blk_443865646643972643_1001, duration: 419253
2011-08-09 19:09:17,024 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:17,025 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionPolicy(178)) - Looping until expected blockCount of 3 is received
MiniDFSCluster Stopping DataNode 127.0.0.1:50867 from a total of 3 datanodes.
2011-08-09 19:09:18,042 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:18,043 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51546
2011-08-09 19:09:18,044 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51546: exiting
2011-08-09 19:09:18,044 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51546: exiting
2011-08-09 19:09:18,051 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51546
2011-08-09 19:09:18,051 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51546: exiting
2011-08-09 19:09:18,053 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:18,053 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:50867, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=44231, ipcPort=51546):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:18,053 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:18,054 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:18,055 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:50867, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=44231, ipcPort=51546):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:18,055 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51546
2011-08-09 19:09:18,055 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:18,056 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:18,060 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:18,062 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:18,203 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:18,204 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 51340
2011-08-09 19:09:18,205 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:18,207 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:18,208 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:18,208 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 60092 webServer.getConnectors()[0].getLocalPort() returned 60092
2011-08-09 19:09:18,209 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 60092
2011-08-09 19:09:18,209 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:18,290 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:60092
2011-08-09 19:09:18,291 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:18,296 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:18,298 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=42697
2011-08-09 19:09:18,299 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:18,300 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 42697: starting
2011-08-09 19:09:18,343 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 42697: starting
2011-08-09 19:09:18,344 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:51340, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=60092, ipcPort=42697)
2011-08-09 19:09:18,353 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 42697: starting
2011-08-09 19:09:18,344 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 42697: starting
2011-08-09 19:09:18,356 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:51340 storage DS-863774097-10.0.62.238-50867-1312909756883
2011-08-09 19:09:18,356 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2793)) - BLOCK* NameSystem.registerDatanode: node 127.0.0.1:50867 is replaced by 127.0.0.1:51340 with the same storageID DS-863774097-10.0.62.238-50867-1312909756883
2011-08-09 19:09:18,357 INFO  net.NetworkTopology (NetworkTopology.java:remove(350)) - Removing a node: /default-rack/127.0.0.1:50867
2011-08-09 19:09:18,357 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:51340
2011-08-09 19:09:18,359 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:51340, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=60092, ipcPort=42697)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:18,361 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:18,362 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionPolicy(197)) - Looping until expected blockCount of 2 is received
2011-08-09 19:09:18,363 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 1000msec Initial delay: 0msec
2011-08-09 19:09:18,367 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:18,368 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:09:18,368 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:18,369 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:18,371 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - First Verification failed for blk_443865646643972643_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:18,371 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - Second Verification failed for blk_443865646643972643_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:18,371 INFO  datanode.DataBlockScanner (DataBlockScanner.java:handleScanFailure(345)) - Reporting bad block blk_443865646643972643_1001 to namenode.
2011-08-09 19:09:18,372 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:18,373 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_443865646643972643 added as corrupt on 127.0.0.1:51340 by /127.0.0.1
2011-08-09 19:09:19,214 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:19,216 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:09:19,364 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:19,365 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionPolicy(197)) - Looping until expected blockCount of 2 is received
2011-08-09 19:09:19,538 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:19,539 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
2011-08-09 19:09:20,368 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:20,378 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:58348, dest: /127.0.0.1:33721, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-175622314-10.0.62.238-58348-1312909756145, blockid: blk_443865646643972643_1001, duration: 4269662
2011-08-09 19:09:20,419 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f4424144424144a712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546c4f7250191a3b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_443865646643972643:of:/tmp/testBlockVerification/file1 at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionPolicy(TestDatanodeBlockScanner.java:212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:20,421 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_443865646643972643_1001 from 127.0.0.1:58348 at 0
2011-08-09 19:09:20,431 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:20,436 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_443865646643972643 added as corrupt on 127.0.0.1:58348 by /127.0.0.1
2011-08-09 19:09:20,440 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:38277, dest: /127.0.0.1:35736, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-1820013218-10.0.62.238-38277-1312909756522, blockid: blk_443865646643972643_1001, duration: 282297
2011-08-09 19:09:20,457 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f41d3ebaf8986da712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546424144424144b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_443865646643972643:of:/tmp/testBlockVerification/file1 at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionPolicy(TestDatanodeBlockScanner.java:212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:20,458 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_443865646643972643_1001 from 127.0.0.1:38277 at 0
2011-08-09 19:09:20,460 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:20,460 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_443865646643972643 added as corrupt on 127.0.0.1:38277 by /127.0.0.1
2011-08-09 19:09:20,461 INFO  hdfs.DFSClient (DFSClient.java:chooseDataNode(2355)) - Could not obtain block blk_443865646643972643_1001 from node:   java.io.IOException: No live nodes contain current block
2011-08-09 19:09:20,462 WARN  hdfs.DFSClient (DFSClient.java:chooseDataNode(2370)) - DFS chooseDataNode: got # 1 IOException, will wait for 533.9161833150988 msec.
2011-08-09 19:09:20,996 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:20,999 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:58348, dest: /127.0.0.1:33723, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-175622314-10.0.62.238-58348-1312909756145, blockid: blk_443865646643972643_1001, duration: 439096
2011-08-09 19:09:21,015 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f4424144424144a712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546c4f7250191a3b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_443865646643972643:of:/tmp/testBlockVerification/file1 at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionPolicy(TestDatanodeBlockScanner.java:212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:21,015 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_443865646643972643_1001 from 127.0.0.1:58348 at 0
2011-08-09 19:09:21,016 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:21,017 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(58)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_443865646643972643 to add as corrupt on 127.0.0.1:58348 by /127.0.0.1
2011-08-09 19:09:21,025 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:38277, dest: /127.0.0.1:35738, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-1820013218-10.0.62.238-38277-1312909756522, blockid: blk_443865646643972643_1001, duration: 311924
2011-08-09 19:09:21,120 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f41d3ebaf8986da712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546424144424144b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_443865646643972643:of:/tmp/testBlockVerification/file1 at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionPolicy(TestDatanodeBlockScanner.java:212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:21,121 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_443865646643972643_1001 from 127.0.0.1:38277 at 0
2011-08-09 19:09:21,182 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:21,191 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(58)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_443865646643972643 to add as corrupt on 127.0.0.1:38277 by /127.0.0.1
2011-08-09 19:09:21,207 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:51340, dest: /127.0.0.1:48010, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-863774097-10.0.62.238-50867-1312909756883, blockid: blk_443865646643972643_1001, duration: 356923
2011-08-09 19:09:21,217 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f41d3ebaf8986da712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546c4f7250191a3b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b734241444241443cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824942414442414420a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_443865646643972643:of:/tmp/testBlockVerification/file1 at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionPolicy(TestDatanodeBlockScanner.java:212)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:21,217 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_443865646643972643_1001 from 127.0.0.1:51340 at 0
2011-08-09 19:09:21,218 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:21,219 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(58)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_443865646643972643 to add as corrupt on 127.0.0.1:51340 by /127.0.0.1
2011-08-09 19:09:21,238 INFO  hdfs.DFSClient (DFSClient.java:chooseDataNode(2355)) - Could not obtain block blk_443865646643972643_1001 from node:   java.io.IOException: No live nodes contain current block
2011-08-09 19:09:21,239 WARN  hdfs.DFSClient (DFSClient.java:chooseDataNode(2370)) - DFS chooseDataNode: got # 1 IOException, will wait for 2524.439159486945 msec.
2011-08-09 19:09:21,363 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:21,364 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
2011-08-09 19:09:22,217 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:22,218 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:09:22,538 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:22,539 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
2011-08-09 19:09:23,764 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:23,767 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:51340, dest: /127.0.0.1:48011, bytes: 1032, op: HDFS_READ, cliID: DFSClient_187331748, offset: 0, srvID: DS-863774097-10.0.62.238-50867-1312909756883, blockid: blk_443865646643972643_1001, duration: 387388
2011-08-09 19:09:23,771 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockVerification/file1	dst=null	perm=null
2011-08-09 19:09:23,771 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionPolicy(225)) - Looping until expected blockCount of 3 is received
2011-08-09 19:09:24,364 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:24,365 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
Shutting down the Mini HDFS Cluster
Shutting down DataNode 2
2011-08-09 19:09:24,900 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:24,901 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 42697
2011-08-09 19:09:24,902 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 42697: exiting
2011-08-09 19:09:24,902 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 42697: exiting
2011-08-09 19:09:24,902 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 42697: exiting
2011-08-09 19:09:24,902 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 42697
2011-08-09 19:09:24,904 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:24,904 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:51340, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=60092, ipcPort=42697):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:24,905 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:24,905 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:24,906 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:51340, storageID=DS-863774097-10.0.62.238-50867-1312909756883, infoPort=60092, ipcPort=42697):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:24,906 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 42697
2011-08-09 19:09:24,906 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:24,907 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:24,907 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:24,908 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:09:24,957 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:24,959 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36192
2011-08-09 19:09:24,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36192: exiting
2011-08-09 19:09:24,960 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36192
2011-08-09 19:09:24,960 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36192: exiting
2011-08-09 19:09:24,960 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36192: exiting
2011-08-09 19:09:24,962 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:24,962 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38277, storageID=DS-1820013218-10.0.62.238-38277-1312909756522, infoPort=35454, ipcPort=36192):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:24,964 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:24,964 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:24,965 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38277, storageID=DS-1820013218-10.0.62.238-38277-1312909756522, infoPort=35454, ipcPort=36192):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:09:24,965 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36192
2011-08-09 19:09:24,966 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:24,966 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:24,966 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:24,967 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:09:25,030 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:25,130 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50878
2011-08-09 19:09:25,131 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50878: exiting
2011-08-09 19:09:25,131 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50878: exiting
2011-08-09 19:09:25,131 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50878: exiting
2011-08-09 19:09:25,132 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50878
2011-08-09 19:09:25,133 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:25,133 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:58348, storageID=DS-175622314-10.0.62.238-58348-1312909756145, infoPort=39187, ipcPort=50878):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:25,134 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:25,134 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:25,135 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:58348, storageID=DS-175622314-10.0.62.238-58348-1312909756145, infoPort=39187, ipcPort=50878):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:25,135 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50878
2011-08-09 19:09:25,135 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:25,136 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:25,136 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:25,137 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:25,142 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:25,243 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:09:25,243 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:09:25,244 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:09:25,247 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60625
2011-08-09 19:09:25,248 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60625
2011-08-09 19:09:25,248 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 60625: exiting
2011-08-09 19:09:25,249 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 60625: exiting
2011-08-09 19:09:25,249 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 60625: exiting
2011-08-09 19:09:25,250 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 60625: exiting
2011-08-09 19:09:25,250 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 60625: exiting
2011-08-09 19:09:25,250 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 60625: exiting
2011-08-09 19:09:25,250 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 60625: exiting
2011-08-09 19:09:25,251 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60625: exiting
2011-08-09 19:09:25,251 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60625: exiting
2011-08-09 19:09:25,251 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60625: exiting
2011-08-09 19:09:25,253 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:25,254 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionRecoveryPolicy(253)) - Testing corrupt replica recovery for one corrupt replica
2011-08-09 19:09:25,298 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:25,298 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:25,298 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:25,299 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:25,304 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:25,304 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:25,305 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:25,305 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:25,313 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:25,313 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:25,325 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:09:25,327 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:25,328 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:25,362 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:09:25,363 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:09:25,366 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:25,366 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:25,366 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:25,366 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:25,366 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:25,372 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:09:25,372 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:25,372 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:25,373 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:25,538 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:25,539 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:09:25,539 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:25,543 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:09:25,543 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:09:25,543 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:09:25,544 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:09:25,544 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:25,545 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:25,546 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:09:25,546 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 174 msecs
2011-08-09 19:09:25,546 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:09:25,550 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:09:25,550 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:09:25,551 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:09:25,551 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:09:25,551 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:09:25,553 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:25,555 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=47780
2011-08-09 19:09:25,556 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:47780
2011-08-09 19:09:25,556 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:25,556 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47780: starting
2011-08-09 19:09:25,578 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47780: starting
2011-08-09 19:09:25,578 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47780: starting
2011-08-09 19:09:25,579 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47780: starting
2011-08-09 19:09:25,579 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 47780: starting
2011-08-09 19:09:25,579 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 47780: starting
2011-08-09 19:09:25,579 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 47780: starting
2011-08-09 19:09:25,580 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 47780: starting
2011-08-09 19:09:25,580 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 47780: starting
2011-08-09 19:09:25,580 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 47780: starting
2011-08-09 19:09:25,581 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 47780: starting
2011-08-09 19:09:25,590 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:09:25,591 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:09:25,591 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:09:25,591 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:09:25,592 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:09:25,594 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:25,595 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:25,595 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 33818 webServer.getConnectors()[0].getLocalPort() returned 33818
2011-08-09 19:09:25,596 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 33818
2011-08-09 19:09:25,596 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:25,675 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:33818
2011-08-09 19:09:25,676 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:33818
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:09:25,721 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:09:25,721 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:25,737 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:09:25,737 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:25,917 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:25,919 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44142
2011-08-09 19:09:25,919 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:25,922 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:25,923 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:25,923 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35246 webServer.getConnectors()[0].getLocalPort() returned 35246
2011-08-09 19:09:25,923 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35246
2011-08-09 19:09:25,924 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:26,009 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35246
2011-08-09 19:09:26,009 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:26,014 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:26,016 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41097
2011-08-09 19:09:26,017 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:26,017 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41097: starting
2011-08-09 19:09:26,019 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41097: starting
2011-08-09 19:09:26,020 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41097: starting
2011-08-09 19:09:26,021 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44142, storageID=, infoPort=35246, ipcPort=41097)
2011-08-09 19:09:26,021 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41097: starting
2011-08-09 19:09:26,026 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44142 storage DS-2111350168-10.0.62.238-44142-1312909766024
2011-08-09 19:09:26,027 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44142
2011-08-09 19:09:26,032 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2111350168-10.0.62.238-44142-1312909766024 is assigned to data-node 127.0.0.1:44142
2011-08-09 19:09:26,041 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44142, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=35246, ipcPort=41097)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:26,042 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:09:26,049 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,052 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:44142 0 blocks shortCircuit first report.
2011-08-09 19:09:26,053 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:09:26,053 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:26,053 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:09:26,054 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:26,054 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,069 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:09:26,070 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:26,203 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:26,205 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 57521
2011-08-09 19:09:26,205 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:26,208 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:26,209 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:26,209 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39536 webServer.getConnectors()[0].getLocalPort() returned 39536
2011-08-09 19:09:26,209 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39536
2011-08-09 19:09:26,210 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:26,329 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39536
2011-08-09 19:09:26,330 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:26,334 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:26,337 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=47705
2011-08-09 19:09:26,338 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:26,339 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47705: starting
2011-08-09 19:09:26,340 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47705: starting
2011-08-09 19:09:26,341 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47705: starting
2011-08-09 19:09:26,341 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:57521, storageID=, infoPort=39536, ipcPort=47705)
2011-08-09 19:09:26,342 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47705: starting
2011-08-09 19:09:26,347 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:57521 storage DS-1790317966-10.0.62.238-57521-1312909766344
2011-08-09 19:09:26,348 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:57521
2011-08-09 19:09:26,354 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1790317966-10.0.62.238-57521-1312909766344 is assigned to data-node 127.0.0.1:57521
2011-08-09 19:09:26,355 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:57521, storageID=DS-1790317966-10.0.62.238-57521-1312909766344, infoPort=39536, ipcPort=47705)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:09:26,398 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:09:26,405 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,406 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:57521 0 blocks shortCircuit first report.
2011-08-09 19:09:26,407 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:09:26,408 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:26,409 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:09:26,410 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:26,410 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,426 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:09:26,427 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:26,608 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:26,609 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 52466
2011-08-09 19:09:26,620 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:26,641 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:26,641 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:26,642 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59395 webServer.getConnectors()[0].getLocalPort() returned 59395
2011-08-09 19:09:26,642 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59395
2011-08-09 19:09:26,642 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:26,739 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59395
2011-08-09 19:09:26,740 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:26,746 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:26,748 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34663
2011-08-09 19:09:26,750 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:26,791 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34663: starting
2011-08-09 19:09:26,791 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34663: starting
2011-08-09 19:09:26,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34663: starting
2011-08-09 19:09:26,811 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:52466, storageID=, infoPort=59395, ipcPort=34663)
2011-08-09 19:09:26,811 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34663: starting
2011-08-09 19:09:26,817 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:52466 storage DS-550454883-10.0.62.238-52466-1312909766815
2011-08-09 19:09:26,818 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:52466
2011-08-09 19:09:26,823 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-550454883-10.0.62.238-52466-1312909766815 is assigned to data-node 127.0.0.1:52466
Starting DataNode 3 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8
2011-08-09 19:09:26,825 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:52466, storageID=DS-550454883-10.0.62.238-52466-1312909766815, infoPort=59395, ipcPort=34663)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:26,826 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:09:26,830 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,833 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:52466 0 blocks shortCircuit first report.
2011-08-09 19:09:26,834 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:09:26,834 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:26,835 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:26,835 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7 is not formatted.
2011-08-09 19:09:26,836 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:26,852 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8 is not formatted.
2011-08-09 19:09:26,853 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:09:27,005 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:27,006 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 45747
2011-08-09 19:09:27,006 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:27,010 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:27,011 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:27,011 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 54651 webServer.getConnectors()[0].getLocalPort() returned 54651
2011-08-09 19:09:27,011 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 54651
2011-08-09 19:09:27,011 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:27,095 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:54651
2011-08-09 19:09:27,096 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:27,106 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:27,109 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=56184
2011-08-09 19:09:27,112 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:27,132 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 56184: starting
2011-08-09 19:09:27,133 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 56184: starting
2011-08-09 19:09:27,135 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:45747, storageID=, infoPort=54651, ipcPort=56184)
2011-08-09 19:09:27,135 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 56184: starting
2011-08-09 19:09:27,135 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 56184: starting
2011-08-09 19:09:27,141 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:45747 storage DS-445428375-10.0.62.238-45747-1312909767139
2011-08-09 19:09:27,142 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:45747
2011-08-09 19:09:27,148 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-445428375-10.0.62.238-45747-1312909767139 is assigned to data-node 127.0.0.1:45747
2011-08-09 19:09:27,149 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:45747, storageID=DS-445428375-10.0.62.238-45747-1312909767139, infoPort=54651, ipcPort=56184)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
2011-08-09 19:09:27,150 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:09:27,154 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:27,155 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:45747 0 blocks shortCircuit first report.
2011-08-09 19:09:27,156 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:09:27,157 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:27,158 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:27,180 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/testBlockCorruptRecovery	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:09:27,186 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:09:27,192 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/testBlockCorruptRecovery/file. blk_2366933448316030159_1001
2011-08-09 19:09:27,194 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2366933448316030159_1001 src: /127.0.0.1:41382 dest: /127.0.0.1:45747
2011-08-09 19:09:27,196 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2366933448316030159_1001 src: /127.0.0.1:35197 dest: /127.0.0.1:52466
2011-08-09 19:09:27,198 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2366933448316030159_1001 src: /127.0.0.1:53281 dest: /127.0.0.1:44142
2011-08-09 19:09:27,206 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:53281, dest: /127.0.0.1:44142, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1254263830, offset: 0, srvID: DS-2111350168-10.0.62.238-44142-1312909766024, blockid: blk_2366933448316030159_1001, duration: 2742026
2011-08-09 19:09:27,206 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_2366933448316030159_1001 terminating
2011-08-09 19:09:27,209 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44142 is added to blk_2366933448316030159_1001 size 1024
2011-08-09 19:09:27,209 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:35197, dest: /127.0.0.1:52466, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1254263830, offset: 0, srvID: DS-550454883-10.0.62.238-52466-1312909766815, blockid: blk_2366933448316030159_1001, duration: 7128612
2011-08-09 19:09:27,210 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_2366933448316030159_1001 terminating
2011-08-09 19:09:27,211 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:27,211 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:52466 is added to blk_2366933448316030159_1001 size 1024
2011-08-09 19:09:27,212 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:41382, dest: /127.0.0.1:45747, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1254263830, offset: 0, srvID: DS-445428375-10.0.62.238-45747-1312909767139, blockid: blk_2366933448316030159_1001, duration: 9526301
2011-08-09 19:09:27,214 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_2366933448316030159_1001 terminating
2011-08-09 19:09:27,215 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:45747 is added to blk_2366933448316030159_1001 size 1024
2011-08-09 19:09:27,216 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 6 msecs
2011-08-09 19:09:27,215 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:27,218 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:27,219 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 4 msecs
2011-08-09 19:09:27,260 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 43 msecs
2011-08-09 19:09:27,262 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/testBlockCorruptRecovery/file is closed by DFSClient_1254263830
2011-08-09 19:09:27,264 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:27,267 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:44142, dest: /127.0.0.1:53282, bytes: 1032, op: HDFS_READ, cliID: DFSClient_1254263830, offset: 0, srvID: DS-2111350168-10.0.62.238-44142-1312909766024, blockid: blk_2366933448316030159_1001, duration: 400310
2011-08-09 19:09:27,275 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
MiniDFSCluster Stopping DataNode 127.0.0.1:44142 from a total of 4 datanodes.
2011-08-09 19:09:27,432 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:27,435 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41097
2011-08-09 19:09:27,435 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41097: exiting
2011-08-09 19:09:27,436 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41097: exiting
2011-08-09 19:09:27,437 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41097
2011-08-09 19:09:27,437 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41097: exiting
2011-08-09 19:09:27,439 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 2
2011-08-09 19:09:27,439 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44142, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=35246, ipcPort=41097):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:27,440 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:28,063 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:28,439 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:28,440 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44142, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=35246, ipcPort=41097):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:28,440 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41097
2011-08-09 19:09:28,440 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:28,441 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:28,441 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:28,442 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:28,582 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:09:28,583 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44874
2011-08-09 19:09:28,584 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:09:28,587 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:09:28,587 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:09:28,588 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 50418 webServer.getConnectors()[0].getLocalPort() returned 50418
2011-08-09 19:09:28,588 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 50418
2011-08-09 19:09:28,600 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:09:28,675 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:50418
2011-08-09 19:09:28,677 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:09:28,681 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:09:28,683 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36165
2011-08-09 19:09:28,685 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:09:28,685 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36165: starting
2011-08-09 19:09:28,686 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36165: starting
2011-08-09 19:09:28,687 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36165: starting
2011-08-09 19:09:28,687 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44874, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=50418, ipcPort=36165)
2011-08-09 19:09:28,688 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36165: starting
2011-08-09 19:09:28,690 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44874 storage DS-2111350168-10.0.62.238-44142-1312909766024
2011-08-09 19:09:28,690 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2793)) - BLOCK* NameSystem.registerDatanode: node 127.0.0.1:44142 is replaced by 127.0.0.1:44874 with the same storageID DS-2111350168-10.0.62.238-44142-1312909766024
2011-08-09 19:09:28,691 INFO  net.NetworkTopology (NetworkTopology.java:remove(350)) - Removing a node: /default-rack/127.0.0.1:44142
2011-08-09 19:09:28,691 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44874
2011-08-09 19:09:28,692 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44874, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=50418, ipcPort=36165)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:28,694 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:09:28,698 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:28,700 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:28,702 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:09:28,703 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:09:28,705 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:28,730 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - First Verification failed for blk_2366933448316030159_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:28,731 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - Second Verification failed for blk_2366933448316030159_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:28,731 INFO  datanode.DataBlockScanner (DataBlockScanner.java:handleScanFailure(345)) - Reporting bad block blk_2366933448316030159_1001 to namenode.
2011-08-09 19:09:28,742 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:28,743 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_2366933448316030159 added as corrupt on 127.0.0.1:44874 by /127.0.0.1
2011-08-09 19:09:28,744 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f41d3ebaf8986da712c82bcd4d554bf0b54023c29b624de9ef9c2f931efc580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546c4f7250191a3b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8ac4241444241445adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_2366933448316030159:of:/tmp/testBlockCorruptRecovery/file at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.blockCorruptionRecoveryPolicy(TestDatanodeBlockScanner.java:322)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionRecoveryPolicy(TestDatanodeBlockScanner.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:09:28,745 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_2366933448316030159_1001 from 127.0.0.1:44874 at 0
2011-08-09 19:09:28,746 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:09:28,746 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:44874, dest: /127.0.0.1:46928, bytes: 1032, op: HDFS_READ, cliID: DFSClient_1254263830, offset: 0, srvID: DS-2111350168-10.0.62.238-44142-1312909766024, blockid: blk_2366933448316030159_1001, duration: 40678612
2011-08-09 19:09:28,747 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(58)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_2366933448316030159 to add as corrupt on 127.0.0.1:44874 by /127.0.0.1
2011-08-09 19:09:28,788 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:52466, dest: /127.0.0.1:35201, bytes: 1032, op: HDFS_READ, cliID: DFSClient_1254263830, offset: 0, srvID: DS-550454883-10.0.62.238-52466-1312909766815, blockid: blk_2366933448316030159_1001, duration: 481657
2011-08-09 19:09:28,789 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(327)) - Looping until expected 1 are reported. Current reported 0
2011-08-09 19:09:29,790 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:29,791 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:30,793 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:30,793 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:31,794 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:31,795 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:32,796 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:32,797 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:33,798 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:33,799 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:34,800 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:34,801 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:35,802 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:35,803 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:36,804 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:36,805 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:37,807 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:37,808 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:38,809 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:38,810 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:39,811 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:39,812 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:40,813 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:40,813 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:41,814 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:41,815 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:42,816 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:42,817 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:43,818 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:43,819 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:44,820 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:44,821 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:45,822 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:45,822 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:46,824 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:46,824 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:47,825 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:47,826 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:48,827 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:48,827 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:49,828 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:49,829 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:50,830 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:50,830 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:51,831 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:51,832 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:52,833 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:52,834 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:53,835 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:53,836 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:54,837 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:54,838 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:55,601 INFO  hdfs.StateChange (FSNamesystem.java:computeReplicationWorkForBlock(3344)) - BLOCK* ask 127.0.0.1:52466 to replicate blk_2366933448316030159_1001 to datanode(s) 127.0.0.1:57521
2011-08-09 19:09:55,839 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:55,840 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:09:56,398 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:56,401 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:57521 0 blocks shortCircuit first report.
2011-08-09 19:09:56,401 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:09:56,826 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:56,829 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 3 msecs
2011-08-09 19:09:56,833 INFO  datanode.DataNode (DataNode.java:transferBlock(1038)) - DatanodeRegistration(127.0.0.1:52466, storageID=DS-550454883-10.0.62.238-52466-1312909766815, infoPort=59395, ipcPort=34663) Starting thread to transfer block blk_2366933448316030159_1001 to 127.0.0.1:57521 
2011-08-09 19:09:56,835 INFO  datanode.DataNode (DataNode.java:run(1249)) - DatanodeRegistration(127.0.0.1:52466, storageID=DS-550454883-10.0.62.238-52466-1312909766815, infoPort=59395, ipcPort=34663):Transmitted block blk_2366933448316030159_1001 to /127.0.0.1:57521
2011-08-09 19:09:56,836 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2366933448316030159_1001 src: /127.0.0.1:39777 dest: /127.0.0.1:57521
2011-08-09 19:09:56,838 INFO  datanode.DataNode (DataXceiver.java:writeBlock(393)) - Received block blk_2366933448316030159_1001 src: /127.0.0.1:39777 dest: /127.0.0.1:57521 of size 1024
2011-08-09 19:09:56,838 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:57521 is added to blk_2366933448316030159_1001 size 1024
2011-08-09 19:09:56,838 INFO  hdfs.StateChange (FSNamesystem.java:invalidateBlock(2105)) - DIR* NameSystem.invalidateBlock: blk_2366933448316030159_1001 on 127.0.0.1:44874
2011-08-09 19:09:56,838 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_2366933448316030159 is added to invalidSet of 127.0.0.1:44874
2011-08-09 19:09:56,839 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:56,841 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:09:56,842 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 3 msecs
Shutting down the Mini HDFS Cluster
Shutting down DataNode 3
2011-08-09 19:09:56,901 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:57,002 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36165
2011-08-09 19:09:57,002 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36165: exiting
2011-08-09 19:09:57,003 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36165: exiting
2011-08-09 19:09:57,003 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36165: exiting
2011-08-09 19:09:57,004 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36165
2011-08-09 19:09:57,005 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:57,006 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:09:57,006 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44874, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=50418, ipcPort=36165):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:57,150 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:09:57,152 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:09:57,747 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:58,006 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:58,007 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44874, storageID=DS-2111350168-10.0.62.238-44142-1312909766024, infoPort=50418, ipcPort=36165):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:09:58,007 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36165
2011-08-09 19:09:58,007 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:58,008 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:58,008 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:58,010 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 2
2011-08-09 19:09:58,045 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:58,146 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56184
2011-08-09 19:09:58,146 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 56184: exiting
2011-08-09 19:09:58,146 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 56184: exiting
2011-08-09 19:09:58,147 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 56184: exiting
2011-08-09 19:09:58,148 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 56184
2011-08-09 19:09:58,149 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:58,150 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:45747, storageID=DS-445428375-10.0.62.238-45747-1312909767139, infoPort=54651, ipcPort=56184):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:58,150 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:58,150 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:58,151 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:45747, storageID=DS-445428375-10.0.62.238-45747-1312909767139, infoPort=54651, ipcPort=56184):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
2011-08-09 19:09:58,151 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56184
2011-08-09 19:09:58,151 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:58,152 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:58,152 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:58,154 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:09:58,157 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:58,157 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34663
2011-08-09 19:09:58,158 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34663: exiting
2011-08-09 19:09:58,158 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34663: exiting
2011-08-09 19:09:58,198 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34663: exiting
2011-08-09 19:09:58,199 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34663
2011-08-09 19:09:58,201 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:58,201 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:09:58,201 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:52466, storageID=DS-550454883-10.0.62.238-52466-1312909766815, infoPort=59395, ipcPort=34663):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:58,841 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:59,202 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:59,203 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:52466, storageID=DS-550454883-10.0.62.238-52466-1312909766815, infoPort=59395, ipcPort=34663):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:09:59,203 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34663
2011-08-09 19:09:59,203 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:59,204 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:59,204 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:59,206 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:09:59,317 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:59,417 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47705
2011-08-09 19:09:59,418 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47705
2011-08-09 19:09:59,418 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47705: exiting
2011-08-09 19:09:59,419 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47705: exiting
2011-08-09 19:09:59,419 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47705: exiting
2011-08-09 19:09:59,421 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:59,422 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:57521, storageID=DS-1790317966-10.0.62.238-57521-1312909766344, infoPort=39536, ipcPort=47705):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:09:59,422 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:59,422 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:09:59,423 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:57521, storageID=DS-1790317966-10.0.62.238-57521-1312909766344, infoPort=39536, ipcPort=47705):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:09:59,424 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47705
2011-08-09 19:09:59,424 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:09:59,424 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:09:59,425 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:09:59,426 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:09:59,473 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:09:59,574 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:09:59,575 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:09:59,576 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:5  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:09:59,579 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47780
2011-08-09 19:09:59,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 47780: exiting
2011-08-09 19:09:59,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 47780: exiting
2011-08-09 19:09:59,582 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47780: exiting
2011-08-09 19:09:59,582 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47780
2011-08-09 19:09:59,582 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47780: exiting
2011-08-09 19:09:59,583 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47780: exiting
2011-08-09 19:09:59,583 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 47780: exiting
2011-08-09 19:09:59,584 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 47780: exiting
2011-08-09 19:09:59,585 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 47780: exiting
2011-08-09 19:09:59,585 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 47780: exiting
2011-08-09 19:09:59,585 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 47780: exiting
2011-08-09 19:09:59,593 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:09:59,593 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:testBlockCorruptionRecoveryPolicy(257)) - Testing corrupt replica recovery for two corrupt replicas
2011-08-09 19:09:59,686 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:59,686 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:59,686 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:59,687 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:59,698 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:59,699 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:59,699 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:59,699 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:59,730 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:59,730 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:59,742 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:09:59,745 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:09:59,745 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:59,782 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:09:59,783 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:09:59,787 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:59,787 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:09:59,787 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:09:59,787 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:09:59,787 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:09:59,791 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:09:59,792 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:09:59,792 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:09:59,792 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:09:59,981 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:09:59,982 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:09:59,983 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:09:59,987 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:09:59,988 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:09:59,988 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:09:59,988 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:09:59,988 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:59,989 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:09:59,990 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:09:59,990 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 199 msecs
2011-08-09 19:09:59,990 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:09:59,994 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:09:59,995 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:09:59,995 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:09:59,995 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:09:59,995 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:09:59,997 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:00,001 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=54630
2011-08-09 19:10:00,002 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:54630
2011-08-09 19:10:00,002 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:00,005 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54630: starting
2011-08-09 19:10:00,046 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54630: starting
2011-08-09 19:10:00,046 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54630: starting
2011-08-09 19:10:00,046 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54630: starting
2011-08-09 19:10:00,046 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 54630: starting
2011-08-09 19:10:00,047 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 54630: starting
2011-08-09 19:10:00,047 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 54630: starting
2011-08-09 19:10:00,047 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 54630: starting
2011-08-09 19:10:00,047 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 54630: starting
2011-08-09 19:10:00,048 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 54630: starting
2011-08-09 19:10:00,073 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 54630: starting
2011-08-09 19:10:00,115 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:10:00,116 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:10:00,116 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:10:00,116 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:10:00,138 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:10:00,139 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:00,140 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:00,140 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35405 webServer.getConnectors()[0].getLocalPort() returned 35405
2011-08-09 19:10:00,141 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35405
2011-08-09 19:10:00,141 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:00,221 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35405
2011-08-09 19:10:00,221 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:35405
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:10:00,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:10:00,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:00,269 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:10:00,269 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:00,527 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:00,531 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48712
2011-08-09 19:10:00,531 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:00,538 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:00,539 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:00,540 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49210 webServer.getConnectors()[0].getLocalPort() returned 49210
2011-08-09 19:10:00,541 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49210
2011-08-09 19:10:00,541 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:00,669 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49210
2011-08-09 19:10:00,671 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:00,677 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:00,680 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60182
2011-08-09 19:10:00,681 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60182: starting
2011-08-09 19:10:00,681 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:00,723 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60182: starting
2011-08-09 19:10:00,724 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60182: starting
2011-08-09 19:10:00,724 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48712, storageID=, infoPort=49210, ipcPort=60182)
2011-08-09 19:10:00,725 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60182: starting
2011-08-09 19:10:00,733 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48712 storage DS-1956468359-10.0.62.238-48712-1312909800728
2011-08-09 19:10:00,734 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48712
2011-08-09 19:10:00,742 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1956468359-10.0.62.238-48712-1312909800728 is assigned to data-node 127.0.0.1:48712
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:10:00,753 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48712, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=49210, ipcPort=60182)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:00,755 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:00,804 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:10:00,806 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:00,807 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:00,808 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48712 0 blocks shortCircuit first report.
2011-08-09 19:10:00,809 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:10:00,809 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:00,810 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:00,823 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:10:00,823 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:00,972 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:00,974 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 56702
2011-08-09 19:10:00,974 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:00,977 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:00,977 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:00,978 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 47550 webServer.getConnectors()[0].getLocalPort() returned 47550
2011-08-09 19:10:00,978 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 47550
2011-08-09 19:10:00,978 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:01,085 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:47550
2011-08-09 19:10:01,086 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:01,091 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:01,093 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=53836
2011-08-09 19:10:01,094 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:01,095 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53836: starting
2011-08-09 19:10:01,096 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53836: starting
2011-08-09 19:10:01,097 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53836: starting
2011-08-09 19:10:01,098 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:56702, storageID=, infoPort=47550, ipcPort=53836)
2011-08-09 19:10:01,098 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53836: starting
2011-08-09 19:10:01,105 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:56702 storage DS-992104614-10.0.62.238-56702-1312909801102
2011-08-09 19:10:01,106 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:56702
2011-08-09 19:10:01,112 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-992104614-10.0.62.238-56702-1312909801102 is assigned to data-node 127.0.0.1:56702
2011-08-09 19:10:01,113 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:56702, storageID=DS-992104614-10.0.62.238-56702-1312909801102, infoPort=47550, ipcPort=53836)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:10:01,115 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:01,121 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,122 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:56702 0 blocks shortCircuit first report.
2011-08-09 19:10:01,124 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:10:01,124 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:01,124 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:10:01,125 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,125 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,142 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:10:01,142 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,288 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:01,289 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 58844
2011-08-09 19:10:01,290 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:01,304 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:01,305 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:01,306 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40699 webServer.getConnectors()[0].getLocalPort() returned 40699
2011-08-09 19:10:01,306 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40699
2011-08-09 19:10:01,306 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:01,368 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40699
2011-08-09 19:10:01,369 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:01,373 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:01,376 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60166
2011-08-09 19:10:01,377 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:01,378 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60166: starting
2011-08-09 19:10:01,378 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60166: starting
2011-08-09 19:10:01,379 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60166: starting
2011-08-09 19:10:01,380 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60166: starting
2011-08-09 19:10:01,380 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:58844, storageID=, infoPort=40699, ipcPort=60166)
2011-08-09 19:10:01,386 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:58844 storage DS-1088246885-10.0.62.238-58844-1312909801383
2011-08-09 19:10:01,387 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:58844
2011-08-09 19:10:01,393 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1088246885-10.0.62.238-58844-1312909801383 is assigned to data-node 127.0.0.1:58844
2011-08-09 19:10:01,394 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-1088246885-10.0.62.238-58844-1312909801383, infoPort=40699, ipcPort=60166)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
Starting DataNode 3 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8
2011-08-09 19:10:01,436 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:01,440 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,443 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:58844 0 blocks shortCircuit first report.
2011-08-09 19:10:01,444 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:10:01,444 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7 is not formatted.
2011-08-09 19:10:01,444 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,444 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:01,446 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,461 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8 is not formatted.
2011-08-09 19:10:01,461 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,646 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:01,648 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 60395
2011-08-09 19:10:01,648 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:01,652 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:01,653 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:01,654 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 33596 webServer.getConnectors()[0].getLocalPort() returned 33596
2011-08-09 19:10:01,654 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 33596
2011-08-09 19:10:01,654 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:01,730 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:33596
2011-08-09 19:10:01,731 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:01,736 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:01,739 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=45863
2011-08-09 19:10:01,741 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:01,741 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45863: starting
2011-08-09 19:10:01,743 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45863: starting
2011-08-09 19:10:01,744 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45863: starting
2011-08-09 19:10:01,744 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:60395, storageID=, infoPort=33596, ipcPort=45863)
2011-08-09 19:10:01,745 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45863: starting
2011-08-09 19:10:01,751 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:60395 storage DS-2083924012-10.0.62.238-60395-1312909801748
2011-08-09 19:10:01,752 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:60395
2011-08-09 19:10:01,758 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2083924012-10.0.62.238-60395-1312909801748 is assigned to data-node 127.0.0.1:60395
2011-08-09 19:10:01,759 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:60395, storageID=DS-2083924012-10.0.62.238-60395-1312909801748, infoPort=33596, ipcPort=45863)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
Starting DataNode 4 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10
2011-08-09 19:10:01,762 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:01,766 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,767 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:60395 0 blocks shortCircuit first report.
2011-08-09 19:10:01,768 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:10:01,768 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:01,769 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:01,774 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9 is not formatted.
2011-08-09 19:10:01,774 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,790 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10 is not formatted.
2011-08-09 19:10:01,790 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:01,948 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:01,950 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 46371
2011-08-09 19:10:01,950 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:01,953 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:01,954 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:01,961 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57587 webServer.getConnectors()[0].getLocalPort() returned 57587
2011-08-09 19:10:01,961 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57587
2011-08-09 19:10:01,961 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:02,046 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57587
2011-08-09 19:10:02,047 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:02,052 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:02,055 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=59023
2011-08-09 19:10:02,056 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:02,057 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 59023: starting
2011-08-09 19:10:02,057 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 59023: starting
2011-08-09 19:10:02,099 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 59023: starting
2011-08-09 19:10:02,100 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 59023: starting
2011-08-09 19:10:02,099 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:46371, storageID=, infoPort=57587, ipcPort=59023)
2011-08-09 19:10:02,107 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:46371 storage DS-603528220-10.0.62.238-46371-1312909802104
2011-08-09 19:10:02,108 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:46371
2011-08-09 19:10:02,115 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-603528220-10.0.62.238-46371-1312909802104 is assigned to data-node 127.0.0.1:46371
2011-08-09 19:10:02,116 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:46371, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=57587, ipcPort=59023)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:10:02,118 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:02,121 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:02,122 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:46371 0 blocks shortCircuit first report.
2011-08-09 19:10:02,123 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:10:02,123 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:02,124 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:02,149 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/testBlockCorruptRecovery	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:10:02,154 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:10:02,159 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/testBlockCorruptRecovery/file. blk_-4230637966424062684_1001
2011-08-09 19:10:02,161 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4230637966424062684_1001 src: /127.0.0.1:57493 dest: /127.0.0.1:46371
2011-08-09 19:10:02,164 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4230637966424062684_1001 src: /127.0.0.1:40394 dest: /127.0.0.1:60395
2011-08-09 19:10:02,166 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4230637966424062684_1001 src: /127.0.0.1:47399 dest: /127.0.0.1:48712
2011-08-09 19:10:02,174 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:47399, dest: /127.0.0.1:48712, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_-505869608, offset: 0, srvID: DS-1956468359-10.0.62.238-48712-1312909800728, blockid: blk_-4230637966424062684_1001, duration: 3601237
2011-08-09 19:10:02,174 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4230637966424062684_1001 terminating
2011-08-09 19:10:02,176 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:40394, dest: /127.0.0.1:60395, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_-505869608, offset: 0, srvID: DS-2083924012-10.0.62.238-60395-1312909801748, blockid: blk_-4230637966424062684_1001, duration: 7022732
2011-08-09 19:10:02,178 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-4230637966424062684_1001 terminating
2011-08-09 19:10:02,177 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48712 is added to blk_-4230637966424062684_1001 size 1024
2011-08-09 19:10:02,180 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:57493, dest: /127.0.0.1:46371, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_-505869608, offset: 0, srvID: DS-603528220-10.0.62.238-46371-1312909802104, blockid: blk_-4230637966424062684_1001, duration: 8960461
2011-08-09 19:10:02,180 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-4230637966424062684_1001 terminating
2011-08-09 19:10:02,181 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:02,181 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:60395 is added to blk_-4230637966424062684_1001 size 1024
2011-08-09 19:10:02,182 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:46371 is added to blk_-4230637966424062684_1001 size 1024
2011-08-09 19:10:02,183 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:02,184 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:02,185 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 3 msecs
2011-08-09 19:10:02,185 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 6 msecs
2011-08-09 19:10:02,188 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/testBlockCorruptRecovery/file is closed by DFSClient_-505869608
2011-08-09 19:10:02,191 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:02,193 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:60395, dest: /127.0.0.1:40396, bytes: 1032, op: HDFS_READ, cliID: DFSClient_-505869608, offset: 0, srvID: DS-2083924012-10.0.62.238-60395-1312909801748, blockid: blk_-4230637966424062684_1001, duration: 266396
2011-08-09 19:10:02,201 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
MiniDFSCluster Stopping DataNode 127.0.0.1:48712 from a total of 5 datanodes.
2011-08-09 19:10:02,223 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 39 msecs
2011-08-09 19:10:02,301 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:02,402 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60182
2011-08-09 19:10:02,402 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60182: exiting
2011-08-09 19:10:02,403 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60182: exiting
2011-08-09 19:10:02,403 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60182: exiting
2011-08-09 19:10:02,404 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60182
2011-08-09 19:10:02,405 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:02,405 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:02,406 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48712, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=49210, ipcPort=60182):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:02,849 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:03,406 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:03,408 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48712, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=49210, ipcPort=60182):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:03,409 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60182
2011-08-09 19:10:03,409 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:03,409 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:03,409 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:03,410 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:10:03,547 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:03,549 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34786
2011-08-09 19:10:03,549 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:03,552 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:03,553 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:03,553 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36505 webServer.getConnectors()[0].getLocalPort() returned 36505
2011-08-09 19:10:03,553 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36505
2011-08-09 19:10:03,553 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:03,665 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36505
2011-08-09 19:10:03,680 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:03,685 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:03,687 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=52525
2011-08-09 19:10:03,688 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:03,689 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 52525: starting
2011-08-09 19:10:03,731 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 52525: starting
2011-08-09 19:10:03,731 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 52525: starting
2011-08-09 19:10:03,731 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34786, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=36505, ipcPort=52525)
2011-08-09 19:10:03,733 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 52525: starting
2011-08-09 19:10:03,735 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34786 storage DS-1956468359-10.0.62.238-48712-1312909800728
2011-08-09 19:10:03,735 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2793)) - BLOCK* NameSystem.registerDatanode: node 127.0.0.1:48712 is replaced by 127.0.0.1:34786 with the same storageID DS-1956468359-10.0.62.238-48712-1312909800728
2011-08-09 19:10:03,735 INFO  net.NetworkTopology (NetworkTopology.java:remove(350)) - Removing a node: /default-rack/127.0.0.1:48712
2011-08-09 19:10:03,736 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34786
MiniDFSCluster Stopping DataNode 127.0.0.1:46371 from a total of 5 datanodes.
2011-08-09 19:10:03,737 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34786, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=36505, ipcPort=52525)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:03,780 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:03,781 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:03,785 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:03,787 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:10:03,787 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:03,787 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:03,789 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - First Verification failed for blk_-4230637966424062684_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:03,789 WARN  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(457)) - Second Verification failed for blk_-4230637966424062684_1001. Exception : org.apache.hadoop.fs.ChecksumException: Checksum failed at 0
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:317)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:425)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyBlock(DataBlockScanner.java:433)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:493)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run(DataBlockScanner.java:591)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:03,789 INFO  datanode.DataBlockScanner (DataBlockScanner.java:handleScanFailure(345)) - Reporting bad block blk_-4230637966424062684_1001 to namenode.
2011-08-09 19:10:03,790 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:10:03,791 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-4230637966424062684 added as corrupt on 127.0.0.1:34786 by /127.0.0.1
2011-08-09 19:10:03,882 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59023
2011-08-09 19:10:03,882 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 59023: exiting
2011-08-09 19:10:03,883 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 59023
2011-08-09 19:10:03,884 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 59023: exiting
2011-08-09 19:10:03,884 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 59023: exiting
2011-08-09 19:10:03,885 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:03,885 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:03,886 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:46371, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=57587, ipcPort=59023):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:04,126 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:04,886 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:04,888 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:46371, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=57587, ipcPort=59023):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:10:04,888 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59023
2011-08-09 19:10:04,888 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:04,889 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:04,889 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:04,890 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:10:05,100 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:05,102 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 60370
2011-08-09 19:10:05,102 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:05,105 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:05,106 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:05,114 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45334 webServer.getConnectors()[0].getLocalPort() returned 45334
2011-08-09 19:10:05,115 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45334
2011-08-09 19:10:05,115 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:05,189 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45334
2011-08-09 19:10:05,190 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:05,196 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:05,198 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=59352
2011-08-09 19:10:05,199 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:05,219 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 59352: starting
2011-08-09 19:10:05,219 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352)
2011-08-09 19:10:05,244 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 59352: starting
2011-08-09 19:10:05,244 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 59352: starting
2011-08-09 19:10:05,243 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 59352: starting
2011-08-09 19:10:05,247 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:60370 storage DS-603528220-10.0.62.238-46371-1312909802104
2011-08-09 19:10:05,247 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2793)) - BLOCK* NameSystem.registerDatanode: node 127.0.0.1:46371 is replaced by 127.0.0.1:60370 with the same storageID DS-603528220-10.0.62.238-46371-1312909802104
2011-08-09 19:10:05,248 INFO  net.NetworkTopology (NetworkTopology.java:remove(350)) - Removing a node: /default-rack/127.0.0.1:46371
2011-08-09 19:10:05,248 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:60370
2011-08-09 19:10:05,249 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:10:05,251 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:05,252 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 30msec Initial delay: 0msec
2011-08-09 19:10:05,300 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:60370, dest: /127.0.0.1:55494, bytes: 1032, op: HDFS_READ, cliID: DFSClient_-505869608, offset: 0, srvID: DS-603528220-10.0.62.238-46371-1312909802104, blockid: blk_-4230637966424062684_1001, duration: 516297
2011-08-09 19:10:05,300 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(327)) - Looping until expected 2 are reported. Current reported 1
2011-08-09 19:10:05,300 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352):DataXceiver
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.updateScanStatus(DataBlockScanner.java:309)
	at org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.verifiedByClient(DataBlockScanner.java:303)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:214)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:112)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:10:05,301 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:05,303 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:10:05,303 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:05,304 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:05,305 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_-4230637966424062684_1001
2011-08-09 19:10:06,302 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:06,305 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:60395, dest: /127.0.0.1:40398, bytes: 1032, op: HDFS_READ, cliID: DFSClient_-505869608, offset: 0, srvID: DS-2083924012-10.0.62.238-60395-1312909801748, blockid: blk_-4230637966424062684_1001, duration: 328450
2011-08-09 19:10:06,319 INFO  fs.FSInputChecker (FSInputChecker.java:readChecksumChunk(247)) - Found checksum error: b[0, 512]=60b420bb3851d9d47acb933dbe70399bf6c92da33af01d4fb770e98c0325f41d3ebaf8986da712c82bcd4d554bf0b54023c29b624de9424144424144580f9afb081b12e107b1e805f2b4f5f0f1d00c2d0f62634670921c505867ff20f6a8335e98af8725385586b41feff205b4e05a000823f78b5f8f5c02439ce8f67a781d90cbe6bf1ae7f2bc40a49709a06c0e31499bf02969ca42d203e566bcc696de08fa0102a0fd2e2330b0964abb7c443020de1cad09bfd6381ffb94daafbb90c4ed91a0613ad1dc4b4703af84c1d63b1a876921c6d5869d61ccb98ed13ae6c09a13fc91e14922f301cf8bcf934315a6049d2f07d983faa91b8f4e7265ecb815a7cbabc1450cb72b3c74107717aa24ac42f25b6c6784767d0e3546c4f7250191a3b6aaa2b64d126e5583b04c113259c948e1d0b39bb9560cd5409b6ecafedbc8acafeea74db7f85adf94be9a85a1dd4b03aa88831dd29c4078810b3a28d22d6680b64fcbb1b237c2441234ceabbfdad87c311548f6790274b92e6a591d3ab1a60b73400bc474c52d3cbcf2fbae72b6e6d49fb0b1851336fa2c540cdfbf78c8db492c65e75b01f2560a9dc456fea4034286569e3086ea649724959c440892daeb724c06e5133ac9aa9410eeba2d54fe8afdf8507d2113e2026a937ae439982bce79cc240e264af6cd43cc3025666bb9b37f81e7141567ad68c9824980dbeccd14db20a8
org.apache.hadoop.fs.ChecksumException: Checksum error: /blk_-4230637966424062684:of:/tmp/testBlockCorruptRecovery/file at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:277)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:241)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:189)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at org.apache.hadoop.hdfs.DFSClient$BlockReader.read(DFSClient.java:1659)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.readBuffer(DFSClient.java:2256)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:2306)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:47)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:85)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.blockCorruptionRecoveryPolicy(TestDatanodeBlockScanner.java:322)
	at org.apache.hadoop.hdfs.TestDatanodeBlockScanner.testBlockCorruptionRecoveryPolicy(TestDatanodeBlockScanner.java:258)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:10:06,319 WARN  hdfs.DFSClient (DFSClient.java:readBuffer(2258)) - Found Checksum error for blk_-4230637966424062684_1001 from 127.0.0.1:60395 at 0
2011-08-09 19:10:06,321 INFO  hdfs.StateChange (NameNode.java:reportBadBlocks(607)) - *DIR* NameNode.reportBadBlocks
2011-08-09 19:10:06,323 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-4230637966424062684 added as corrupt on 127.0.0.1:60395 by /127.0.0.1
2011-08-09 19:10:06,334 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(327)) - Looping until expected 2 are reported. Current reported 1
2011-08-09 19:10:06,335 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:60370, dest: /127.0.0.1:55496, bytes: 1032, op: HDFS_READ, cliID: DFSClient_-505869608, offset: 0, srvID: DS-603528220-10.0.62.238-46371-1312909802104, blockid: blk_-4230637966424062684_1001, duration: 1497175
2011-08-09 19:10:07,336 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:07,337 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:08,338 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:08,339 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:09,341 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:09,342 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:10,343 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:10,344 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:11,345 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:11,346 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:12,380 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:12,383 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:13,385 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:13,386 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:14,387 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:14,387 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:15,389 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:15,389 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:16,390 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:16,393 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:17,394 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:17,395 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:18,396 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:18,396 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:19,398 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:19,398 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:20,399 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:20,400 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:21,401 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:21,402 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:22,403 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:22,403 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:23,404 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:23,405 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:24,406 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:24,407 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:25,408 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:25,409 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:26,410 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:26,411 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:27,412 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:27,413 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:28,414 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:28,415 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:29,416 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:29,417 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:30,186 INFO  hdfs.StateChange (FSNamesystem.java:computeReplicationWorkForBlock(3344)) - BLOCK* ask 127.0.0.1:60370 to replicate blk_-4230637966424062684_1001 to datanode(s) 127.0.0.1:58844 127.0.0.1:56702
2011-08-09 19:10:30,418 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:30,418 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:31,116 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:31,121 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:56702 0 blocks shortCircuit first report.
2011-08-09 19:10:31,122 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 6 msecs
2011-08-09 19:10:31,420 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:31,420 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:31,436 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:31,438 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:58844 0 blocks shortCircuit first report.
2011-08-09 19:10:31,438 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:10:31,763 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:31,764 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:10:32,421 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:32,422 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:33,423 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:33,429 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:33,781 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:33,782 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 2 msecs
2011-08-09 19:10:34,430 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
2011-08-09 19:10:34,430 INFO  hdfs.TestDatanodeBlockScanner (TestDatanodeBlockScanner.java:blockCorruptionRecoveryPolicy(342)) - Looping until block gets rereplicated to 3
2011-08-09 19:10:35,254 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:35,256 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 3 msecs
2011-08-09 19:10:35,259 INFO  datanode.DataNode (DataNode.java:transferBlock(1038)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352) Starting thread to transfer block blk_-4230637966424062684_1001 to 127.0.0.1:58844 127.0.0.1:56702 
2011-08-09 19:10:35,260 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4230637966424062684_1001 src: /127.0.0.1:43755 dest: /127.0.0.1:58844
2011-08-09 19:10:35,261 INFO  datanode.DataNode (DataNode.java:run(1249)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352):Transmitted block blk_-4230637966424062684_1001 to /127.0.0.1:58844
2011-08-09 19:10:35,263 INFO  datanode.DataNode (DataXceiver.java:writeBlock(393)) - Received block blk_-4230637966424062684_1001 src: /127.0.0.1:43755 dest: /127.0.0.1:58844 of size 1024
2011-08-09 19:10:35,265 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:58844 is added to blk_-4230637966424062684_1001 size 1024
2011-08-09 19:10:35,265 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:35,266 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4230637966424062684_1001 src: /127.0.0.1:48385 dest: /127.0.0.1:56702
2011-08-09 19:10:35,266 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
2011-08-09 19:10:35,268 INFO  datanode.DataNode (DataXceiver.java:writeBlock(393)) - Received block blk_-4230637966424062684_1001 src: /127.0.0.1:48385 dest: /127.0.0.1:56702 of size 1024
2011-08-09 19:10:35,268 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56702 is added to blk_-4230637966424062684_1001 size 1024
2011-08-09 19:10:35,268 INFO  hdfs.StateChange (FSNamesystem.java:invalidateBlock(2105)) - DIR* NameSystem.invalidateBlock: blk_-4230637966424062684_1001 on 127.0.0.1:34786
2011-08-09 19:10:35,269 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-4230637966424062684 is added to invalidSet of 127.0.0.1:34786
2011-08-09 19:10:35,269 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 9 on 54630, call blockReceived(DatanodeRegistration(127.0.0.1:56702, storageID=DS-992104614-10.0.62.238-56702-1312909801102, infoPort=47550, ipcPort=53836), [Lorg.apache.hadoop.hdfs.protocol.Block;@4f8f104, [Ljava.lang.String;@73974028) from 127.0.0.1:53613: error: java.io.IOException: java.util.ConcurrentModificationException
java.io.IOException: java.util.ConcurrentModificationException
	at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
	at java.util.TreeMap$KeyIterator.next(TreeMap.java:1154)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateCorruptReplicas(FSNamesystem.java:3996)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock(FSNamesystem.java:3971)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.blockReceived(FSNamesystem.java:4443)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.blockReceived(NameNode.java:998)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:10:35,271 WARN  datanode.DataNode (DataNode.java:offerService(892)) - org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.util.ConcurrentModificationException
	at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
	at java.util.TreeMap$KeyIterator.next(TreeMap.java:1154)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.invalidateCorruptReplicas(FSNamesystem.java:3996)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.addStoredBlock(FSNamesystem.java:3971)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.blockReceived(FSNamesystem.java:4443)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.blockReceived(NameNode.java:998)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.blockReceived(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:814)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1282)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:35,272 WARN  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3897)) - BLOCK* NameSystem.addStoredBlock: Redundant addStoredBlock request received for blk_-4230637966424062684_1001 on 127.0.0.1:56702 size 1024
2011-08-09 19:10:35,273 INFO  hdfs.StateChange (FSNamesystem.java:invalidateBlock(2105)) - DIR* NameSystem.invalidateBlock: blk_-4230637966424062684_1001 on 127.0.0.1:60395
2011-08-09 19:10:35,273 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-4230637966424062684 is added to invalidSet of 127.0.0.1:60395
2011-08-09 19:10:35,273 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:35,275 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 1 msecs
2011-08-09 19:10:35,431 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/tmp/testBlockCorruptRecovery/file	dst=null	perm=null
Shutting down the Mini HDFS Cluster
Shutting down DataNode 4
2011-08-09 19:10:35,449 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:35,549 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59352
2011-08-09 19:10:35,550 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 59352: exiting
2011-08-09 19:10:35,552 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:35,552 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:35,553 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:35,553 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 59352
2011-08-09 19:10:35,553 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 59352: exiting
2011-08-09 19:10:35,553 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 59352: exiting
2011-08-09 19:10:36,308 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:36,553 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:36,553 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:60370, storageID=DS-603528220-10.0.62.238-46371-1312909802104, infoPort=45334, ipcPort=59352):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:10:36,554 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59352
2011-08-09 19:10:36,554 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:36,555 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:36,555 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:36,556 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 3
2011-08-09 19:10:36,559 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:36,660 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52525
2011-08-09 19:10:36,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 52525: exiting
2011-08-09 19:10:36,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 52525: exiting
2011-08-09 19:10:36,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 52525: exiting
2011-08-09 19:10:36,661 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 52525
2011-08-09 19:10:36,663 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34786, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=36505, ipcPort=52525):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:36,663 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:36,663 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:36,664 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:36,664 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34786, storageID=DS-1956468359-10.0.62.238-48712-1312909800728, infoPort=36505, ipcPort=52525):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:36,665 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52525
2011-08-09 19:10:36,665 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:36,665 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:36,666 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:36,666 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 2
2011-08-09 19:10:36,677 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:36,777 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45863
2011-08-09 19:10:36,778 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45863: exiting
2011-08-09 19:10:36,778 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45863: exiting
2011-08-09 19:10:36,779 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45863: exiting
2011-08-09 19:10:36,780 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45863
2011-08-09 19:10:36,781 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:36,781 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 2
2011-08-09 19:10:36,781 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:60395, storageID=DS-2083924012-10.0.62.238-60395-1312909801748, infoPort=33596, ipcPort=45863):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:36,783 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:37,781 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:37,783 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:60395, storageID=DS-2083924012-10.0.62.238-60395-1312909801748, infoPort=33596, ipcPort=45863):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
2011-08-09 19:10:37,783 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45863
2011-08-09 19:10:37,783 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:37,784 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:37,784 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:37,785 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:10:37,788 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:37,789 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60166
2011-08-09 19:10:37,790 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60166: exiting
2011-08-09 19:10:37,790 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60166: exiting
2011-08-09 19:10:37,790 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60166: exiting
2011-08-09 19:10:37,790 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60166
2011-08-09 19:10:37,792 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-1088246885-10.0.62.238-58844-1312909801383, infoPort=40699, ipcPort=60166):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:37,792 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:37,794 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:37,794 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:37,795 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-1088246885-10.0.62.238-58844-1312909801383, infoPort=40699, ipcPort=60166):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:10:37,795 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60166
2011-08-09 19:10:37,795 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:37,796 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:37,796 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:37,797 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:10:37,815 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:37,817 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53836
2011-08-09 19:10:37,817 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53836: exiting
2011-08-09 19:10:37,818 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53836: exiting
2011-08-09 19:10:37,818 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53836: exiting
2011-08-09 19:10:37,819 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53836
2011-08-09 19:10:37,820 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:37,820 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:37,821 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:56702, storageID=DS-992104614-10.0.62.238-56702-1312909801102, infoPort=47550, ipcPort=53836):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:38,131 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:38,821 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:38,822 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:56702, storageID=DS-992104614-10.0.62.238-56702-1312909801102, infoPort=47550, ipcPort=53836):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:10:38,822 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53836
2011-08-09 19:10:38,822 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:38,823 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:38,823 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:38,824 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:10:38,827 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:38,928 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:10:38,928 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:10:38,929 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:10:38,932 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54630
2011-08-09 19:10:38,932 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54630: exiting
2011-08-09 19:10:38,933 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 54630: exiting
2011-08-09 19:10:38,933 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 54630: exiting
2011-08-09 19:10:38,933 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 54630: exiting
2011-08-09 19:10:38,934 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54630
2011-08-09 19:10:38,934 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 54630: exiting
2011-08-09 19:10:38,934 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 54630: exiting
2011-08-09 19:10:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 54630: exiting
2011-08-09 19:10:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 54630: exiting
2011-08-09 19:10:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54630: exiting
2011-08-09 19:10:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54630: exiting
2011-08-09 19:10:38,936 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:38,961 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:10:38,961 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:10:38,961 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:10:38,961 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:10:38,968 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:10:38,968 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:10:38,969 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:10:38,969 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:10:38,978 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:10:38,978 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:38,990 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:10:38,993 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:10:38,993 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:39,039 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:10:39,040 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:10:39,044 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:10:39,044 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:10:39,044 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:10:39,044 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:10:39,045 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:10:39,049 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:10:39,049 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:10:39,049 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:10:39,049 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:10:39,199 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:10:39,200 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:10:39,200 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:10:39,205 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:10:39,205 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:10:39,205 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:10:39,206 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:10:39,206 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:39,207 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:39,208 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:10:39,208 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 159 msecs
2011-08-09 19:10:39,208 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:10:39,212 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:10:39,212 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:10:39,212 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:10:39,213 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:10:39,213 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:10:39,214 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:39,216 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=38165
2011-08-09 19:10:39,217 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:38165
2011-08-09 19:10:39,217 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:39,217 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 38165: starting
2011-08-09 19:10:39,218 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 38165: starting
2011-08-09 19:10:39,218 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 38165: starting
2011-08-09 19:10:39,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 38165: starting
2011-08-09 19:10:39,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 38165: starting
2011-08-09 19:10:39,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 38165: starting
2011-08-09 19:10:39,228 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:10:39,229 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:10:39,229 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:10:39,229 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:10:39,271 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:10:39,272 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:39,273 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:39,273 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 38420 webServer.getConnectors()[0].getLocalPort() returned 38420
2011-08-09 19:10:39,273 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 38420
2011-08-09 19:10:39,274 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:39,329 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:38420
2011-08-09 19:10:39,329 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:38420
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:10:39,351 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:10:39,352 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:39,368 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:10:39,368 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:39,558 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:39,560 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 52706
2011-08-09 19:10:39,560 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:39,563 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:39,564 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:39,564 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36888 webServer.getConnectors()[0].getLocalPort() returned 36888
2011-08-09 19:10:39,564 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36888
2011-08-09 19:10:39,564 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:39,634 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36888
2011-08-09 19:10:39,635 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:39,640 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:39,643 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=38482
2011-08-09 19:10:39,644 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:39,644 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 38482: starting
2011-08-09 19:10:39,646 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 38482: starting
2011-08-09 19:10:39,645 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 38482: starting
2011-08-09 19:10:39,645 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:52706, storageID=, infoPort=36888, ipcPort=38482)
2011-08-09 19:10:39,645 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 38482: starting
2011-08-09 19:10:39,653 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:52706 storage DS-87209568-10.0.62.238-52706-1312909839650
2011-08-09 19:10:39,654 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:52706
2011-08-09 19:10:39,659 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-87209568-10.0.62.238-52706-1312909839650 is assigned to data-node 127.0.0.1:52706
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:10:39,661 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:52706, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=36888, ipcPort=38482)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:39,662 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:10:39,667 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:10:39,667 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:39,683 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:39,685 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:52706 0 blocks shortCircuit first report.
2011-08-09 19:10:39,685 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:10:39,686 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:39,688 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:39,698 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:10:39,699 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:39,840 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:39,842 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53407
2011-08-09 19:10:39,842 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:39,845 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:39,845 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:39,846 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 55062 webServer.getConnectors()[0].getLocalPort() returned 55062
2011-08-09 19:10:39,846 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 55062
2011-08-09 19:10:39,846 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:39,959 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:55062
2011-08-09 19:10:39,961 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:39,965 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:39,968 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=40447
2011-08-09 19:10:39,969 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:39,970 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40447: starting
2011-08-09 19:10:39,991 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40447: starting
2011-08-09 19:10:39,992 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40447: starting
2011-08-09 19:10:39,993 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53407, storageID=, infoPort=55062, ipcPort=40447)
2011-08-09 19:10:39,993 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40447: starting
2011-08-09 19:10:39,999 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53407 storage DS-737660342-10.0.62.238-53407-1312909839997
2011-08-09 19:10:40,000 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53407
2011-08-09 19:10:40,006 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-737660342-10.0.62.238-53407-1312909839997 is assigned to data-node 127.0.0.1:53407
2011-08-09 19:10:40,007 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53407, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=55062, ipcPort=40447)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:10:40,009 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:10:40,017 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:40,020 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53407 0 blocks shortCircuit first report.
2011-08-09 19:10:40,021 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 5 msecs
2011-08-09 19:10:40,021 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:40,022 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:40,040 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:10:40,046 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:10:40,051 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /file1. blk_8271303234646508575_1001
2011-08-09 19:10:40,053 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8271303234646508575_1001 src: /127.0.0.1:41376 dest: /127.0.0.1:53407
2011-08-09 19:10:40,056 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8271303234646508575_1001 src: /127.0.0.1:60517 dest: /127.0.0.1:52706
2011-08-09 19:10:40,061 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:60517, dest: /127.0.0.1:52706, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_-82069149, offset: 0, srvID: DS-87209568-10.0.62.238-52706-1312909839650, blockid: blk_8271303234646508575_1001, duration: 2506199
2011-08-09 19:10:40,061 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_8271303234646508575_1001 terminating
2011-08-09 19:10:40,065 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:52706 is added to blk_8271303234646508575_1001 size 1
2011-08-09 19:10:40,063 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:41376, dest: /127.0.0.1:53407, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_-82069149, offset: 0, srvID: DS-737660342-10.0.62.238-53407-1312909839997, blockid: blk_8271303234646508575_1001, duration: 3813246
2011-08-09 19:10:40,067 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_8271303234646508575_1001 terminating
2011-08-09 19:10:40,109 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53407 is added to blk_8271303234646508575_1001 size 1
2011-08-09 19:10:40,113 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /file1 is closed by DFSClient_-82069149
2011-08-09 19:10:40,117 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
2011-08-09 19:10:40,121 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
2011-08-09 19:10:40,131 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:52706, dest: /127.0.0.1:60518, bytes: 5, op: HDFS_READ, cliID: DFSClient_-82069149, offset: 0, srvID: DS-87209568-10.0.62.238-52706-1312909839650, blockid: blk_8271303234646508575_1001, duration: 528018
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:10:40,255 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:40,356 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40447
2011-08-09 19:10:40,356 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40447: exiting
2011-08-09 19:10:40,357 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40447: exiting
2011-08-09 19:10:40,356 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40447: exiting
2011-08-09 19:10:40,357 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40447
2011-08-09 19:10:40,361 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53407, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=55062, ipcPort=40447):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:40,361 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:40,361 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:40,362 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:40,362 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53407, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=55062, ipcPort=40447):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:10:40,363 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40447
2011-08-09 19:10:40,363 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:40,363 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:40,364 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:40,365 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:10:40,456 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:40,557 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38482
2011-08-09 19:10:40,557 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 38482: exiting
2011-08-09 19:10:40,557 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 38482: exiting
2011-08-09 19:10:40,558 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 38482
2011-08-09 19:10:40,558 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 38482: exiting
2011-08-09 19:10:40,559 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:40,560 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:40,560 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:52706, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=36888, ipcPort=38482):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:40,690 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:41,560 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:41,561 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:52706, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=36888, ipcPort=38482):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:41,561 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38482
2011-08-09 19:10:41,562 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:41,562 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:41,562 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:41,563 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:10:41,752 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:41,853 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:10:41,854 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:10:41,854 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:10:41,857 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38165
2011-08-09 19:10:41,858 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 38165: exiting
2011-08-09 19:10:41,858 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 38165: exiting
2011-08-09 19:10:41,858 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 38165: exiting
2011-08-09 19:10:41,858 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 38165: exiting
2011-08-09 19:10:41,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 38165: exiting
2011-08-09 19:10:41,860 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 38165
2011-08-09 19:10:41,863 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:41,864 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:10:41,867 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:10:41,867 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:10:41,867 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:10:41,867 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:10:41,867 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:10:41,873 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:10:41,873 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:10:41,873 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:10:41,873 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:10:41,877 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:10:41,877 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:10:41,877 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:10:41,882 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:10:41,882 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:10:41,882 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:10:41,883 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 237 edits # 3 loaded in 0 seconds.
2011-08-09 19:10:41,884 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:41,929 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:41,933 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:41,938 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:41,945 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 175 saved in 0 seconds.
2011-08-09 19:10:41,945 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:42,001 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 175 saved in 0 seconds.
2011-08-09 19:10:42,001 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:42,006 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:42,006 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:10:42,024 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:10:42,024 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 151 msecs
2011-08-09 19:10:42,024 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:10:42,027 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 1
2011-08-09 19:10:42,028 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:10:42,028 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:10:42,028 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:10:42,029 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 1.Safe mode will be turned off automatically.
2011-08-09 19:10:42,029 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:10:42,058 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:10:42,060 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:42,063 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=48138
2011-08-09 19:10:42,063 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:48138
2011-08-09 19:10:42,063 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:42,064 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48138: starting
2011-08-09 19:10:42,065 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48138: starting
2011-08-09 19:10:42,065 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48138: starting
2011-08-09 19:10:42,065 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48138: starting
2011-08-09 19:10:42,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 48138: starting
2011-08-09 19:10:42,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 48138: starting
2011-08-09 19:10:42,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 48138: starting
2011-08-09 19:10:42,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 48138: starting
2011-08-09 19:10:42,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 48138: starting
2011-08-09 19:10:42,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 48138: starting
2011-08-09 19:10:42,115 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 48138: starting
2011-08-09 19:10:42,163 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:10:42,165 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:42,165 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:42,166 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 38158 webServer.getConnectors()[0].getLocalPort() returned 38158
2011-08-09 19:10:42,166 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 38158
2011-08-09 19:10:42,166 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:42,225 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:38158
2011-08-09 19:10:42,226 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:38158
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:10:42,438 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:42,439 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 51667
2011-08-09 19:10:42,440 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:42,442 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:42,443 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:42,450 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 53071 webServer.getConnectors()[0].getLocalPort() returned 53071
2011-08-09 19:10:42,451 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 53071
2011-08-09 19:10:42,451 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:42,677 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:53071
2011-08-09 19:10:42,678 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:42,683 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:42,685 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=45706
2011-08-09 19:10:42,686 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:42,686 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45706: starting
2011-08-09 19:10:42,687 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45706: starting
2011-08-09 19:10:42,688 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45706: starting
2011-08-09 19:10:42,688 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:51667, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=53071, ipcPort=45706)
2011-08-09 19:10:42,688 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45706: starting
2011-08-09 19:10:42,690 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:51667 storage DS-87209568-10.0.62.238-52706-1312909839650
2011-08-09 19:10:42,690 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:51667
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:10:42,692 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:51667, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=53071, ipcPort=45706)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:42,693 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:10:42,697 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:42,699 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:51667 1 blocks shortCircuit first report.
2011-08-09 19:10:42,700 WARN  namenode.FSNamesystem (FSNamesystem.java:addStoredBlock(3816)) - Inconsistent size for block blk_8271303234646508575_1001 reported from 127.0.0.1:51667 current size is 1 reported size is 0
2011-08-09 19:10:42,700 WARN  namenode.FSNamesystem (FSNamesystem.java:addStoredBlock(3824)) - Mark new replica blk_8271303234646508575_1001 from 127.0.0.1:51667as corrupt because its length is shorter than existing ones
2011-08-09 19:10:42,701 INFO  hdfs.StateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(53)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_8271303234646508575 added as corrupt on 127.0.0.1:51667 by /127.0.0.1
2011-08-09 19:10:42,701 INFO  namenode.FSNamesystem (FSNamesystem.java:processReport(3715)) - BLOCK* NameSystem.processReport:1 data nodes reporting, 0/1 blocks safe (0.0)
2011-08-09 19:10:42,702 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 6 msecs
2011-08-09 19:10:42,702 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:42,705 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:42,872 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:42,874 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 60816
2011-08-09 19:10:42,874 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:42,877 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:42,878 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:42,885 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40222 webServer.getConnectors()[0].getLocalPort() returned 40222
2011-08-09 19:10:42,885 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40222
2011-08-09 19:10:42,885 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:42,965 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40222
2011-08-09 19:10:42,967 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:42,972 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:42,974 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34042
2011-08-09 19:10:42,976 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:43,023 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34042: starting
2011-08-09 19:10:43,024 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34042: starting
2011-08-09 19:10:43,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34042: starting
2011-08-09 19:10:43,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34042: starting
2011-08-09 19:10:43,068 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042)
2011-08-09 19:10:43,071 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:60816 storage DS-737660342-10.0.62.238-53407-1312909839997
2011-08-09 19:10:43,072 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:60816
2011-08-09 19:10:43,076 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:10:43,078 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:10:43,088 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:43,091 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:60816 1 blocks shortCircuit first report.
2011-08-09 19:10:43,092 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 1 secs.
2011-08-09 19:10:43,092 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:10:43,093 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 2 datanodes
2011-08-09 19:10:43,093 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:10:43,094 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 1 blocks got processed in 7 msecs
2011-08-09 19:10:43,094 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:43,095 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:43,096 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_8271303234646508575_1001
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:10:44,099 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:10:44,100 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:44,117 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:10:44,117 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:10:44,260 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:10:44,261 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 55257
2011-08-09 19:10:44,262 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:10:44,265 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:10:44,265 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:10:44,266 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48790 webServer.getConnectors()[0].getLocalPort() returned 48790
2011-08-09 19:10:44,266 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48790
2011-08-09 19:10:44,266 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:10:44,339 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48790
2011-08-09 19:10:44,340 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:10:44,345 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:10:44,348 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=48672
2011-08-09 19:10:44,349 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:10:44,350 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48672: starting
2011-08-09 19:10:44,364 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48672: starting
2011-08-09 19:10:44,364 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48672: starting
2011-08-09 19:10:44,364 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48672: starting
2011-08-09 19:10:44,365 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:55257, storageID=, infoPort=48790, ipcPort=48672)
2011-08-09 19:10:44,371 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:55257 storage DS-37883815-10.0.62.238-55257-1312909844369
2011-08-09 19:10:44,372 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:55257
2011-08-09 19:10:44,379 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-37883815-10.0.62.238-55257-1312909844369 is assigned to data-node 127.0.0.1:55257
2011-08-09 19:10:44,380 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:55257, storageID=DS-37883815-10.0.62.238-55257-1312909844369, infoPort=48790, ipcPort=48672)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:10:44,381 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:10:44,384 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:44,386 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:55257 0 blocks shortCircuit first report.
2011-08-09 19:10:44,386 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:10:44,387 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:10:44,388 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:10:44,403 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:44,507 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:44,610 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:44,712 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:44,815 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:44,917 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,020 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,061 INFO  hdfs.StateChange (FSNamesystem.java:computeReplicationWorkForBlock(3344)) - BLOCK* ask 127.0.0.1:60816 to replicate blk_8271303234646508575_1001 to datanode(s) 127.0.0.1:55257
2011-08-09 19:10:45,123 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,225 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,327 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,429 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,531 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,634 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,739 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,841 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:45,943 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:46,046 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
File /file1 has replication factor 1
Waiting for replication factor to drain
2011-08-09 19:10:46,081 INFO  datanode.DataNode (DataNode.java:transferBlock(1038)) - DatanodeRegistration(127.0.0.1:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042) Starting thread to transfer block blk_8271303234646508575_1001 to 127.0.0.1:55257 
2011-08-09 19:10:46,083 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8271303234646508575_1001 src: /127.0.0.1:59888 dest: /127.0.0.1:55257
2011-08-09 19:10:46,083 INFO  datanode.DataNode (DataNode.java:run(1249)) - DatanodeRegistration(127.0.0.1:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042):Transmitted block blk_8271303234646508575_1001 to /127.0.0.1:55257
2011-08-09 19:10:46,085 INFO  datanode.DataNode (DataXceiver.java:writeBlock(393)) - Received block blk_8271303234646508575_1001 src: /127.0.0.1:59888 dest: /127.0.0.1:55257 of size 1
2011-08-09 19:10:46,087 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:55257 is added to blk_8271303234646508575_1001 size 1
2011-08-09 19:10:46,087 INFO  hdfs.StateChange (FSNamesystem.java:invalidateBlock(2105)) - DIR* NameSystem.invalidateBlock: blk_8271303234646508575_1001 on 127.0.0.1:51667
2011-08-09 19:10:46,088 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_8271303234646508575 is added to invalidSet of 127.0.0.1:51667
2011-08-09 19:10:46,151 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/file1	dst=null	perm=null
2011-08-09 19:10:48,061 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:51667 to delete  blk_8271303234646508575_1001
2011-08-09 19:10:48,699 INFO  datanode.DataNode (FSDatasetAsyncDiskService.java:deleteAsync(147)) - Scheduling block blk_8271303234646508575_1001 file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_8271303234646508575 for deletion
2011-08-09 19:10:48,701 INFO  datanode.DataNode (FSDatasetAsyncDiskService.java:run(193)) - Deleted block blk_8271303234646508575_1001 at file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_8271303234646508575
Shutting down the Mini HDFS Cluster
Shutting down DataNode 2
2011-08-09 19:10:48,777 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:48,879 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48672
2011-08-09 19:10:48,879 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48672: exiting
2011-08-09 19:10:48,879 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48672: exiting
2011-08-09 19:10:48,879 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 48672
2011-08-09 19:10:48,880 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48672: exiting
2011-08-09 19:10:48,880 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:55257, storageID=DS-37883815-10.0.62.238-55257-1312909844369, infoPort=48790, ipcPort=48672):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:48,880 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:48,881 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:48,882 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:48,882 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:55257, storageID=DS-37883815-10.0.62.238-55257-1312909844369, infoPort=48790, ipcPort=48672):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:10:48,883 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48672
2011-08-09 19:10:48,883 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:48,883 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:48,884 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:48,884 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:10:48,921 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:49,021 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34042
2011-08-09 19:10:49,021 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34042: exiting
2011-08-09 19:10:49,022 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34042: exiting
2011-08-09 19:10:49,022 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34042
2011-08-09 19:10:49,022 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34042: exiting
2011-08-09 19:10:49,024 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:49,024 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:49,024 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:49,025 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:49,025 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:60816, storageID=DS-737660342-10.0.62.238-53407-1312909839997, infoPort=40222, ipcPort=34042):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:10:49,025 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34042
2011-08-09 19:10:49,026 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:49,026 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:49,026 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:49,028 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:10:49,081 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:49,181 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45706
2011-08-09 19:10:49,182 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45706: exiting
2011-08-09 19:10:49,182 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45706: exiting
2011-08-09 19:10:49,182 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45706: exiting
2011-08-09 19:10:49,183 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45706
2011-08-09 19:10:49,184 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:10:49,184 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:51667, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=53071, ipcPort=45706):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:10:49,185 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:10:49,185 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:10:49,185 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:51667, storageID=DS-87209568-10.0.62.238-52706-1312909839650, infoPort=53071, ipcPort=45706):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:10:49,186 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45706
2011-08-09 19:10:49,186 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:10:49,187 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:10:49,187 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:10:49,188 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:10:49,213 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:10:49,214 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:10:49,214 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:10:49,215 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:10:49,222 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48138
2011-08-09 19:10:49,222 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 48138: exiting
2011-08-09 19:10:49,222 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 48138: exiting
2011-08-09 19:10:49,223 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 48138: exiting
2011-08-09 19:10:49,224 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 48138: exiting
2011-08-09 19:10:49,224 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 48138: exiting
2011-08-09 19:10:49,225 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
------------- ---------------- ---------------
------------- Standard Error -----------------
Waiting for the Mini HDFS Cluster to start...
------------- ---------------- ---------------

Testcase: testDatanodeBlockScanner took 376.52 sec
Testcase: testBlockCorruptionPolicy took 10.206 sec
Testcase: testBlockCorruptionRecoveryPolicy took 73.684 sec
Testcase: testTruncatedBlockReport took 10.288 sec
