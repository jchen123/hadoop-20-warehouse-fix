Testsuite: org.apache.hadoop.hdfs.TestFileCreation
Tests run: 11, Failures: 0, Errors: 0, Time elapsed: 86.897 sec
------------- Standard Output ---------------
2011-08-09 19:23:24,361 WARN  conf.Configuration (Configuration.java:<clinit>(191)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2011-08-09 19:23:24,661 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:24,664 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:24,664 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:24,665 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:24,698 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:24,698 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:24,699 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:24,822 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:24,935 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:24,938 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:24,944 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:24,944 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:24,945 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:24,988 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:23:24,992 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:24,992 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:24,993 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:24,993 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:24,993 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:25,005 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:23:25,023 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 19:23:25,099 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:25,100 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:25,100 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:25,100 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:25,103 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:25,174 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:23:25,175 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:25,175 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:25,176 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:25,202 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:25,203 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:23:25,212 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:25,220 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:23:25,220 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:23:25,221 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:23:25,223 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:23:25,224 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:25,225 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:25,232 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:23:25,232 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 59 msecs
2011-08-09 19:23:25,234 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:23:25,244 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:23:25,245 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:23:25,245 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:23:25,245 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:23:25,246 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:23:25,271 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:25,275 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=34722
2011-08-09 19:23:25,279 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:34722
2011-08-09 19:23:25,280 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:25,282 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34722: starting
2011-08-09 19:23:25,282 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34722: starting
2011-08-09 19:23:25,282 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34722: starting
2011-08-09 19:23:25,312 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34722: starting
2011-08-09 19:23:25,313 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 34722: starting
2011-08-09 19:23:25,313 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 34722: starting
2011-08-09 19:23:25,313 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 34722: starting
2011-08-09 19:23:25,314 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 34722: starting
2011-08-09 19:23:25,315 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 34722: starting
2011-08-09 19:23:25,315 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 34722: starting
2011-08-09 19:23:25,318 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 34722: starting
2011-08-09 19:23:25,450 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:23:25,452 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:23:25,452 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:23:25,452 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:23:25,455 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:23:25,460 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:23:25,571 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 19:23:25,646 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:25,655 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:25,655 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34583 webServer.getConnectors()[0].getLocalPort() returned 34583
2011-08-09 19:23:25,656 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34583
2011-08-09 19:23:25,656 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:26,116 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34583
2011-08-09 19:23:26,117 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:34583
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:23:26,197 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:23:26,197 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:26,221 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:23:26,222 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:26,438 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:23:26,441 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34900
2011-08-09 19:23:26,445 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:23:26,456 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:26,461 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:26,462 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 53110 webServer.getConnectors()[0].getLocalPort() returned 53110
2011-08-09 19:23:26,462 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 53110
2011-08-09 19:23:26,463 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:26,657 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:53110
2011-08-09 19:23:26,660 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:23:26,700 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:26,709 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36642
2011-08-09 19:23:26,711 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:26,712 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36642: starting
2011-08-09 19:23:26,712 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36642: starting
2011-08-09 19:23:26,713 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36642: starting
2011-08-09 19:23:26,713 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34900, storageID=, infoPort=53110, ipcPort=36642)
2011-08-09 19:23:26,715 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36642: starting
2011-08-09 19:23:26,771 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34900 storage DS-1131686092-10.0.62.238-34900-1312910606767
2011-08-09 19:23:26,775 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34900
2011-08-09 19:23:26,781 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1131686092-10.0.62.238-34900-1312910606767 is assigned to data-node 127.0.0.1:34900
2011-08-09 19:23:26,783 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34900, storageID=DS-1131686092-10.0.62.238-34900-1312910606767, infoPort=53110, ipcPort=36642)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:26,784 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:23:26,789 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:23:26,791 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:34900 0 blocks shortCircuit first report.
2011-08-09 19:23:26,792 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:23:26,792 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:23:26,793 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
Path : "/"
true
2011-08-09 19:23:26,809 DEBUG hdfs.DFSClient (DFSClient.java:mkdirs(1383)) - /test_dir: masked=rwxr-xr-x
2011-08-09 19:23:26,812 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 9, 47, 116, 101, 115, 116, 95, 100, 105, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 49, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,813 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 9, 47, 116, 101, 115, 116, 95, 100, 105, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 49, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,814 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:26,814 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:26,814 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 57
2011-08-09 19:23:26,821 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:26,821 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:26,822 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 57
2011-08-09 19:23:26,825 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test_dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
createFile: Creating test_dir for overwrite of existing directory.
2011-08-09 19:23:26,827 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /test_dir: masked=rwxr-xr-x
2011-08-09 19:23:26,832 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/test_dir, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:26,836 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 34722, call create(/test_dir, rwxr-xr-x, DFSClient_997141278, true, 1, 67108864) from 127.0.0.1:38431: error: java.io.IOException: Cannot create file /test_dir; already exists as a directory.
java.io.IOException: Cannot create file /test_dir; already exists as a directory.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1469)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
createFile: Created filestatus.dat with 1 replica.
2011-08-09 19:23:26,839 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /user/jeff/filestatus.dat: masked=rwxr-xr-x
2011-08-09 19:23:26,839 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:26,841 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:26,841 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:26,842 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,842 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,842 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,842 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:26,845 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 57, 57, 55, 49, 52, 49, 50, 55, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:26,845 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 57, 57, 55, 49, 52, 49, 50, 55, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:26,846 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 252
2011-08-09 19:23:26,847 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 252
2011-08-09 19:23:26,849 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/user/jeff/filestatus.dat	dst=null	perm=jeff:supergroup:rw-r--r--
Path : "filestatus.dat"
2011-08-09 19:23:26,858 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(49)) - seed=5398291377707409299
2011-08-09 19:23:26,858 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16385
2011-08-09 19:23:26,862 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/user/jeff/filestatus.dat, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:23:26,862 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=0, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:26,862 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:26,869 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:26,871 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-4903513374015264782_1001
2011-08-09 19:23:26,874 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:34900
2011-08-09 19:23:26,874 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:34900
2011-08-09 19:23:26,875 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:26,950 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4903513374015264782_1001 src: /127.0.0.1:47695 dest: /127.0.0.1:34900
2011-08-09 19:23:26,959 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-4903513374015264782_1001 wrote packet seqno:0 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:26,960 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:26,960 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=1, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:26,960 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:26,965 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:47695, dest: /127.0.0.1:34900, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_997141278, offset: 0, srvID: DS-1131686092-10.0.62.238-34900-1312910606767, blockid: blk_-4903513374015264782_1001, duration: 6074501
2011-08-09 19:23:26,965 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4903513374015264782_1001 terminating
2011-08-09 19:23:26,966 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:23:26,967 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34900 is added to blk_-4903513374015264782_1001 size 8192
2011-08-09 19:23:26,969 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-4903513374015264782_1001
2011-08-09 19:23:26,969 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:26,970 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_6581747059773699577_1001
2011-08-09 19:23:26,971 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:34900
2011-08-09 19:23:26,971 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:34900
2011-08-09 19:23:26,972 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:26,972 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6581747059773699577_1001 src: /127.0.0.1:47696 dest: /127.0.0.1:34900
2011-08-09 19:23:26,973 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_6581747059773699577_1001 wrote packet seqno:1 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:26,974 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:47696, dest: /127.0.0.1:34900, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_997141278, offset: 0, srvID: DS-1131686092-10.0.62.238-34900-1312910606767, blockid: blk_6581747059773699577_1001, duration: 840319
2011-08-09 19:23:26,975 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34900 is added to blk_6581747059773699577_1001 size 8192
2011-08-09 19:23:26,975 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6581747059773699577_1001 terminating
2011-08-09 19:23:26,975 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 1
2011-08-09 19:23:26,976 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_6581747059773699577_1001
2011-08-09 19:23:27,964 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/user/jeff/filestatus.dat	dst=null	perm=null
2011-08-09 19:23:27,969 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/user/jeff/filestatus.dat	dst=null	perm=null
2011-08-09 19:23:27,975 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16384
2011-08-09 19:23:27,981 DEBUG hdfs.DFSClient (DFSClient.java:fetchBlockByteRange(2402)) - fetchBlockByteRange shortCircuitLocalReads false localhst alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:34900
2011-08-09 19:23:27,998 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:34900, dest: /127.0.0.1:47697, bytes: 8256, op: HDFS_READ, cliID: DFSClient_997141278, offset: 0, srvID: DS-1131686092-10.0.62.238-34900-1312910606767, blockid: blk_-4903513374015264782_1001, duration: 1058014
2011-08-09 19:23:27,998 DEBUG hdfs.DFSClient (DFSClient.java:fetchBlockByteRange(2402)) - fetchBlockByteRange shortCircuitLocalReads false localhst alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:34900
2011-08-09 19:23:28,001 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:34900, dest: /127.0.0.1:47698, bytes: 8256, op: HDFS_READ, cliID: DFSClient_997141278, offset: 0, srvID: DS-1131686092-10.0.62.238-34900-1312910606767, blockid: blk_6581747059773699577_1001, duration: 296221
2011-08-09 19:23:28,054 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=2, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:28,054 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:28,055 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_5233603747384305059_1001
2011-08-09 19:23:28,056 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:34900
2011-08-09 19:23:28,056 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:34900
2011-08-09 19:23:28,056 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:28,058 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5233603747384305059_1001 src: /127.0.0.1:47699 dest: /127.0.0.1:34900
2011-08-09 19:23:28,061 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_5233603747384305059_1001 wrote packet seqno:2 size:30 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:28,062 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:47699, dest: /127.0.0.1:34900, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_997141278, offset: 0, srvID: DS-1131686092-10.0.62.238-34900-1312910606767, blockid: blk_5233603747384305059_1001, duration: 2769114
2011-08-09 19:23:28,063 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5233603747384305059_1001 terminating
2011-08-09 19:23:28,063 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34900 is added to blk_5233603747384305059_1001 size 1
2011-08-09 19:23:28,065 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 2
2011-08-09 19:23:28,066 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_5233603747384305059_1001
2011-08-09 19:23:28,068 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 56, 48, 54, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -69, -13, 56, -112, -10, 113, 103, -14, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 91, 87, 16, 20, 75, 72, 117, -7, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 72, -95, 126, -31, 33, -2, -91, -93, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:28,068 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 56, 48, 54, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 48, 54, 56, 52, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -69, -13, 56, -112, -10, 113, 103, -14, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 91, 87, 16, 20, 75, 72, 117, -7, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 72, -95, 126, -31, 33, -2, -91, -93, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:28,069 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /user/jeff/filestatus.dat is closed by DFSClient_997141278
2011-08-09 19:23:28,070 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
2011-08-09 19:23:28,071 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:23:28,107 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:28,108 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36642
2011-08-09 19:23:28,109 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36642: exiting
2011-08-09 19:23:28,109 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36642: exiting
2011-08-09 19:23:28,109 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36642: exiting
2011-08-09 19:23:28,110 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36642
2011-08-09 19:23:28,110 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:28,111 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:23:28,111 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34900, storageID=DS-1131686092-10.0.62.238-34900-1312910606767, infoPort=53110, ipcPort=36642):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:23:28,798 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:23:29,111 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:29,112 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34900, storageID=DS-1131686092-10.0.62.238-34900-1312910606767, infoPort=53110, ipcPort=36642):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:29,112 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36642
2011-08-09 19:23:29,113 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:29,113 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:23:29,113 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:23:29,114 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:23:29,169 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:29,271 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:29,271 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:29,272 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:29,272 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:29,272 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:9  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:23:29,273 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:29,274 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:29,275 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34722
2011-08-09 19:23:29,275 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34722: exiting
2011-08-09 19:23:29,275 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34722: exiting
2011-08-09 19:23:29,275 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34722: exiting
2011-08-09 19:23:29,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 34722: exiting
2011-08-09 19:23:29,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 34722: exiting
2011-08-09 19:23:29,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 34722: exiting
2011-08-09 19:23:29,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 34722: exiting
2011-08-09 19:23:29,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 34722: exiting
2011-08-09 19:23:29,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 34722: exiting
2011-08-09 19:23:29,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 34722: exiting
2011-08-09 19:23:29,278 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34722
2011-08-09 19:23:29,279 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:29,317 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:29,317 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:29,318 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:29,318 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:29,480 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:29,484 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:29,484 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:29,485 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:29,508 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:29,508 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:29,510 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:29,537 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:29,538 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:29,549 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:23:29,552 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:29,552 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:29,553 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:29,553 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:29,553 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:29,564 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:23:29,564 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:23:29,568 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:29,568 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:29,568 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:29,568 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:29,569 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:29,576 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:23:29,577 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:29,577 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:29,577 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:29,581 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:29,582 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:23:29,582 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:29,586 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:23:29,587 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:23:29,587 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:23:29,587 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:23:29,588 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:29,611 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:29,611 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:23:29,612 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 36 msecs
2011-08-09 19:23:29,612 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:23:29,619 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:23:29,620 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:23:29,620 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:23:29,620 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:23:29,620 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:23:29,630 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:29,634 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=50472
2011-08-09 19:23:29,635 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:50472
2011-08-09 19:23:29,635 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:29,636 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50472: starting
2011-08-09 19:23:29,657 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50472: starting
2011-08-09 19:23:29,658 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50472: starting
2011-08-09 19:23:29,658 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 50472: starting
2011-08-09 19:23:29,658 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 50472: starting
2011-08-09 19:23:29,658 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 50472: starting
2011-08-09 19:23:29,658 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 50472: starting
2011-08-09 19:23:29,659 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 50472: starting
2011-08-09 19:23:29,659 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 50472: starting
2011-08-09 19:23:29,659 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50472: starting
2011-08-09 19:23:29,660 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 50472: starting
2011-08-09 19:23:29,672 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:23:29,672 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:23:29,673 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:23:29,673 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:23:29,673 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:23:29,693 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:23:29,695 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:29,700 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:29,700 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36566 webServer.getConnectors()[0].getLocalPort() returned 36566
2011-08-09 19:23:29,700 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36566
2011-08-09 19:23:29,700 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:29,897 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36566
2011-08-09 19:23:29,959 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:36566
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:23:29,973 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:23:29,974 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:29,990 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:23:29,990 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:30,146 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:23:30,148 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 49917
2011-08-09 19:23:30,148 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:23:30,151 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:30,152 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:30,153 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49195 webServer.getConnectors()[0].getLocalPort() returned 49195
2011-08-09 19:23:30,153 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49195
2011-08-09 19:23:30,153 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:30,324 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49195
2011-08-09 19:23:30,341 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:23:30,376 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:30,382 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41317
2011-08-09 19:23:30,384 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:30,384 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41317: starting
2011-08-09 19:23:30,385 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41317: starting
2011-08-09 19:23:30,386 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41317: starting
2011-08-09 19:23:30,388 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41317: starting
2011-08-09 19:23:30,420 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:49917, storageID=, infoPort=49195, ipcPort=41317)
2011-08-09 19:23:30,428 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:49917 storage DS-1430269919-10.0.62.238-49917-1312910610424
2011-08-09 19:23:30,429 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:49917
2011-08-09 19:23:30,436 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1430269919-10.0.62.238-49917-1312910610424 is assigned to data-node 127.0.0.1:49917
2011-08-09 19:23:30,438 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:49917, storageID=DS-1430269919-10.0.62.238-49917-1312910610424, infoPort=49195, ipcPort=41317)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:30,439 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:23:30,485 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:23:30,486 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:49917 0 blocks shortCircuit first report.
2011-08-09 19:23:30,487 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:23:30,487 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:23:30,489 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created filestatus.dat with 1 replica.
2011-08-09 19:23:30,501 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /user/jeff/filestatus.dat: masked=rwxr-xr-x
2011-08-09 19:23:30,503 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:30,505 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:30,505 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:30,506 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:30,506 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:30,506 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:30,506 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:23:30,507 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 50, 50, 55, 56, 53, 51, 56, 48, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:30,507 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 50, 50, 55, 56, 53, 51, 56, 48, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:30,508 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:30,509 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:30,509 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 253
2011-08-09 19:23:30,513 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:30,514 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:30,514 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 253
2011-08-09 19:23:30,517 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/user/jeff/filestatus.dat	dst=null	perm=jeff:supergroup:rw-r--r--
createFile: Created filestatus2.dat with 1 replica.
2011-08-09 19:23:30,518 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /user/jeff/filestatus2.dat: masked=rwxr-xr-x
2011-08-09 19:23:30,520 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus2.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:30,522 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:23:30,522 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:23:30,523 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 50, 50, 55, 56, 53, 51, 56, 48, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:30,523 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 50, 50, 55, 56, 53, 51, 56, 48, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:30,523 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 145
2011-08-09 19:23:30,524 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 145
2011-08-09 19:23:30,525 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/user/jeff/filestatus2.dat	dst=null	perm=jeff:supergroup:rw-r--r--
createFile: Created filestatus3.dat with 1 replica.
DeleteOnExit: Created files.
2011-08-09 19:23:30,529 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16385
2011-08-09 19:23:30,533 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/user/jeff/filestatus.dat, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:23:30,533 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=0, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:30,533 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:30,533 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:30,535 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-5001990449700821542_1002
2011-08-09 19:23:30,536 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:49917
2011-08-09 19:23:30,536 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:49917
2011-08-09 19:23:30,536 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:30,537 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-5001990449700821542_1002 src: /127.0.0.1:40627 dest: /127.0.0.1:49917
2011-08-09 19:23:30,540 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-5001990449700821542_1002 wrote packet seqno:0 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:30,540 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:30,540 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=1, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:30,540 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:30,540 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16385
2011-08-09 19:23:30,541 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=2, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:30,544 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40627, dest: /127.0.0.1:49917, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_1227853808, offset: 0, srvID: DS-1430269919-10.0.62.238-49917-1312910610424, blockid: blk_-5001990449700821542_1002, duration: 2365022
2011-08-09 19:23:30,544 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-5001990449700821542_1002 terminating
2011-08-09 19:23:30,550 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:23:30,551 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-5001990449700821542_1002
2011-08-09 19:23:30,551 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49917 is added to blk_-5001990449700821542_1002 size 8192
2011-08-09 19:23:30,592 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:30,600 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-1548018386190810118_1002
2011-08-09 19:23:30,601 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:49917
2011-08-09 19:23:30,602 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:49917
2011-08-09 19:23:30,602 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:30,603 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1548018386190810118_1002 src: /127.0.0.1:40628 dest: /127.0.0.1:49917
2011-08-09 19:23:30,604 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-1548018386190810118_1002 wrote packet seqno:1 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:30,606 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49917 is added to blk_-1548018386190810118_1002 size 8192
2011-08-09 19:23:30,607 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40628, dest: /127.0.0.1:49917, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_1227853808, offset: 0, srvID: DS-1430269919-10.0.62.238-49917-1312910610424, blockid: blk_-1548018386190810118_1002, duration: 577632
2011-08-09 19:23:30,607 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 1
2011-08-09 19:23:30,607 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1548018386190810118_1002 terminating
2011-08-09 19:23:30,608 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-1548018386190810118_1002
2011-08-09 19:23:30,609 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:30,610 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-9061251265211054233_1002
2011-08-09 19:23:30,610 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:49917
2011-08-09 19:23:30,610 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:49917
2011-08-09 19:23:30,611 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:30,611 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-9061251265211054233_1002 src: /127.0.0.1:40629 dest: /127.0.0.1:49917
2011-08-09 19:23:30,612 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-9061251265211054233_1002 wrote packet seqno:2 size:30 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:30,614 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40629, dest: /127.0.0.1:49917, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_1227853808, offset: 0, srvID: DS-1430269919-10.0.62.238-49917-1312910610424, blockid: blk_-9061251265211054233_1002, duration: 683546
2011-08-09 19:23:30,614 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-9061251265211054233_1002 terminating
2011-08-09 19:23:30,614 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49917 is added to blk_-9061251265211054233_1002 size 1
2011-08-09 19:23:30,636 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 2
2011-08-09 19:23:30,636 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-9061251265211054233_1002
2011-08-09 19:23:30,638 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 51, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -70, -107, 92, 48, 11, -81, -91, -38, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -22, -22, -124, 85, 122, -63, 82, -61, -6, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -22, -126, 63, -9, -5, -100, -119, 71, 103, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:30,639 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 51, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 48, 53, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -70, -107, 92, 48, 11, -81, -91, -38, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -22, -22, -124, 85, 122, -63, 82, -61, -6, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -22, -126, 63, -9, -5, -100, -119, 71, 103, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:30,639 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /user/jeff/filestatus.dat is closed by DFSClient_1227853808
2011-08-09 19:23:30,640 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
2011-08-09 19:23:30,640 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
2011-08-09 19:23:30,643 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 52, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:30,644 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 52, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 53, 50, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:30,644 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /user/jeff/filestatus2.dat is closed by DFSClient_1227853808
2011-08-09 19:23:30,644 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 99
2011-08-09 19:23:30,645 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 99
2011-08-09 19:23:30,653 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /user/jeff/filestatus.dat is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:23:30,665 DEBUG namenode.LeaseManager (LeaseManager.java:findLeaseWithPrefixPath(328)) - LeaseManager.findLease: prefix=/user/jeff/filestatus.dat
2011-08-09 19:23:30,667 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [2, 0, 0, 0, 2, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 54, 52]
2011-08-09 19:23:30,668 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [2, 0, 0, 0, 2, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 54, 52]
2011-08-09 19:23:30,668 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-5001990449700821542 is added to invalidSet of 127.0.0.1:49917
2011-08-09 19:23:30,668 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1548018386190810118 is added to invalidSet of 127.0.0.1:49917
2011-08-09 19:23:30,668 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-9061251265211054233 is added to invalidSet of 127.0.0.1:49917
2011-08-09 19:23:30,668 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 52
2011-08-09 19:23:30,669 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 52
2011-08-09 19:23:30,670 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/user/jeff/filestatus.dat	dst=null	perm=null
Deleted /user/jeff/filestatus.dat
2011-08-09 19:23:30,671 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /user/jeff/filestatus2.dat is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:23:30,673 DEBUG namenode.LeaseManager (LeaseManager.java:findLeaseWithPrefixPath(328)) - LeaseManager.findLease: prefix=/user/jeff/filestatus2.dat
2011-08-09 19:23:30,673 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [2, 0, 0, 0, 2, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 55, 51]
2011-08-09 19:23:30,673 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [2, 0, 0, 0, 2, 0, 26, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 50, 46, 100, 97, 116, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 48, 54, 55, 51]
2011-08-09 19:23:30,674 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 53
2011-08-09 19:23:30,674 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 53
2011-08-09 19:23:30,675 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/user/jeff/filestatus2.dat	dst=null	perm=null
Deleted /user/jeff/filestatus2.dat
2011-08-09 19:23:30,676 DEBUG hdfs.DFSClient (DFSClient.java:interruptAndJoin(1498)) - Wait for lease checker to terminate
2011-08-09 19:23:30,677 DEBUG hdfs.DFSClient (DFSClient.java:run(1581)) - LeaseChecker@DFSClient[clientName=DFSClient_1227853808, ugi=jeff,jeff]: java.lang.Throwable: for testing
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.toString(DFSClient.java:1592)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1581)
	at java.lang.Thread.run(Thread.java:662)
 is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1578)
	at java.lang.Thread.run(Thread.java:662)
DeleteOnExit successful.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:23:30,690 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:30,791 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41317
2011-08-09 19:23:30,791 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41317: exiting
2011-08-09 19:23:30,792 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41317: exiting
2011-08-09 19:23:30,792 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41317: exiting
2011-08-09 19:23:30,792 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41317
2011-08-09 19:23:30,794 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:30,794 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:49917, storageID=DS-1430269919-10.0.62.238-49917-1312910610424, infoPort=49195, ipcPort=41317):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:23:30,795 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:30,795 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:23:30,797 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:49917, storageID=DS-1430269919-10.0.62.238-49917-1312910610424, infoPort=49195, ipcPort=41317):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:30,797 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41317
2011-08-09 19:23:30,798 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:30,798 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:23:30,798 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:23:30,800 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:23:30,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:30,952 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:30,952 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:30,953 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:30,953 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:30,954 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 10 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:8 
2011-08-09 19:23:30,954 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:30,955 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:30,956 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50472
2011-08-09 19:23:30,956 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50472: exiting
2011-08-09 19:23:30,957 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50472: exiting
2011-08-09 19:23:30,958 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 50472: exiting
2011-08-09 19:23:30,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 50472: exiting
2011-08-09 19:23:30,960 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 50472: exiting
2011-08-09 19:23:30,964 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50472
2011-08-09 19:23:30,968 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:30,994 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:30,995 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:30,995 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:30,995 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:31,001 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:31,001 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:31,002 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:31,002 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:31,015 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:31,015 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:31,160 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:31,160 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:31,161 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:31,172 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:23:31,175 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:31,175 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:31,176 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:31,176 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:31,176 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:31,187 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:23:31,188 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:23:31,192 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:31,192 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:31,192 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:31,192 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:31,192 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:31,201 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:23:31,201 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:31,202 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:31,202 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:31,206 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:31,207 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:23:31,207 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:31,212 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:23:31,212 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:23:31,213 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:23:31,213 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:23:31,213 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:31,237 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:31,237 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:23:31,238 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:23:31,238 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:23:31,241 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:23:31,241 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:23:31,241 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:23:31,242 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:23:31,242 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:23:31,243 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:31,246 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=41716
2011-08-09 19:23:31,246 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:41716
2011-08-09 19:23:31,247 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:31,247 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41716: starting
2011-08-09 19:23:31,248 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41716: starting
2011-08-09 19:23:31,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41716: starting
2011-08-09 19:23:31,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41716: starting
2011-08-09 19:23:31,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 41716: starting
2011-08-09 19:23:31,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 41716: starting
2011-08-09 19:23:31,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 41716: starting
2011-08-09 19:23:31,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 41716: starting
2011-08-09 19:23:31,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 41716: starting
2011-08-09 19:23:31,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 41716: starting
2011-08-09 19:23:31,251 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 41716: starting
2011-08-09 19:23:31,260 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:23:31,261 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:23:31,261 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:23:31,261 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:23:31,263 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:23:31,263 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:23:31,264 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:31,265 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:31,266 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36699 webServer.getConnectors()[0].getLocalPort() returned 36699
2011-08-09 19:23:31,266 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36699
2011-08-09 19:23:31,266 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:31,409 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36699
2011-08-09 19:23:31,409 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:36699
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:23:31,417 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:23:31,417 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:31,432 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:23:31,433 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:31,621 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:23:31,622 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53772
2011-08-09 19:23:31,623 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:23:31,626 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:31,627 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:31,627 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 46643 webServer.getConnectors()[0].getLocalPort() returned 46643
2011-08-09 19:23:31,627 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 46643
2011-08-09 19:23:31,627 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:31,769 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:46643
2011-08-09 19:23:31,770 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:23:31,777 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:31,779 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49403
2011-08-09 19:23:31,781 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49403: starting
2011-08-09 19:23:31,781 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:31,815 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49403: starting
2011-08-09 19:23:31,816 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49403: starting
2011-08-09 19:23:31,816 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53772, storageID=, infoPort=46643, ipcPort=49403)
2011-08-09 19:23:31,828 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49403: starting
2011-08-09 19:23:31,848 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53772 storage DS-2132707306-10.0.62.238-53772-1312910611829
2011-08-09 19:23:31,849 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53772
2011-08-09 19:23:31,875 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2132707306-10.0.62.238-53772-1312910611829 is assigned to data-node 127.0.0.1:53772
2011-08-09 19:23:31,895 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53772, storageID=DS-2132707306-10.0.62.238-53772-1312910611829, infoPort=46643, ipcPort=49403)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:31,901 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:23:31,911 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:23:31,913 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53772 0 blocks shortCircuit first report.
2011-08-09 19:23:31,914 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:23:31,914 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:23:31,916 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /filestatus.dat with 1 replica.
2011-08-09 19:23:31,930 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /filestatus.dat: masked=rwxr-xr-x
2011-08-09 19:23:31,931 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/filestatus.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:31,933 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:31,933 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:31,934 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 21, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 51, 55, 49, 53, 53, 50, 54, 48, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:31,934 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 21, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 51, 55, 49, 53, 53, 50, 54, 48, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:31,935 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:31,936 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:31,936 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 135
2011-08-09 19:23:31,941 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:31,941 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:31,941 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 135
2011-08-09 19:23:31,944 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/filestatus.dat	dst=null	perm=jeff:supergroup:rw-r--r--
Path : "/filestatus.dat"
Shutting down DataNode 0
2011-08-09 19:23:32,025 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:32,126 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49403
2011-08-09 19:23:32,126 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49403: exiting
2011-08-09 19:23:32,126 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49403: exiting
2011-08-09 19:23:32,127 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49403: exiting
2011-08-09 19:23:32,127 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49403
2011-08-09 19:23:32,129 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:32,129 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53772, storageID=DS-2132707306-10.0.62.238-53772-1312910611829, infoPort=46643, ipcPort=49403):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:23:32,130 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:32,130 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:23:32,131 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53772, storageID=DS-2132707306-10.0.62.238-53772-1312910611829, infoPort=46643, ipcPort=49403):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:32,131 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49403
2011-08-09 19:23:32,132 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:32,133 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:23:32,133 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:23:32,134 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
testFileCreationError1: waiting for datanode  to die.
2011-08-09 19:23:44,176 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=1
2011-08-09 19:23:44,176 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/filestatus.dat, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:23:44,177 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:44,178 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /filestatus.dat. blk_-2161245427388526654_1001
2011-08-09 19:23:44,178 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:53772
2011-08-09 19:23:44,178 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:53772
2011-08-09 19:23:44,179 INFO  hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3558)) - Exception in createBlockOutputStream 127.0.0.1:53772 java.net.ConnectException: Connection refused
2011-08-09 19:23:44,180 INFO  hdfs.DFSClient (DFSClient.java:nextBlockOutputStream(3475)) - Abandoning block blk_-2161245427388526654_1001
2011-08-09 19:23:44,181 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 21, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 51, 55, 49, 53, 53, 50, 54, 48, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:44,181 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 49, 49, 57, 51, 51, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 21, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 51, 55, 49, 53, 53, 50, 54, 48, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:44,264 INFO  hdfs.StateChange (FSNamesystem.java:heartbeatCheck(3654)) - BLOCK* NameSystem.heartbeatCheck: lost heartbeat from 127.0.0.1:53772
2011-08-09 19:23:44,265 INFO  net.NetworkTopology (NetworkTopology.java:remove(350)) - Removing a node: /default-rack/127.0.0.1:53772
2011-08-09 19:23:50,184 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 41716, call addBlock(/filestatus.dat, DFSClient_-1371552601) from 127.0.0.1:49232: error: java.io.IOException: File /filestatus.dat could only be replicated to 0 nodes, instead of 1
java.io.IOException: File /filestatus.dat could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1729)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:560)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:23:50,187 WARN  hdfs.DFSClient (DFSClient.java:run(2976)) - DataStreamer Exception: org.apache.hadoop.ipc.RemoteException: java.io.IOException: File /filestatus.dat could only be replicated to 0 nodes, instead of 1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1729)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:560)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:3591)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3465)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2700(DFSClient.java:2676)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2933)

2011-08-09 19:23:50,187 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_-2161245427388526654_1001 bad datanode[0] nodes == null
2011-08-09 19:23:50,187 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3181)) - Could not get block locations. Source file "/filestatus.dat" - Aborting...
Encountered expected exception
2011-08-09 19:23:50,229 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/filestatus.dat	dst=null	perm=null
locations = 0
Shutting down the Mini HDFS Cluster
2011-08-09 19:23:50,245 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:50,346 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:50,347 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:50,347 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:50,347 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:50,348 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:3 
2011-08-09 19:23:50,348 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 122
2011-08-09 19:23:50,350 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 122
2011-08-09 19:23:50,351 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41716
2011-08-09 19:23:50,351 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41716: exiting
2011-08-09 19:23:50,351 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41716: exiting
2011-08-09 19:23:50,352 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41716: exiting
2011-08-09 19:23:50,352 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 41716: exiting
2011-08-09 19:23:50,352 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 41716: exiting
2011-08-09 19:23:50,352 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 41716: exiting
2011-08-09 19:23:50,353 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 41716: exiting
2011-08-09 19:23:50,353 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 41716: exiting
2011-08-09 19:23:50,353 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 41716: exiting
2011-08-09 19:23:50,354 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 41716: exiting
2011-08-09 19:23:50,354 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41716
2011-08-09 19:23:50,356 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
testFileCreationError2 start
2011-08-09 19:23:50,390 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:50,390 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:50,390 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:50,390 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:50,421 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:50,421 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:50,421 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:50,422 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:50,442 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:50,442 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:50,601 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:50,602 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:50,603 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:50,615 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:23:50,619 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:50,619 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:50,620 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:50,620 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:50,621 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:50,632 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:23:50,632 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:23:50,638 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:50,638 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:50,639 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:50,639 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:50,639 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:50,657 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:23:50,658 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:50,658 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:50,658 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:50,662 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:50,662 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:23:50,663 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:50,667 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:23:50,667 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:23:50,668 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:23:50,668 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:23:50,668 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:50,692 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:50,692 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:23:50,693 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 36 msecs
2011-08-09 19:23:50,693 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:23:50,696 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:23:50,696 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:23:50,697 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:23:50,697 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:23:50,697 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:23:50,698 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:50,701 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=45671
2011-08-09 19:23:50,701 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:45671
2011-08-09 19:23:50,702 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:50,703 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45671: starting
2011-08-09 19:23:50,738 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45671: starting
2011-08-09 19:23:50,739 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45671: starting
2011-08-09 19:23:50,739 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45671: starting
2011-08-09 19:23:50,739 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 45671: starting
2011-08-09 19:23:50,739 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 45671: starting
2011-08-09 19:23:50,740 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 45671: starting
2011-08-09 19:23:50,740 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 45671: starting
2011-08-09 19:23:50,741 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 45671: starting
2011-08-09 19:23:50,741 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 45671: starting
2011-08-09 19:23:50,741 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 45671: starting
2011-08-09 19:23:50,772 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:23:50,794 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:23:50,794 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:23:50,794 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:23:50,795 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:23:50,836 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:23:50,837 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:50,838 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:50,839 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58279 webServer.getConnectors()[0].getLocalPort() returned 58279
2011-08-09 19:23:50,839 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58279
2011-08-09 19:23:50,839 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:50,935 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58279
2011-08-09 19:23:50,936 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:58279
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:23:51,018 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:23:51,018 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:51,035 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:23:51,035 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:51,274 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:23:51,277 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54479
2011-08-09 19:23:51,278 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:23:51,286 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:51,289 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:51,290 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49997 webServer.getConnectors()[0].getLocalPort() returned 49997
2011-08-09 19:23:51,290 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49997
2011-08-09 19:23:51,291 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:51,496 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49997
2011-08-09 19:23:51,496 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:23:51,501 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:51,503 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=40436
2011-08-09 19:23:51,504 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:51,548 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40436: starting
2011-08-09 19:23:51,548 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40436: starting
2011-08-09 19:23:51,549 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40436: starting
2011-08-09 19:23:51,549 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54479, storageID=, infoPort=49997, ipcPort=40436)
2011-08-09 19:23:51,550 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40436: starting
2011-08-09 19:23:51,556 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54479 storage DS-1060737289-10.0.62.238-54479-1312910631553
2011-08-09 19:23:51,557 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54479
2011-08-09 19:23:51,563 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1060737289-10.0.62.238-54479-1312910631553 is assigned to data-node 127.0.0.1:54479
2011-08-09 19:23:51,564 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54479, storageID=DS-1060737289-10.0.62.238-54479-1312910631553, infoPort=49997, ipcPort=40436)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:51,565 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:23:51,571 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:23:51,572 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54479 0 blocks shortCircuit first report.
2011-08-09 19:23:51,573 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:23:51,573 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:23:51,616 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /filestatus.dat with 1 replica.
2011-08-09 19:23:51,644 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /filestatus.dat: masked=rwxr-xr-x
2011-08-09 19:23:51,645 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/filestatus.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:51,647 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:51,648 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:51,648 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 55, 54, 50, 56, 55, 53, 53, 54, 50, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:51,649 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 55, 54, 50, 56, 55, 53, 53, 54, 50, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:51,650 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:51,650 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:51,650 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 134
2011-08-09 19:23:51,657 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:51,658 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:51,658 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 134
2011-08-09 19:23:51,661 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/filestatus.dat	dst=null	perm=jeff:supergroup:rw-r--r--
testFileCreationError2: Created file filestatus.dat with one replicas.
2011-08-09 19:23:51,705 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/filestatus.dat	dst=null	perm=null
testFileCreationError2: The file has 0 blocks.
2011-08-09 19:23:51,708 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /filestatus.dat. blk_-3000042623933869784_1001
testFileCreationError2: Added block blk_-3000042623933869784_1001
2011-08-09 19:23:51,748 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/filestatus.dat	dst=null	perm=null
testFileCreationError2: The file now has 1 blocks.
2011-08-09 19:23:51,779 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:53,779 INFO  namenode.LeaseManager (LeaseManager.java:checkLeases(389)) - Lease [Lease.  Holder: DFSClient_1762875562, pendingcreates: 1] has expired hard limit
2011-08-09 19:23:53,780 INFO  namenode.FSNamesystem (FSNamesystem.java:internalReleaseLease(2452)) - Recovering lease=[Lease.  Holder: DFSClient_1762875562, pendingcreates: 1], src=/filestatus.dat
2011-08-09 19:23:53,781 INFO  hdfs.StateChange (INodeFileUnderConstruction.java:assignPrimaryDatanode(163)) - BLOCK* blk_-3000042623933869784_1001 recovery started, primary=127.0.0.1:54479
2011-08-09 19:23:54,573 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - NameNode calls recoverBlock(block=blk_-3000042623933869784_1001, targets=[127.0.0.1:54479])
2011-08-09 19:23:54,574 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54479
2011-08-09 19:23:54,575 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2544)) - commitBlockSynchronization(lastblock=blk_-3000042623933869784_1001, newgenerationstamp=0, newlength=0, newtargets=[], closeFile=true, deleteBlock=true)
2011-08-09 19:23:54,575 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 52, 53, 55, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:54,576 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 15, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 52, 53, 55, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 49, 54, 52, 56, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:54,576 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 88
2011-08-09 19:23:54,577 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 88
2011-08-09 19:23:54,578 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2625)) - commitBlockSynchronization(newblock=blk_-3000042623933869784_1001, file=/filestatus.dat, newgenerationstamp=0, newlength=0, newtargets=[]) successful
2011-08-09 19:23:56,796 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/filestatus.dat	dst=null	perm=null
testFileCreationError2: locations = 0
testFileCreationError2 successful
2011-08-09 19:23:56,798 WARN  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1872)) - DIR* NameSystem.completeFile: failed to complete /filestatus.dat because dir.getFileBlocks() is null  and pendingFile is null
2011-08-09 19:23:56,800 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:56,801 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:56,802 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 45671, call complete(/filestatus.dat, DFSClient_1762875562) from 127.0.0.1:44502: error: java.io.IOException: Could not complete write to file /filestatus.dat by DFSClient_1762875562
java.io.IOException: Could not complete write to file /filestatus.dat by DFSClient_1762875562
	at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:596)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:23:56,803 ERROR hdfs.DFSClient (DFSClient.java:close(1511)) - Exception closing file /filestatus.dat : org.apache.hadoop.ipc.RemoteException: java.io.IOException: Could not complete write to file /filestatus.dat by DFSClient_1762875562
	at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:596)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: Could not complete write to file /filestatus.dat by DFSClient_1762875562
	at org.apache.hadoop.hdfs.server.namenode.NameNode.complete(NameNode.java:596)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.complete(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3944)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3842)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.close(DFSClient.java:1509)
	at org.apache.hadoop.hdfs.DFSClient.close(DFSClient.java:347)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:312)
	at org.apache.hadoop.io.IOUtils.cleanup(IOUtils.java:135)
	at org.apache.hadoop.io.IOUtils.closeStream(IOUtils.java:151)
	at org.apache.hadoop.hdfs.TestFileCreation.testFileCreationError2(TestFileCreation.java:446)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:23:56,803 DEBUG hdfs.DFSClient (DFSClient.java:interruptAndJoin(1498)) - Wait for lease checker to terminate
2011-08-09 19:23:56,804 DEBUG hdfs.DFSClient (DFSClient.java:run(1581)) - LeaseChecker@DFSClient[clientName=DFSClient_1762875562, ugi=jeff,jeff]: java.lang.Throwable: for testing
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.toString(DFSClient.java:1592)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1581)
	at java.lang.Thread.run(Thread.java:662)
 is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1578)
	at java.lang.Thread.run(Thread.java:662)
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:23:56,859 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:56,861 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40436
2011-08-09 19:23:56,861 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40436: exiting
2011-08-09 19:23:56,861 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40436: exiting
2011-08-09 19:23:56,863 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40436
2011-08-09 19:23:56,863 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40436: exiting
2011-08-09 19:23:56,864 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:56,865 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:23:56,865 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54479, storageID=DS-1060737289-10.0.62.238-54479-1312910631553, infoPort=49997, ipcPort=40436):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:23:57,570 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54479, storageID=DS-1060737289-10.0.62.238-54479-1312910631553, infoPort=49997, ipcPort=40436):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:57,571 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40436
2011-08-09 19:23:57,571 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:57,572 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:23:57,573 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:23:57,573 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:23:57,865 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:23:57,866 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:23:57,976 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:57,978 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:57,978 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:23:57,978 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:57,979 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:23:57,980 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:23:57,981 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:57,984 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:23:57,985 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45671
2011-08-09 19:23:57,985 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 45671: exiting
2011-08-09 19:23:57,985 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45671: exiting
2011-08-09 19:23:57,986 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 45671: exiting
2011-08-09 19:23:57,986 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 45671: exiting
2011-08-09 19:23:57,987 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45671
2011-08-09 19:23:57,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 45671: exiting
2011-08-09 19:23:57,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 45671: exiting
2011-08-09 19:23:57,988 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:57,988 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45671: exiting
2011-08-09 19:23:57,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 45671: exiting
2011-08-09 19:23:57,988 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45671: exiting
Testing adbornal client death.
2011-08-09 19:23:58,001 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 45671: exiting
2011-08-09 19:23:58,008 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:58,008 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:58,009 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:58,009 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:58,021 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:58,021 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:58,021 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:58,022 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:58,034 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:58,034 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:58,179 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:58,180 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:58,180 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:58,192 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:23:58,195 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:23:58,195 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:58,195 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:23:58,196 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:23:58,196 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:23:58,207 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:23:58,208 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:23:58,211 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:58,211 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:23:58,211 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:23:58,211 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:23:58,211 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:23:58,218 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:23:58,218 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:23:58,219 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:23:58,219 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:23:58,222 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:23:58,223 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:23:58,224 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:23:58,227 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:23:58,227 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:23:58,228 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:23:58,228 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:23:58,228 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:58,252 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:23:58,252 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:23:58,252 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 34 msecs
2011-08-09 19:23:58,253 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:23:58,256 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:23:58,256 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:23:58,256 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:23:58,256 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:23:58,257 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:23:58,258 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:58,291 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=49241
2011-08-09 19:23:58,291 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:49241
2011-08-09 19:23:58,292 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:58,292 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49241: starting
2011-08-09 19:23:58,333 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49241: starting
2011-08-09 19:23:58,333 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49241: starting
2011-08-09 19:23:58,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 49241: starting
2011-08-09 19:23:58,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 49241: starting
2011-08-09 19:23:58,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 49241: starting
2011-08-09 19:23:58,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 49241: starting
2011-08-09 19:23:58,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 49241: starting
2011-08-09 19:23:58,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 49241: starting
2011-08-09 19:23:58,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 49241: starting
2011-08-09 19:23:58,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49241: starting
2011-08-09 19:23:58,345 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:23:58,345 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:23:58,345 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:23:58,346 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:23:58,347 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:23:58,347 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:23:58,377 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:58,378 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:58,379 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45854 webServer.getConnectors()[0].getLocalPort() returned 45854
2011-08-09 19:23:58,379 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45854
2011-08-09 19:23:58,379 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:58,457 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45854
2011-08-09 19:23:58,479 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:45854
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:23:58,486 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:23:58,486 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:58,502 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:23:58,502 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:23:58,706 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:23:58,707 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 56344
2011-08-09 19:23:58,708 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:23:58,710 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:23:58,711 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:23:58,712 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45978 webServer.getConnectors()[0].getLocalPort() returned 45978
2011-08-09 19:23:58,712 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45978
2011-08-09 19:23:58,712 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:23:58,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45978
2011-08-09 19:23:58,852 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:23:58,856 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:23:58,859 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=46242
2011-08-09 19:23:58,860 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:23:58,861 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 46242: starting
2011-08-09 19:23:58,861 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 46242: starting
2011-08-09 19:23:58,904 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 46242: starting
2011-08-09 19:23:58,905 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:56344, storageID=, infoPort=45978, ipcPort=46242)
2011-08-09 19:23:58,906 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 46242: starting
2011-08-09 19:23:58,911 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:56344 storage DS-428398958-10.0.62.238-56344-1312910638908
2011-08-09 19:23:58,912 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:56344
2011-08-09 19:23:58,917 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-428398958-10.0.62.238-56344-1312910638908 is assigned to data-node 127.0.0.1:56344
2011-08-09 19:23:58,918 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:56344, storageID=DS-428398958-10.0.62.238-56344-1312910638908, infoPort=45978, ipcPort=46242)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:23:58,919 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:23:58,924 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:23:58,926 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:56344 0 blocks shortCircuit first report.
2011-08-09 19:23:58,927 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:23:58,928 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:23:58,963 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /clienttest.dat with 1 replica.
2011-08-09 19:23:58,966 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /clienttest.dat: masked=rwxr-xr-x
2011-08-09 19:23:58,968 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/clienttest.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:23:58,970 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:58,970 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:23:58,971 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 99, 108, 105, 101, 110, 116, 116, 101, 115, 116, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 55, 55, 51, 56, 57, 49, 54, 56, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:58,972 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 15, 47, 99, 108, 105, 101, 110, 116, 116, 101, 115, 116, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 55, 55, 51, 56, 57, 49, 54, 56, 49, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:23:58,972 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:58,973 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:58,973 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 134
2011-08-09 19:23:58,977 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:23:58,978 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:23:58,978 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 134
2011-08-09 19:23:58,981 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/clienttest.dat	dst=null	perm=jeff:supergroup:rw-r--r--
Created file clienttest.dat
2011-08-09 19:23:58,983 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16385
2011-08-09 19:23:58,984 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/clienttest.dat, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:23:58,984 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=0, src=/clienttest.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:58,984 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/clienttest.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:58,985 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:59,007 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /clienttest.dat. blk_-8706107492269589471_1001
2011-08-09 19:23:59,008 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:56344
2011-08-09 19:23:59,008 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:56344
2011-08-09 19:23:59,009 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:59,009 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8706107492269589471_1001 src: /127.0.0.1:36563 dest: /127.0.0.1:56344
2011-08-09 19:23:59,013 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-8706107492269589471_1001 wrote packet seqno:0 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:59,013 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/clienttest.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:59,016 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:36563, dest: /127.0.0.1:56344, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_1773891681, offset: 0, srvID: DS-428398958-10.0.62.238-56344-1312910638908, blockid: blk_-8706107492269589471_1001, duration: 3477526
2011-08-09 19:23:59,016 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-8706107492269589471_1001 terminating
2011-08-09 19:23:59,016 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:23:59,018 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-8706107492269589471_1001
2011-08-09 19:23:59,053 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56344 is added to blk_-8706107492269589471_1001 size 8192
2011-08-09 19:23:59,054 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=1, src=/clienttest.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:23:59,054 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/clienttest.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:23:59,054 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=2, src=/clienttest.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:23:59,055 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:59,056 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /clienttest.dat. blk_2981188562785499946_1001
2011-08-09 19:23:59,057 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:56344
2011-08-09 19:23:59,057 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:56344
2011-08-09 19:23:59,057 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:59,058 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2981188562785499946_1001 src: /127.0.0.1:36564 dest: /127.0.0.1:56344
2011-08-09 19:23:59,059 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_2981188562785499946_1001 wrote packet seqno:1 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:59,061 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56344 is added to blk_2981188562785499946_1001 size 8192
2011-08-09 19:23:59,062 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:36564, dest: /127.0.0.1:56344, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_1773891681, offset: 0, srvID: DS-428398958-10.0.62.238-56344-1312910638908, blockid: blk_2981188562785499946_1001, duration: 535993
2011-08-09 19:23:59,062 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_2981188562785499946_1001 terminating
2011-08-09 19:23:59,063 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 1
2011-08-09 19:23:59,063 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_2981188562785499946_1001
2011-08-09 19:23:59,064 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:23:59,064 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /clienttest.dat. blk_623901263905424892_1001
2011-08-09 19:23:59,065 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:56344
2011-08-09 19:23:59,065 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:56344
2011-08-09 19:23:59,065 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:23:59,066 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_623901263905424892_1001 src: /127.0.0.1:36565 dest: /127.0.0.1:56344
2011-08-09 19:23:59,067 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_623901263905424892_1001 wrote packet seqno:2 size:30 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:23:59,069 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56344 is added to blk_623901263905424892_1001 size 1
2011-08-09 19:23:59,069 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:36565, dest: /127.0.0.1:56344, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_1773891681, offset: 0, srvID: DS-428398958-10.0.62.238-56344-1312910638908, blockid: blk_623901263905424892_1001, duration: 922198
2011-08-09 19:23:59,069 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_623901263905424892_1001 terminating
2011-08-09 19:23:59,069 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 2
2011-08-09 19:23:59,070 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_623901263905424892_1001
2011-08-09 19:23:59,072 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 15, 47, 99, 108, 105, 101, 110, 116, 116, 101, 115, 116, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 57, 48, 55, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -121, 45, -79, 92, -38, -25, 124, 33, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 41, 95, 79, 51, -19, 73, 123, 42, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 8, -88, -118, -28, -38, 0, 5, -4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:59,072 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 15, 47, 99, 108, 105, 101, 110, 116, 116, 101, 115, 116, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 57, 48, 55, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 51, 56, 57, 55, 49, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -121, 45, -79, 92, -38, -25, 124, 33, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 41, 95, 79, 51, -19, 73, 123, 42, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 8, -88, -118, -28, -38, 0, 5, -4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:23:59,072 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /clienttest.dat is closed by DFSClient_1773891681
2011-08-09 19:23:59,073 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 160
2011-08-09 19:23:59,073 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 160
2011-08-09 19:23:59,075 DEBUG hdfs.DFSClient (DFSClient.java:interruptAndJoin(1498)) - Wait for lease checker to terminate
2011-08-09 19:23:59,075 DEBUG hdfs.DFSClient (DFSClient.java:run(1581)) - LeaseChecker@DFSClient[clientName=DFSClient_1773891681, ugi=jeff,jeff]: java.lang.Throwable: for testing
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.toString(DFSClient.java:1592)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1581)
	at java.lang.Thread.run(Thread.java:662)
 is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1578)
	at java.lang.Thread.run(Thread.java:662)
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:23:59,148 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:23:59,249 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46242
2011-08-09 19:23:59,249 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 46242: exiting
2011-08-09 19:23:59,249 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 46242: exiting
2011-08-09 19:23:59,249 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 46242: exiting
2011-08-09 19:23:59,250 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 46242
2011-08-09 19:23:59,252 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:23:59,252 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:23:59,253 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:56344, storageID=DS-428398958-10.0.62.238-56344-1312910638908, infoPort=45978, ipcPort=46242):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:23:59,964 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:00,253 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:00,253 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:56344, storageID=DS-428398958-10.0.62.238-56344-1312910638908, infoPort=45978, ipcPort=46242):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:00,254 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46242
2011-08-09 19:24:00,254 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:00,255 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:00,255 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:00,255 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:00,299 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:00,300 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:00,301 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:00,301 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:00,301 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:00,302 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:5  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:24:00,303 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:00,305 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:00,306 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49241
2011-08-09 19:24:00,306 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49241: exiting
2011-08-09 19:24:00,306 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 49241: exiting
2011-08-09 19:24:00,306 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 49241: exiting
2011-08-09 19:24:00,306 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49241: exiting
2011-08-09 19:24:00,307 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 49241: exiting
2011-08-09 19:24:00,307 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49241: exiting
2011-08-09 19:24:00,307 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 49241: exiting
2011-08-09 19:24:00,307 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 49241: exiting
2011-08-09 19:24:00,308 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 49241: exiting
2011-08-09 19:24:00,308 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 49241: exiting
2011-08-09 19:24:00,308 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49241
2011-08-09 19:24:00,309 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:00,339 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:00,340 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:00,340 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:00,340 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:00,351 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:00,351 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:00,351 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:00,351 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:00,362 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:00,362 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:00,504 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:00,505 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:00,505 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:00,516 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:00,519 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:00,519 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:00,520 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:00,520 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:00,520 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:00,530 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:00,531 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:00,534 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:00,534 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:00,534 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:00,535 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:00,535 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:00,541 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:00,542 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:00,542 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:00,542 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:00,545 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:00,546 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:00,547 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:00,550 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:00,550 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:00,550 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:00,551 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:00,551 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:00,574 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:00,575 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:00,575 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 34 msecs
2011-08-09 19:24:00,575 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:00,578 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:00,579 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:00,579 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:00,579 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:00,579 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:00,580 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:00,582 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=44784
2011-08-09 19:24:00,583 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:44784
2011-08-09 19:24:00,583 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:00,583 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44784: starting
2011-08-09 19:24:00,584 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44784: starting
2011-08-09 19:24:00,584 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44784: starting
2011-08-09 19:24:00,585 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 44784: starting
2011-08-09 19:24:00,585 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 44784: starting
2011-08-09 19:24:00,585 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 44784: starting
2011-08-09 19:24:00,585 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 44784: starting
2011-08-09 19:24:00,586 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 44784: starting
2011-08-09 19:24:00,586 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 44784: starting
2011-08-09 19:24:00,586 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 44784: starting
2011-08-09 19:24:00,586 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44784: starting
2011-08-09 19:24:00,594 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:00,595 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:00,596 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:00,596 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:00,596 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:00,597 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:00,599 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:00,616 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:00,616 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58788 webServer.getConnectors()[0].getLocalPort() returned 58788
2011-08-09 19:24:00,616 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58788
2011-08-09 19:24:00,616 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:00,717 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58788
2011-08-09 19:24:00,718 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:58788
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:00,773 INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(648)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:00,774 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44860
2011-08-09 19:24:00,774 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:00,774 INFO  datanode.DataNode (DataNode.java:startDataNode(359)) - Periodic Block Verification is disabled because verifcation is supported only with FSDataset.
2011-08-09 19:24:00,775 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:00,776 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:00,776 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 55733 webServer.getConnectors()[0].getLocalPort() returned 55733
2011-08-09 19:24:00,776 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 55733
2011-08-09 19:24:00,776 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:00,905 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:55733
2011-08-09 19:24:00,906 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:00,909 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:00,911 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=48590
2011-08-09 19:24:00,912 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:00,912 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48590: starting
2011-08-09 19:24:00,913 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48590: starting
2011-08-09 19:24:00,913 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48590: starting
2011-08-09 19:24:00,913 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44860, storageID=DS-1373158532-10.0.62.238-0-1312910640769, infoPort=55733, ipcPort=48590)
2011-08-09 19:24:00,913 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48590: starting
2011-08-09 19:24:00,914 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44860 storage DS-1373158532-10.0.62.238-0-1312910640769
2011-08-09 19:24:00,914 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44860
2011-08-09 19:24:00,915 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1373158532-10.0.62.238-0-1312910640769 is assigned to data-node 127.0.0.1:44860
2011-08-09 19:24:00,915 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44860, storageID=DS-1373158532-10.0.62.238-0-1312910640769, infoPort=55733, ipcPort=48590)In DataNode.run, data = Simulated FSDataset-DS-1373158532-10.0.62.238-0-1312910640769
2011-08-09 19:24:00,916 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:00,919 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:44860 0 blocks shortCircuit first report.
2011-08-09 19:24:00,920 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 1 msecs
Path : "/"
true
2011-08-09 19:24:00,926 DEBUG hdfs.DFSClient (DFSClient.java:mkdirs(1383)) - /test_dir: masked=rwxr-xr-x
2011-08-09 19:24:00,931 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 9, 47, 116, 101, 115, 116, 95, 100, 105, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 51, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,931 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 9, 47, 116, 101, 115, 116, 95, 100, 105, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 51, 49, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,932 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:00,932 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:00,932 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 57
2011-08-09 19:24:00,938 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:00,939 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:00,939 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 57
2011-08-09 19:24:00,941 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test_dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
createFile: Creating test_dir for overwrite of existing directory.
2011-08-09 19:24:00,942 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /test_dir: masked=rwxr-xr-x
2011-08-09 19:24:00,943 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/test_dir, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:00,944 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 44784, call create(/test_dir, rwxr-xr-x, DFSClient_725893778, true, 1, 67108864) from 127.0.0.1:40149: error: java.io.IOException: Cannot create file /test_dir; already exists as a directory.
java.io.IOException: Cannot create file /test_dir; already exists as a directory.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1469)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
createFile: Created filestatus.dat with 1 replica.
2011-08-09 19:24:00,945 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /user/jeff/filestatus.dat: masked=rwxr-xr-x
2011-08-09 19:24:00,945 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:00,946 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:00,946 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:00,947 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,948 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 5, 47, 117, 115, 101, 114, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,948 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,948 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 10, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:00,948 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 55, 50, 53, 56, 57, 51, 55, 55, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:00,948 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 55, 50, 53, 56, 57, 51, 55, 55, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:00,949 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 252
2011-08-09 19:24:00,950 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 252
2011-08-09 19:24:00,951 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/user/jeff/filestatus.dat	dst=null	perm=jeff:supergroup:rw-r--r--
Path : "filestatus.dat"
2011-08-09 19:24:00,953 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(70)) - seed=3735928559, size=16385
2011-08-09 19:24:00,954 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/user/jeff/filestatus.dat, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:00,955 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=0, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:24:00,955 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:24:00,955 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:24:00,955 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:00,956 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-5903069803925148926_1001
2011-08-09 19:24:00,957 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:44860
2011-08-09 19:24:00,957 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:44860
2011-08-09 19:24:00,957 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:00,958 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-5903069803925148926_1001 src: /127.0.0.1:44021 dest: /127.0.0.1:44860
2011-08-09 19:24:00,960 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-5903069803925148926_1001 wrote packet seqno:0 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:00,960 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3685)) - DFSClient writeChunk packet full seqno=1, src=/user/jeff/filestatus.dat, bytesCurBlock=8192, blockSize=8192, appendChunk=false
2011-08-09 19:24:00,960 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/user/jeff/filestatus.dat, chunkSize=516, chunksPerPacket=16, packetSize=8281
2011-08-09 19:24:00,961 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:44021, dest: /127.0.0.1:44860, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_725893778, offset: 0, srvID: DS-1373158532-10.0.62.238-0-1312910640769, blockid: blk_-5903069803925148926_1001, duration: 1090429
2011-08-09 19:24:00,962 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-5903069803925148926_1001 terminating
2011-08-09 19:24:00,987 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:00,987 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-5903069803925148926_1001
2011-08-09 19:24:00,988 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:00,991 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44860 is added to blk_-5903069803925148926_1001 size 8192
2011-08-09 19:24:00,992 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_6852250332163041690_1001
2011-08-09 19:24:00,992 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:44860
2011-08-09 19:24:00,993 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:44860
2011-08-09 19:24:00,993 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:00,993 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6852250332163041690_1001 src: /127.0.0.1:44022 dest: /127.0.0.1:44860
2011-08-09 19:24:00,994 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_6852250332163041690_1001 wrote packet seqno:1 size:8281 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:00,996 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:44022, dest: /127.0.0.1:44860, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_725893778, offset: 0, srvID: DS-1373158532-10.0.62.238-0-1312910640769, blockid: blk_6852250332163041690_1001, duration: 1169236
2011-08-09 19:24:00,996 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6852250332163041690_1001 terminating
2011-08-09 19:24:00,997 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 1
2011-08-09 19:24:00,997 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_6852250332163041690_1001
2011-08-09 19:24:01,001 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44860 is added to blk_6852250332163041690_1001 size 8192
2011-08-09 19:24:01,963 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/user/jeff/filestatus.dat	dst=null	perm=null
2011-08-09 19:24:01,965 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/user/jeff/filestatus.dat	dst=null	perm=null
2011-08-09 19:24:01,966 DEBUG hdfs.DFSClient (DFSClient.java:fetchBlockByteRange(2402)) - fetchBlockByteRange shortCircuitLocalReads false localhst alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:44860
2011-08-09 19:24:01,969 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:44860, dest: /127.0.0.1:44023, bytes: 8192, op: HDFS_READ, cliID: DFSClient_725893778, offset: 0, srvID: DS-1373158532-10.0.62.238-0-1312910640769, blockid: blk_-5903069803925148926_1001, duration: 1164764
2011-08-09 19:24:01,973 DEBUG hdfs.DFSClient (DFSClient.java:fetchBlockByteRange(2402)) - fetchBlockByteRange shortCircuitLocalReads false localhst alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:44860
2011-08-09 19:24:01,986 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:44860, dest: /127.0.0.1:44024, bytes: 8192, op: HDFS_READ, cliID: DFSClient_725893778, offset: 0, srvID: DS-1373158532-10.0.62.238-0-1312910640769, blockid: blk_6852250332163041690_1001, duration: 11722535
2011-08-09 19:24:02,003 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=2, src=/user/jeff/filestatus.dat, packetSize=8281, chunksPerPacket=16, bytesCurBlock=0
2011-08-09 19:24:02,003 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:02,004 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /user/jeff/filestatus.dat. blk_-6537229048630535150_1001
2011-08-09 19:24:02,004 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:44860
2011-08-09 19:24:02,004 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:44860
2011-08-09 19:24:02,005 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:02,005 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6537229048630535150_1001 src: /127.0.0.1:44025 dest: /127.0.0.1:44860
2011-08-09 19:24:02,006 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-6537229048630535150_1001 wrote packet seqno:2 size:30 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:02,008 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:44025, dest: /127.0.0.1:44860, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_725893778, offset: 0, srvID: DS-1373158532-10.0.62.238-0-1312910640769, blockid: blk_-6537229048630535150_1001, duration: 786943
2011-08-09 19:24:02,008 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-6537229048630535150_1001 terminating
2011-08-09 19:24:02,009 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 2
2011-08-09 19:24:02,023 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-6537229048630535150_1001
2011-08-09 19:24:02,025 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44860 is added to blk_-6537229048630535150_1001 size 1
2011-08-09 19:24:02,027 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 50, 48, 50, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -82, 20, 21, 74, 4, -76, -21, 2, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 95, 24, 21, 95, 80, -95, 105, -102, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, -91, 71, 24, -48, -27, 3, 28, 18, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:02,027 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 25, 47, 117, 115, 101, 114, 47, 106, 101, 102, 102, 47, 102, 105, 108, 101, 115, 116, 97, 116, 117, 115, 46, 100, 97, 116, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 50, 48, 50, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 48, 57, 52, 55, 0, 4, 56, 49, 57, 50, 0, 0, 0, 3, -82, 20, 21, 74, 4, -76, -21, 2, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, 95, 24, 21, 95, 80, -95, 105, -102, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 3, -23, -91, 71, 24, -48, -27, 3, 28, 18, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:02,028 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /user/jeff/filestatus.dat is closed by DFSClient_725893778
2011-08-09 19:24:02,028 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
2011-08-09 19:24:02,029 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 170
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:24:02,120 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:02,220 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48590
2011-08-09 19:24:02,221 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48590: exiting
2011-08-09 19:24:02,221 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48590: exiting
2011-08-09 19:24:02,221 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48590: exiting
2011-08-09 19:24:02,221 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 48590
2011-08-09 19:24:02,222 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:02,223 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:02,223 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44860, storageID=DS-1373158532-10.0.62.238-0-1312910640769, infoPort=55733, ipcPort=48590):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:03,024 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 0 time(s).
2011-08-09 19:24:03,223 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:03,224 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44860, storageID=DS-1373158532-10.0.62.238-0-1312910640769, infoPort=55733, ipcPort=48590):Finishing DataNode in: Simulated FSDataset-DS-1373158532-10.0.62.238-0-1312910640769
2011-08-09 19:24:03,225 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48590
2011-08-09 19:24:03,225 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:03,269 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:03,369 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:03,370 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:03,370 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:03,370 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:03,371 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:24:03,372 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:03,373 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:03,374 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44784
2011-08-09 19:24:03,374 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44784: exiting
2011-08-09 19:24:03,374 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44784: exiting
2011-08-09 19:24:03,374 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44784: exiting
2011-08-09 19:24:03,375 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 44784: exiting
2011-08-09 19:24:03,375 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 44784: exiting
2011-08-09 19:24:03,375 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 44784: exiting
2011-08-09 19:24:03,375 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 44784: exiting
2011-08-09 19:24:03,376 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 44784: exiting
2011-08-09 19:24:03,376 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 44784: exiting
2011-08-09 19:24:03,376 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44784
2011-08-09 19:24:03,376 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 44784: exiting
2011-08-09 19:24:03,378 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:03,393 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:03,393 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:03,394 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:03,394 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:03,399 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:03,400 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:03,400 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:03,400 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:03,410 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:03,410 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:03,523 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:03,524 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:03,524 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:03,535 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:03,539 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:03,539 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:03,540 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:03,540 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:03,540 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:03,550 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:03,551 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:03,554 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:03,554 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:03,554 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:03,554 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:03,554 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:03,562 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:03,563 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:03,563 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:03,563 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:03,566 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:03,567 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:03,567 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:03,571 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:03,571 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:03,571 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:03,571 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:03,572 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:03,585 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:03,586 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:03,586 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 24 msecs
2011-08-09 19:24:03,586 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:03,589 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:03,589 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:03,590 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:03,590 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:03,590 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:03,591 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:03,593 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=35168
2011-08-09 19:24:03,594 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:35168
2011-08-09 19:24:03,594 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:03,594 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 35168: starting
2011-08-09 19:24:03,595 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 35168: starting
2011-08-09 19:24:03,595 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 35168: starting
2011-08-09 19:24:03,595 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 35168: starting
2011-08-09 19:24:03,596 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 35168: starting
2011-08-09 19:24:03,597 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 35168: starting
2011-08-09 19:24:03,605 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:03,605 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:03,605 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:03,606 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:03,607 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:03,628 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:03,630 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:03,631 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:03,631 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 32823 webServer.getConnectors()[0].getLocalPort() returned 32823
2011-08-09 19:24:03,631 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 32823
2011-08-09 19:24:03,631 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:03,731 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:32823
2011-08-09 19:24:03,731 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:32823
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:03,738 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:24:03,739 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:03,754 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:24:03,755 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:03,895 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:03,897 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 52245
2011-08-09 19:24:03,897 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:03,900 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:03,901 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:03,901 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43412 webServer.getConnectors()[0].getLocalPort() returned 43412
2011-08-09 19:24:03,901 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43412
2011-08-09 19:24:03,901 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:03,967 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43412
2011-08-09 19:24:03,968 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:03,973 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:03,975 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=47543
2011-08-09 19:24:03,976 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:03,977 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47543: starting
2011-08-09 19:24:03,977 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47543: starting
2011-08-09 19:24:03,978 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47543: starting
2011-08-09 19:24:03,978 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:52245, storageID=, infoPort=43412, ipcPort=47543)
2011-08-09 19:24:03,979 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47543: starting
2011-08-09 19:24:03,984 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:52245 storage DS-723207322-10.0.62.238-52245-1312910643981
2011-08-09 19:24:03,985 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:52245
2011-08-09 19:24:03,990 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-723207322-10.0.62.238-52245-1312910643981 is assigned to data-node 127.0.0.1:52245
2011-08-09 19:24:03,991 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:52245, storageID=DS-723207322-10.0.62.238-52245-1312910643981, infoPort=43412, ipcPort=47543)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:03,992 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:03,997 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:03,999 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:52245 0 blocks shortCircuit first report.
2011-08-09 19:24:04,000 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:24:04,001 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:04,004 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:04,004 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /foo: masked=rwxr-xr-x
2011-08-09 19:24:04,006 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/foo, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:04,008 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:04,016 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:04,017 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 51, 57, 48, 50, 56, 56, 57, 52, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:04,017 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 51, 57, 48, 50, 56, 56, 57, 52, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:04,020 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:04,020 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:04,021 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 126
2011-08-09 19:24:04,025 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 1 time(s).
2011-08-09 19:24:04,027 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:04,027 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:04,027 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 126
2011-08-09 19:24:04,030 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:04,032 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /bar: masked=rwxr-xr-x
2011-08-09 19:24:04,032 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/bar, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:04,036 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:04,036 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:04,037 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 51, 57, 48, 50, 56, 56, 57, 52, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:04,037 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 19, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 51, 57, 48, 50, 56, 56, 57, 52, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:04,037 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 126
2011-08-09 19:24:04,038 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 126
2011-08-09 19:24:04,039 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/bar	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:04,041 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/foo, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:04,042 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:04,043 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo. blk_-1876826436800622969_1002
2011-08-09 19:24:04,044 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:52245
2011-08-09 19:24:04,044 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:52245
2011-08-09 19:24:04,045 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:04,046 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1876826436800622969_1002 src: /127.0.0.1:55877 dest: /127.0.0.1:52245
2011-08-09 19:24:04,050 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-1876826436800622969_1002 wrote packet seqno:0 size:129 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:04,053 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:52245 is added to blk_-1876826436800622969_1002 size 100
2011-08-09 19:24:04,052 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:55877, dest: /127.0.0.1:52245, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_-39028894, offset: 0, srvID: DS-723207322-10.0.62.238-52245-1312910643981, blockid: blk_-1876826436800622969_1002, duration: 1713611
2011-08-09 19:24:04,054 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1876826436800622969_1002 terminating
2011-08-09 19:24:04,087 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:04,087 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-1876826436800622969_1002
2011-08-09 19:24:04,090 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 56, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, -27, -12, 44, 76, -79, 111, -50, -121, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:04,091 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 56, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 49, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, -27, -12, 44, 76, -79, 111, -50, -121, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:04,091 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /foo is closed by DFSClient_-39028894
2011-08-09 19:24:04,091 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:04,092 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:04,093 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/bar, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:04,093 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:04,094 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /bar. blk_8214554301653665802_1002
2011-08-09 19:24:04,095 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:52245
2011-08-09 19:24:04,095 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:52245
2011-08-09 19:24:04,096 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:04,096 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8214554301653665802_1002 src: /127.0.0.1:55878 dest: /127.0.0.1:52245
2011-08-09 19:24:04,098 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_8214554301653665802_1002 wrote packet seqno:0 size:229 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:04,100 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:52245 is added to blk_8214554301653665802_1002 size 200
2011-08-09 19:24:04,101 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:55878, dest: /127.0.0.1:52245, bytes: 200, op: HDFS_WRITE, cliID: DFSClient_-39028894, offset: 0, srvID: DS-723207322-10.0.62.238-52245-1312910643981, blockid: blk_8214554301653665802_1002, duration: 1075339
2011-08-09 19:24:04,101 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_8214554301653665802_1002 terminating
2011-08-09 19:24:04,101 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:04,102 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_8214554301653665802_1002
2011-08-09 19:24:04,106 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 49, 48, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, 113, -1, -11, -99, 98, 57, 72, 10, 0, 0, 0, 0, 0, 0, 0, -56, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:04,107 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 49, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 49, 48, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 52, 48, 51, 55, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, 113, -1, -11, -99, 98, 57, 72, 10, 0, 0, 0, 0, 0, 0, 0, -56, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:04,108 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /bar is closed by DFSClient_-39028894
2011-08-09 19:24:04,108 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:04,108 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:04,111 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null
2011-08-09 19:24:04,112 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/bar	dst=null	perm=null
2011-08-09 19:24:04,113 WARN  hdfs.DFSClient (DFSClient.java:blockSeekTo(2158)) - blockSeekTo shortCircuitLocalReads false localhost alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:52245
2011-08-09 19:24:04,115 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:52245, dest: /127.0.0.1:55879, bytes: 104, op: HDFS_READ, cliID: DFSClient_-39028894, offset: 0, srvID: DS-723207322-10.0.62.238-52245-1312910643981, blockid: blk_-1876826436800622969_1002, duration: 292868
2011-08-09 19:24:04,116 WARN  hdfs.DFSClient (DFSClient.java:blockSeekTo(2158)) - blockSeekTo shortCircuitLocalReads false localhost alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:52245
2011-08-09 19:24:04,119 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:52245, dest: /127.0.0.1:55880, bytes: 204, op: HDFS_READ, cliID: DFSClient_-39028894, offset: 0, srvID: DS-723207322-10.0.62.238-52245-1312910643981, blockid: blk_8214554301653665802_1002, duration: 403252
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:24:04,130 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:04,231 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47543
2011-08-09 19:24:04,231 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47543: exiting
2011-08-09 19:24:04,236 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47543: exiting
2011-08-09 19:24:04,238 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47543
2011-08-09 19:24:04,236 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47543: exiting
2011-08-09 19:24:04,239 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:04,239 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:04,239 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:52245, storageID=DS-723207322-10.0.62.238-52245-1312910643981, infoPort=43412, ipcPort=47543):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:05,007 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:05,026 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 2 time(s).
2011-08-09 19:24:05,239 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:05,240 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:52245, storageID=DS-723207322-10.0.62.238-52245-1312910643981, infoPort=43412, ipcPort=47543):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:05,241 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47543
2011-08-09 19:24:05,242 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:05,243 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:05,243 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:05,244 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:05,262 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:05,363 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:05,363 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:05,364 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:05,364 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:05,364 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:7 
2011-08-09 19:24:05,365 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:05,366 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35168
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 35168: exiting
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 35168: exiting
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 35168: exiting
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 35168: exiting
2011-08-09 19:24:05,367 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 35168: exiting
2011-08-09 19:24:05,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 35168: exiting
2011-08-09 19:24:05,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 35168: exiting
2011-08-09 19:24:05,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 35168: exiting
2011-08-09 19:24:05,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 35168: exiting
2011-08-09 19:24:05,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 35168: exiting
2011-08-09 19:24:05,369 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 35168
testLeaseExpireHardLimit start
2011-08-09 19:24:05,376 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:05,396 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:05,396 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:05,397 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:05,397 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:05,403 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:05,404 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:05,404 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:05,404 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:05,414 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:05,414 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:05,562 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:05,563 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:05,563 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:05,574 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:05,577 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:05,577 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:05,578 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:05,578 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:05,579 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:05,589 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:05,590 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:05,593 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:05,593 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:05,593 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:05,593 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:05,593 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:05,601 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:05,602 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:05,602 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:05,602 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:05,606 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:05,607 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:05,608 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:05,611 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:05,612 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:05,612 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:05,612 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:05,612 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:05,636 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:05,636 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:05,636 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 35 msecs
2011-08-09 19:24:05,637 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:05,640 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:05,640 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:05,640 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:05,640 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:05,641 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:05,642 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:05,644 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=53785
2011-08-09 19:24:05,645 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:53785
2011-08-09 19:24:05,645 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:05,645 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53785: starting
2011-08-09 19:24:05,646 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53785: starting
2011-08-09 19:24:05,646 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53785: starting
2011-08-09 19:24:05,646 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 53785: starting
2011-08-09 19:24:05,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 53785: starting
2011-08-09 19:24:05,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 53785: starting
2011-08-09 19:24:05,656 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:05,656 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:05,657 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:05,657 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:05,657 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:05,699 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:05,700 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:05,701 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:05,701 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48432 webServer.getConnectors()[0].getLocalPort() returned 48432
2011-08-09 19:24:05,701 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48432
2011-08-09 19:24:05,702 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:05,779 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48432
2011-08-09 19:24:05,820 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:48432
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:05,834 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:24:05,834 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:05,850 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:24:05,850 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:06,029 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 3 time(s).
2011-08-09 19:24:06,040 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:06,042 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40754
2011-08-09 19:24:06,043 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:06,047 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:06,048 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:06,048 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 33725 webServer.getConnectors()[0].getLocalPort() returned 33725
2011-08-09 19:24:06,048 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 33725
2011-08-09 19:24:06,049 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:06,115 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:33725
2011-08-09 19:24:06,116 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:06,121 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:06,123 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=50415
2011-08-09 19:24:06,124 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:06,147 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50415: starting
2011-08-09 19:24:06,148 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50415: starting
2011-08-09 19:24:06,148 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50415: starting
2011-08-09 19:24:06,191 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40754, storageID=, infoPort=33725, ipcPort=50415)
2011-08-09 19:24:06,191 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50415: starting
2011-08-09 19:24:06,196 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40754 storage DS-364323547-10.0.62.238-40754-1312910646194
2011-08-09 19:24:06,197 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40754
2011-08-09 19:24:06,202 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-364323547-10.0.62.238-40754-1312910646194 is assigned to data-node 127.0.0.1:40754
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:24:06,204 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:06,205 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:06,221 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:24:06,257 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:06,259 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:06,260 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40754 0 blocks shortCircuit first report.
2011-08-09 19:24:06,262 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:24:06,262 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:06,263 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:06,276 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:24:06,276 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:06,461 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:06,462 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 35796
2011-08-09 19:24:06,463 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:06,465 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:06,466 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:06,473 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36721 webServer.getConnectors()[0].getLocalPort() returned 36721
2011-08-09 19:24:06,474 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36721
2011-08-09 19:24:06,474 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:06,542 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36721
2011-08-09 19:24:06,543 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:06,548 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:06,551 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=45592
2011-08-09 19:24:06,552 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:06,553 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45592: starting
2011-08-09 19:24:06,595 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45592: starting
2011-08-09 19:24:06,597 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45592: starting
2011-08-09 19:24:06,596 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:35796, storageID=, infoPort=36721, ipcPort=45592)
2011-08-09 19:24:06,595 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45592: starting
2011-08-09 19:24:06,603 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:35796 storage DS-411078744-10.0.62.238-35796-1312910646600
2011-08-09 19:24:06,604 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:35796
2011-08-09 19:24:06,610 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-411078744-10.0.62.238-35796-1312910646600 is assigned to data-node 127.0.0.1:35796
2011-08-09 19:24:06,611 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:24:06,612 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:06,617 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:06,620 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:35796 0 blocks shortCircuit first report.
2011-08-09 19:24:06,621 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:24:06,621 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:06,622 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:06,624 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:24:06,624 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:06,640 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:24:06,641 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:06,834 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:06,835 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54237
2011-08-09 19:24:06,835 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:06,838 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:06,839 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:06,839 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39632 webServer.getConnectors()[0].getLocalPort() returned 39632
2011-08-09 19:24:06,839 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39632
2011-08-09 19:24:06,840 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:06,902 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39632
2011-08-09 19:24:06,903 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:06,908 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:06,910 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=35402
2011-08-09 19:24:06,912 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:06,939 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 35402: starting
2011-08-09 19:24:06,940 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 35402: starting
2011-08-09 19:24:06,941 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54237, storageID=, infoPort=39632, ipcPort=35402)
2011-08-09 19:24:06,941 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 35402: starting
2011-08-09 19:24:06,978 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 35402: starting
2011-08-09 19:24:06,983 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54237 storage DS-610767949-10.0.62.238-54237-1312910646981
2011-08-09 19:24:06,983 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54237
2011-08-09 19:24:06,989 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-610767949-10.0.62.238-54237-1312910646981 is assigned to data-node 127.0.0.1:54237
2011-08-09 19:24:06,990 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54237, storageID=DS-610767949-10.0.62.238-54237-1312910646981, infoPort=39632, ipcPort=35402)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:06,992 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:06,996 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:06,997 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54237 0 blocks shortCircuit first report.
2011-08-09 19:24:06,998 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:24:06,999 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:07,001 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /TestFileCreation/foo with 3 replica.
2011-08-09 19:24:07,009 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /TestFileCreation/foo: masked=rwxr-xr-x
2011-08-09 19:24:07,012 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/TestFileCreation/foo, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:07,013 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:07,014 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:07,014 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:07,015 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:07,015 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 50, 49, 51, 54, 53, 54, 53, 53, 56, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:07,015 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 50, 49, 51, 54, 53, 54, 53, 53, 56, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:07,017 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:07,018 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:07,018 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 204
2011-08-09 19:24:07,021 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:07,022 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:07,022 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 204
2011-08-09 19:24:07,025 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestFileCreation/foo	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:07,027 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/TestFileCreation/foo, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:07,027 DEBUG hdfs.DFSClient (DFSClient.java:sync(3737)) - DFSClient flush() : saveOffset 0 bytesCurBlock 9 lastFlushOffset -1
2011-08-09 19:24:07,028 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:07,031 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestFileCreation/foo. blk_5289914114283556282_1001
2011-08-09 19:24:07,032 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:40754
2011-08-09 19:24:07,032 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:54237
2011-08-09 19:24:07,032 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:35796
2011-08-09 19:24:07,032 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:40754
2011-08-09 19:24:07,033 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:07,034 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5289914114283556282_1001 src: /127.0.0.1:60983 dest: /127.0.0.1:40754
2011-08-09 19:24:07,036 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5289914114283556282_1001 src: /127.0.0.1:47303 dest: /127.0.0.1:54237
2011-08-09 19:24:07,037 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 4 time(s).
2011-08-09 19:24:07,082 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5289914114283556282_1001 src: /127.0.0.1:55202 dest: /127.0.0.1:35796
2011-08-09 19:24:07,085 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_5289914114283556282_1001 wrote packet seqno:0 size:38 offsetInBlock:0 lastPacketInBlock:false
2011-08-09 19:24:07,100 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:07,101 INFO  hdfs.StateChange (FSNamesystem.java:fsync(2430)) - BLOCK* NameSystem.fsync: file /TestFileCreation/foo for DFSClient_2136565587
2011-08-09 19:24:07,102 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, 73, 105, -116, -36, 26, 50, 77, -70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 50, 49, 51, 54, 53, 54, 53, 53, 56, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:07,102 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, 73, 105, -116, -36, 26, 50, 77, -70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 50, 49, 51, 54, 53, 54, 53, 53, 56, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:07,102 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 151
2011-08-09 19:24:07,103 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 151
2011-08-09 19:24:07,105 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:08,080 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 5 time(s).
2011-08-09 19:24:09,080 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 6 time(s).
2011-08-09 19:24:09,105 INFO  namenode.LeaseManager (LeaseManager.java:checkLeases(389)) - Lease [Lease.  Holder: DFSClient_2136565587, pendingcreates: 1] has expired hard limit
2011-08-09 19:24:09,105 INFO  namenode.FSNamesystem (FSNamesystem.java:internalReleaseLease(2452)) - Recovering lease=[Lease.  Holder: DFSClient_2136565587, pendingcreates: 1], src=/TestFileCreation/foo
2011-08-09 19:24:09,106 INFO  hdfs.StateChange (INodeFileUnderConstruction.java:assignPrimaryDatanode(163)) - BLOCK* blk_5289914114283556282_1001 recovery started, primary=127.0.0.1:40754
2011-08-09 19:24:09,223 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - NameNode calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:09,223 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:09,226 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:09,266 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:35796 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:09,273 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:09,273 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:09,274 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5289914114283556282_1001(length=9), newblock=blk_5289914114283556282_1002(length=9), datanode=127.0.0.1:40754
2011-08-09 19:24:09,275 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5289914114283556282_1001 java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:40754 remote=/127.0.0.1:60983]. 0 millis timeout left.
2011-08-09 19:24:09,275 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5289914114283556282_1001 received exception java.io.IOException: Interrupted receiveBlock
2011-08-09 19:24:09,275 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415):DataXceiver
java.io.IOException: Interrupted receiveBlock
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:582)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:09,275 WARN  hdfs.DFSClient (DFSClient.java:run(3117)) - DFSOutputStream ResponseProcessor exception  for block blk_5289914114283556282_1001java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3071)

2011-08-09 19:24:09,276 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5289914114283556282_1001 java.io.EOFException: while trying to read 38 bytes
2011-08-09 19:24:09,276 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_5289914114283556282_1001 2 Exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 117824 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:09,276 INFO  datanode.DataNode (BlockReceiver.java:run(930)) - PacketResponder blk_5289914114283556282_1001 2 : Thread is interrupted.
2011-08-09 19:24:09,276 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_5289914114283556282_1001 terminating
2011-08-09 19:24:09,277 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_5289914114283556282_1001 1 Exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:55202 remote=/127.0.0.1:35796]. 57823 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:09,278 INFO  datanode.DataNode (BlockReceiver.java:run(930)) - PacketResponder blk_5289914114283556282_1001 1 : Thread is interrupted.
2011-08-09 19:24:09,278 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5289914114283556282_1001 terminating
2011-08-09 19:24:09,277 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:09,278 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5289914114283556282_1001 received exception java.io.EOFException: while trying to read 38 bytes
2011-08-09 19:24:09,278 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:09,279 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:54237, storageID=DS-610767949-10.0.62.238-54237-1312910646981, infoPort=39632, ipcPort=35402):DataXceiver
java.io.EOFException: while trying to read 38 bytes
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:277)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:09,280 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5289914114283556282_1001 java.io.EOFException: while trying to read 38 bytes
2011-08-09 19:24:09,280 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(780)) - PacketResponder 0 for block blk_5289914114283556282_1001 Interrupted.
2011-08-09 19:24:09,280 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5289914114283556282_1001 terminating
2011-08-09 19:24:09,284 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5289914114283556282_1001 received exception java.io.EOFException: while trying to read 38 bytes
2011-08-09 19:24:09,284 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592):DataXceiver
java.io.EOFException: while trying to read 38 bytes
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:277)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:09,284 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5289914114283556282_1002 of size 9 as part of lease recovery.
2011-08-09 19:24:09,286 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5289914114283556282_1001(length=9), newblock=blk_5289914114283556282_1002(length=9), datanode=127.0.0.1:54237
2011-08-09 19:24:09,289 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:09,289 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:09,290 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5289914114283556282_1002 of size 9 as part of lease recovery.
2011-08-09 19:24:09,291 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5289914114283556282_1002 on 127.0.0.1:40754 size 9 But it does not belong to any file.
2011-08-09 19:24:09,292 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5289914114283556282_1002 on 127.0.0.1:54237 size 9 But it does not belong to any file.
2011-08-09 19:24:09,293 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5289914114283556282_1001(length=9), newblock=blk_5289914114283556282_1002(length=9), datanode=127.0.0.1:35796
2011-08-09 19:24:09,294 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5289914114283556282_1002 of size 9 as part of lease recovery.
2011-08-09 19:24:09,294 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:09,295 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5289914114283556282_1002 on 127.0.0.1:35796 size 9 But it does not belong to any file.
2011-08-09 19:24:09,295 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2544)) - commitBlockSynchronization(lastblock=blk_5289914114283556282_1001, newgenerationstamp=1002, newlength=9, newtargets=[127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796], closeFile=true, deleteBlock=false)
2011-08-09 19:24:09,296 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6049)) - blk_5289914114283556282_1001 is beening recovered, ignoring this request.
2011-08-09 19:24:09,296 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 7 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is beening recovered, ignoring this request.
java.io.IOException: blk_5289914114283556282_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:09,296 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 57, 50, 57, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, 73, 105, -116, -36, 26, 50, 77, -70, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:09,297 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 21, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 57, 50, 57, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 52, 55, 48, 49, 52, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, 73, 105, -116, -36, 26, 50, 77, -70, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:09,298 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 131
2011-08-09 19:24:09,297 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2e29d50d) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:09,299 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 131
2011-08-09 19:24:09,300 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 1 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Will retry...
2011-08-09 19:24:09,300 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2625)) - commitBlockSynchronization(newblock=blk_5289914114283556282_1002, file=/TestFileCreation/foo, newgenerationstamp=1002, newlength=9, newtargets=[127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796]) successful
2011-08-09 19:24:10,081 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 7 time(s).
2011-08-09 19:24:10,300 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:10,300 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:10,302 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:10,302 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:10,304 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:10,305 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:10,305 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:10,305 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2144c5bb) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:10,306 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 2 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Will retry...
2011-08-09 19:24:11,081 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 8 time(s).
2011-08-09 19:24:11,306 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:11,306 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:11,308 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:11,308 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:11,309 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:11,310 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:11,310 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 5 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:11,311 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@6c10a234) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:11,312 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 3 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Will retry...
2011-08-09 19:24:12,083 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 9 time(s).
2011-08-09 19:24:12,084 WARN  hdfs.DFSClient (DFSClient.java:run(1571)) - Problem renewing lease for DFSClient_-1371552601 for a period of 30 seconds. Will retry shortly...
java.net.ConnectException: Call to localhost/127.0.0.1:41716 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:791)
	at org.apache.hadoop.ipc.Client.call(Client.java:767)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1542)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1562)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:405)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:324)
	at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:196)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:884)
	at org.apache.hadoop.ipc.Client.call(Client.java:744)
	... 12 more
2011-08-09 19:24:12,105 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/TestFileCreation/foo	dst=null	perm=null
blockfile=/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_5289914114283556282
blockfile=/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_5289914114283556282
blockfile=/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_5289914114283556282
successcount=3
2011-08-09 19:24:12,107 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/TestFileCreation/foo, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:12,108 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:12,108 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:12,109 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:12,109 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:12,110 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:12,111 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:12,111 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 9 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:12,112 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@631e1aa5) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:12,113 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 4 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Will retry...
2011-08-09 19:24:13,113 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:13,113 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:13,115 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:13,116 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:13,118 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:13,118 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:13,119 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:13,145 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@1ca53e68) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:13,159 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 5 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Will retry...
2011-08-09 19:24:14,087 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 0 time(s).
2011-08-09 19:24:14,159 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5289914114283556282_1001 bad datanode[0] 127.0.0.1:40754
2011-08-09 19:24:14,159 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5289914114283556282_1001 in pipeline 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796: bad datanode 127.0.0.1:40754
2011-08-09 19:24:14,161 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237, 127.0.0.1:35796])
2011-08-09 19:24:14,161 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592))
2011-08-09 19:24:14,162 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:35796
2011-08-09 19:24:14,163 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:14,163 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:14,164 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 45592, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@1c571cc4) from 127.0.0.1:49196: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:14,165 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3246)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:35796 failed 6 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237, 127.0.0.1:35796. Marking primary datanode as bad.
2011-08-09 19:24:15,088 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 1 time(s).
2011-08-09 19:24:15,169 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:15,169 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:15,169 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:15,172 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:15,172 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:15,173 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@513e86ec) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:15,174 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 1 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Will retry...
2011-08-09 19:24:16,090 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 2 time(s).
2011-08-09 19:24:16,176 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:16,177 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:16,177 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:16,179 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:16,179 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 5 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:16,186 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@54fe0ce1) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:16,187 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 2 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Will retry...
2011-08-09 19:24:17,092 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 3 time(s).
2011-08-09 19:24:17,189 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:17,189 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:17,190 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:17,192 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:17,192 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 9 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:17,194 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2e807f85) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:17,195 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 3 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Will retry...
2011-08-09 19:24:18,093 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 4 time(s).
2011-08-09 19:24:18,197 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:18,197 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:18,197 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:18,199 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:18,199 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:18,200 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2e4f7bc2) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:18,201 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 4 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Will retry...
2011-08-09 19:24:19,095 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 5 time(s).
2011-08-09 19:24:19,203 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:19,203 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:19,203 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:19,205 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:19,205 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:19,206 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@f6b7e0e) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:19,207 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 5 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Will retry...
2011-08-09 19:24:20,096 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 6 time(s).
2011-08-09 19:24:20,209 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:40754, 127.0.0.1:54237])
2011-08-09 19:24:20,209 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:40754
2011-08-09 19:24:20,209 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54237 (dnReg=DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415))
2011-08-09 19:24:20,213 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:20,213 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:20,214 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 50415, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@670b5064) from 127.0.0.1:44831: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:20,215 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3246)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:40754 failed 6 times.  Pipeline was 127.0.0.1:40754, 127.0.0.1:54237. Marking primary datanode as bad.
2011-08-09 19:24:21,098 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 7 time(s).
2011-08-09 19:24:21,219 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:21,219 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:21,220 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:21,220 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 5 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:21,221 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@1ab2f2d6) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:21,222 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 1 times.  Pipeline was 127.0.0.1:54237. Will retry...
2011-08-09 19:24:22,098 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 8 time(s).
2011-08-09 19:24:22,224 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:22,224 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:22,225 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:22,225 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 9 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:22,227 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@72ebbf5c) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:22,228 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 2 times.  Pipeline was 127.0.0.1:54237. Will retry...
2011-08-09 19:24:23,099 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 9 time(s).
2011-08-09 19:24:23,099 WARN  hdfs.DFSClient (DFSClient.java:run(1571)) - Problem renewing lease for DFSClient_-1371552601 for a period of 30 seconds. Will retry shortly...
java.net.ConnectException: Call to localhost/127.0.0.1:41716 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:791)
	at org.apache.hadoop.ipc.Client.call(Client.java:767)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1542)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1562)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:405)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:324)
	at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:196)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:884)
	at org.apache.hadoop.ipc.Client.call(Client.java:744)
	... 11 more
2011-08-09 19:24:23,229 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:23,230 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:23,231 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:23,231 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:23,232 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@684be8b8) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:23,233 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 3 times.  Pipeline was 127.0.0.1:54237. Will retry...
2011-08-09 19:24:24,236 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:24,236 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:24,237 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:24,237 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:24,239 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@490eb6ae) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:24,240 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 4 times.  Pipeline was 127.0.0.1:54237. Will retry...
2011-08-09 19:24:25,100 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 0 time(s).
2011-08-09 19:24:25,241 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:25,242 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:25,242 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:25,243 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:25,244 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@3a2c4ede) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:25,245 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 5 times.  Pipeline was 127.0.0.1:54237. Will retry...
2011-08-09 19:24:26,101 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 1 time(s).
2011-08-09 19:24:26,246 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5289914114283556282_1001, targets=[127.0.0.1:54237])
2011-08-09 19:24:26,246 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:54237
2011-08-09 19:24:26,247 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5289914114283556282_1001 is already commited, storedBlock == null.
2011-08-09 19:24:26,247 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 7 on 53785, call nextGenerationStamp(blk_5289914114283556282_1001) from 127.0.0.1:36443: error: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:26,249 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 35402, call recoverBlock(blk_5289914114283556282_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@3485def8) from 127.0.0.1:54730: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5289914114283556282_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:24:26,249 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3260)) - Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 6 times.  Pipeline was 127.0.0.1:54237. Aborting...
2011-08-09 19:24:26,250 ERROR hdfs.DFSClient (DFSClient.java:close(1511)) - Exception closing file /TestFileCreation/foo : java.io.IOException: Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 6 times.  Pipeline was 127.0.0.1:54237. Aborting...
java.io.IOException: Error Recovery for block blk_5289914114283556282_1001 failed  because recovery from primary datanode 127.0.0.1:54237 failed 6 times.  Pipeline was 127.0.0.1:54237. Aborting...
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:3261)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2400(DFSClient.java:2676)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2912)
2011-08-09 19:24:26,250 DEBUG hdfs.DFSClient (DFSClient.java:interruptAndJoin(1498)) - Wait for lease checker to terminate
2011-08-09 19:24:26,251 DEBUG hdfs.DFSClient (DFSClient.java:run(1581)) - LeaseChecker@DFSClient[clientName=DFSClient_2136565587, ugi=jeff,jeff]: java.lang.Throwable: for testing
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.toString(DFSClient.java:1592)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1581)
	at java.lang.Thread.run(Thread.java:662)
 is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1578)
	at java.lang.Thread.run(Thread.java:662)
Shutting down the Mini HDFS Cluster
Shutting down DataNode 2
2011-08-09 19:24:26,253 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:26,354 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35402
2011-08-09 19:24:26,354 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 35402: exiting
2011-08-09 19:24:26,355 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54237, storageID=DS-610767949-10.0.62.238-54237-1312910646981, infoPort=39632, ipcPort=35402):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:26,355 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 35402
2011-08-09 19:24:26,355 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 35402: exiting
2011-08-09 19:24:26,356 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:26,354 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 35402: exiting
2011-08-09 19:24:26,397 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:26,398 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:26,399 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54237, storageID=DS-610767949-10.0.62.238-54237-1312910646981, infoPort=39632, ipcPort=35402):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:26,399 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35402
2011-08-09 19:24:26,399 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:26,400 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:26,400 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:26,401 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:24:26,451 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:26,552 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45592
2011-08-09 19:24:26,552 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45592: exiting
2011-08-09 19:24:26,552 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45592
2011-08-09 19:24:26,552 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45592: exiting
2011-08-09 19:24:26,553 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45592: exiting
2011-08-09 19:24:26,554 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:26,555 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:26,555 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:26,556 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:26,556 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:35796, storageID=DS-411078744-10.0.62.238-35796-1312910646600, infoPort=36721, ipcPort=45592):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:24:26,557 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45592
2011-08-09 19:24:26,557 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:26,557 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:26,557 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:26,559 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:24:26,609 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:26,710 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50415
2011-08-09 19:24:26,710 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50415: exiting
2011-08-09 19:24:26,710 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50415: exiting
2011-08-09 19:24:26,711 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50415: exiting
2011-08-09 19:24:26,711 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50415
2011-08-09 19:24:26,711 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 2
2011-08-09 19:24:26,712 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:26,712 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:27,102 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 2 time(s).
2011-08-09 19:24:27,239 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40754, storageID=DS-364323547-10.0.62.238-40754-1312910646194, infoPort=33725, ipcPort=50415):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:27,240 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50415
2011-08-09 19:24:27,240 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:27,240 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:27,241 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:27,241 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:27,712 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:27,713 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:27,724 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:27,826 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:27,826 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:27,826 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:27,827 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:24:27,827 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:27,828 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:27,830 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:27,830 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53785
2011-08-09 19:24:27,831 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53785: exiting
2011-08-09 19:24:27,831 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53785: exiting
2011-08-09 19:24:27,831 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53785: exiting
2011-08-09 19:24:27,831 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 53785: exiting
2011-08-09 19:24:27,831 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 53785: exiting
2011-08-09 19:24:27,832 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 53785: exiting
2011-08-09 19:24:27,927 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53785
testLeaseExpireHardLimit successful
2011-08-09 19:24:27,927 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:27,833 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 53785: exiting
test file system close start
2011-08-09 19:24:27,832 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 53785: exiting
2011-08-09 19:24:27,832 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 53785: exiting
2011-08-09 19:24:27,832 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 53785: exiting
2011-08-09 19:24:27,946 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:27,946 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:27,947 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:27,947 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:27,952 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:27,952 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:27,952 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:27,952 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:27,964 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:27,964 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:27,965 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:27,965 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:27,989 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:28,000 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:28,003 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:28,003 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:28,004 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:28,004 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:28,004 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:28,015 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:28,015 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:28,018 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:28,018 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:28,018 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:28,018 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:28,018 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:28,024 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:28,024 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:28,024 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:28,024 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:28,027 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:28,028 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:28,028 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:28,032 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:28,032 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:28,032 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:28,033 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:28,033 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:28,055 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:28,056 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:28,056 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 32 msecs
2011-08-09 19:24:28,056 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:28,059 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:28,059 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:28,060 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:28,060 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:28,060 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:28,062 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:28,064 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=51121
2011-08-09 19:24:28,064 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:51121
2011-08-09 19:24:28,064 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:28,065 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51121: starting
2011-08-09 19:24:28,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51121: starting
2011-08-09 19:24:28,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51121: starting
2011-08-09 19:24:28,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51121: starting
2011-08-09 19:24:28,066 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 51121: starting
2011-08-09 19:24:28,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 51121: starting
2011-08-09 19:24:28,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 51121: starting
2011-08-09 19:24:28,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 51121: starting
2011-08-09 19:24:28,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 51121: starting
2011-08-09 19:24:28,067 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 51121: starting
2011-08-09 19:24:28,068 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 51121: starting
2011-08-09 19:24:28,115 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 3 time(s).
2011-08-09 19:24:28,118 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:28,119 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:28,119 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:28,119 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:28,119 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:28,120 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:28,121 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:28,124 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:28,124 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39977 webServer.getConnectors()[0].getLocalPort() returned 39977
2011-08-09 19:24:28,124 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39977
2011-08-09 19:24:28,124 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:28,176 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39977
2011-08-09 19:24:28,177 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:39977
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:28,183 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:24:28,183 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:28,198 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:24:28,198 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:28,400 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:28,402 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38946
2011-08-09 19:24:28,402 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:28,405 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:28,406 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:28,406 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59287 webServer.getConnectors()[0].getLocalPort() returned 59287
2011-08-09 19:24:28,407 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59287
2011-08-09 19:24:28,407 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:28,491 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59287
2011-08-09 19:24:28,492 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:28,497 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:28,499 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=33439
2011-08-09 19:24:28,500 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:28,501 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 33439: starting
2011-08-09 19:24:28,501 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 33439: starting
2011-08-09 19:24:28,527 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 33439: starting
2011-08-09 19:24:28,528 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 33439: starting
2011-08-09 19:24:28,527 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38946, storageID=, infoPort=59287, ipcPort=33439)
2011-08-09 19:24:28,534 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38946 storage DS-424958807-10.0.62.238-38946-1312910668531
2011-08-09 19:24:28,535 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38946
2011-08-09 19:24:28,540 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-424958807-10.0.62.238-38946-1312910668531 is assigned to data-node 127.0.0.1:38946
2011-08-09 19:24:28,542 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38946, storageID=DS-424958807-10.0.62.238-38946-1312910668531, infoPort=59287, ipcPort=33439)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:24:28,582 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:28,589 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:28,590 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38946 0 blocks shortCircuit first report.
2011-08-09 19:24:28,591 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:24:28,591 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:28,593 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:28,593 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:24:28,594 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:28,610 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:24:28,610 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:28,786 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:28,787 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37581
2011-08-09 19:24:28,787 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:28,790 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:28,791 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:28,792 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 54350 webServer.getConnectors()[0].getLocalPort() returned 54350
2011-08-09 19:24:28,792 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 54350
2011-08-09 19:24:28,792 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:28,858 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:54350
2011-08-09 19:24:28,858 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:28,863 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:28,866 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=44484
2011-08-09 19:24:28,867 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:28,867 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44484: starting
2011-08-09 19:24:28,869 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44484: starting
2011-08-09 19:24:28,869 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37581, storageID=, infoPort=54350, ipcPort=44484)
2011-08-09 19:24:28,870 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44484: starting
2011-08-09 19:24:28,870 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44484: starting
2011-08-09 19:24:28,874 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37581 storage DS-433702742-10.0.62.238-37581-1312910668872
2011-08-09 19:24:28,875 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37581
2011-08-09 19:24:28,881 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-433702742-10.0.62.238-37581-1312910668872 is assigned to data-node 127.0.0.1:37581
2011-08-09 19:24:28,882 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37581, storageID=DS-433702742-10.0.62.238-37581-1312910668872, infoPort=54350, ipcPort=44484)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:24:28,884 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:28,911 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:28,913 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37581 0 blocks shortCircuit first report.
2011-08-09 19:24:28,913 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:24:28,914 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:28,916 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:28,917 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:24:28,917 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:28,934 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:24:28,934 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:29,099 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:29,100 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 58908
2011-08-09 19:24:29,100 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:29,106 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:29,106 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:29,107 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44416 webServer.getConnectors()[0].getLocalPort() returned 44416
2011-08-09 19:24:29,107 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44416
2011-08-09 19:24:29,107 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:29,124 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 4 time(s).
2011-08-09 19:24:29,224 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44416
2011-08-09 19:24:29,225 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:29,230 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:29,233 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=44213
2011-08-09 19:24:29,234 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:29,235 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44213: starting
2011-08-09 19:24:29,235 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44213: starting
2011-08-09 19:24:29,237 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44213: starting
2011-08-09 19:24:29,237 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:58908, storageID=, infoPort=44416, ipcPort=44213)
2011-08-09 19:24:29,237 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44213: starting
2011-08-09 19:24:29,242 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:58908 storage DS-271415272-10.0.62.238-58908-1312910669240
2011-08-09 19:24:29,243 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:58908
2011-08-09 19:24:29,249 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-271415272-10.0.62.238-58908-1312910669240 is assigned to data-node 127.0.0.1:58908
2011-08-09 19:24:29,250 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:58908, storageID=DS-271415272-10.0.62.238-58908-1312910669240, infoPort=44416, ipcPort=44213)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:29,251 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:29,256 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:29,258 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:58908 0 blocks shortCircuit first report.
2011-08-09 19:24:29,259 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:24:29,259 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:29,259 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /TestFileCreation/foofs with 3 replica.
2011-08-09 19:24:29,289 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /TestFileCreation/foofs: masked=rwxr-xr-x
2011-08-09 19:24:29,290 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/TestFileCreation/foofs, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:29,292 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:29,292 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:29,293 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:29,293 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:29,294 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 23, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 102, 115, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 54, 49, 49, 56, 51, 52, 54, 53, 53, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:29,294 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 23, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 102, 115, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 54, 49, 49, 56, 51, 52, 54, 53, 53, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:29,295 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:29,295 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:29,295 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 206
2011-08-09 19:24:29,301 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:29,302 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:29,302 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 206
2011-08-09 19:24:29,306 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestFileCreation/foofs	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:29,309 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/TestFileCreation/foofs, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:29,331 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:29,333 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestFileCreation/foofs. blk_-6088999457469770831_1001
2011-08-09 19:24:29,334 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:58908
2011-08-09 19:24:29,334 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:38946
2011-08-09 19:24:29,334 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:37581
2011-08-09 19:24:29,335 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:58908
2011-08-09 19:24:29,336 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:29,336 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6088999457469770831_1001 src: /127.0.0.1:47347 dest: /127.0.0.1:58908
2011-08-09 19:24:29,338 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6088999457469770831_1001 src: /127.0.0.1:50631 dest: /127.0.0.1:38946
2011-08-09 19:24:29,340 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6088999457469770831_1001 src: /127.0.0.1:45312 dest: /127.0.0.1:37581
2011-08-09 19:24:29,344 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-6088999457469770831_1001 wrote packet seqno:0 size:38 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:29,348 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:45312, dest: /127.0.0.1:37581, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_1611834655, offset: 0, srvID: DS-433702742-10.0.62.238-37581-1312910668872, blockid: blk_-6088999457469770831_1001, duration: 2828909
2011-08-09 19:24:29,348 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-6088999457469770831_1001 terminating
2011-08-09 19:24:29,349 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:37581 is added to blk_-6088999457469770831_1001 size 9
2011-08-09 19:24:29,350 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50631, dest: /127.0.0.1:38946, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_1611834655, offset: 0, srvID: DS-424958807-10.0.62.238-38946-1312910668531, blockid: blk_-6088999457469770831_1001, duration: 4629708
2011-08-09 19:24:29,351 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-6088999457469770831_1001 terminating
2011-08-09 19:24:29,354 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:38946 is added to blk_-6088999457469770831_1001 size 9
2011-08-09 19:24:29,355 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:47347, dest: /127.0.0.1:58908, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_1611834655, offset: 0, srvID: DS-271415272-10.0.62.238-58908-1312910669240, blockid: blk_-6088999457469770831_1001, duration: 9341297
2011-08-09 19:24:29,355 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-6088999457469770831_1001 terminating
2011-08-09 19:24:29,356 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:58908 is added to blk_-6088999457469770831_1001 size 9
2011-08-09 19:24:29,357 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:29,358 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-6088999457469770831_1001
2011-08-09 19:24:29,360 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 23, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 102, 115, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 51, 54, 48, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, -85, 127, -121, 65, 27, -9, -45, -79, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:29,360 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 23, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 102, 111, 111, 102, 115, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 51, 54, 48, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 54, 57, 50, 57, 50, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, -85, 127, -121, 65, 27, -9, -45, -79, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:29,360 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /TestFileCreation/foofs is closed by DFSClient_1611834655
2011-08-09 19:24:29,361 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 120
2011-08-09 19:24:29,362 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 120
2011-08-09 19:24:29,363 DEBUG hdfs.DFSClient (DFSClient.java:interruptAndJoin(1498)) - Wait for lease checker to terminate
2011-08-09 19:24:29,364 DEBUG hdfs.DFSClient (DFSClient.java:run(1581)) - LeaseChecker@DFSClient[clientName=DFSClient_1611834655, ugi=jeff,jeff]: java.lang.Throwable: for testing
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.toString(DFSClient.java:1592)
	at java.lang.String.valueOf(String.java:2826)
	at java.lang.StringBuilder.append(StringBuilder.java:115)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1581)
	at java.lang.Thread.run(Thread.java:662)
 is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1578)
	at java.lang.Thread.run(Thread.java:662)
testFsClose successful
Shutting down the Mini HDFS Cluster
Shutting down DataNode 2
2011-08-09 19:24:29,421 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:29,521 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44213
2011-08-09 19:24:29,522 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44213: exiting
2011-08-09 19:24:29,522 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44213: exiting
2011-08-09 19:24:29,523 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:29,524 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44213: exiting
2011-08-09 19:24:29,523 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:58908, storageID=DS-271415272-10.0.62.238-58908-1312910669240, infoPort=44416, ipcPort=44213):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:29,524 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44213
2011-08-09 19:24:29,522 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:30,125 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 5 time(s).
2011-08-09 19:24:30,261 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:30,524 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:30,524 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:58908, storageID=DS-271415272-10.0.62.238-58908-1312910669240, infoPort=44416, ipcPort=44213):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:30,525 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44213
2011-08-09 19:24:30,525 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:30,526 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:30,526 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:30,527 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:24:30,537 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:30,538 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44484
2011-08-09 19:24:30,538 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44484
2011-08-09 19:24:30,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44484: exiting
2011-08-09 19:24:30,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44484: exiting
2011-08-09 19:24:30,539 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44484: exiting
2011-08-09 19:24:30,539 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:30,540 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:30,541 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37581, storageID=DS-433702742-10.0.62.238-37581-1312910668872, infoPort=54350, ipcPort=44484):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:30,918 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:31,126 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 6 time(s).
2011-08-09 19:24:31,540 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:31,540 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37581, storageID=DS-433702742-10.0.62.238-37581-1312910668872, infoPort=54350, ipcPort=44484):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:24:31,541 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44484
2011-08-09 19:24:31,541 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:31,542 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:31,542 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:31,545 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:24:31,587 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:31,588 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33439
2011-08-09 19:24:31,588 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 33439: exiting
2011-08-09 19:24:31,588 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 33439: exiting
2011-08-09 19:24:31,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 33439: exiting
2011-08-09 19:24:31,591 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 33439
2011-08-09 19:24:31,592 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:31,593 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:31,593 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38946, storageID=DS-424958807-10.0.62.238-38946-1312910668531, infoPort=59287, ipcPort=33439):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:31,595 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:32,126 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 7 time(s).
2011-08-09 19:24:32,593 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:32,594 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38946, storageID=DS-424958807-10.0.62.238-38946-1312910668531, infoPort=59287, ipcPort=33439):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:32,595 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33439
2011-08-09 19:24:32,595 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:32,595 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:32,595 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:32,597 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:32,599 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:32,700 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:32,701 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:32,701 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:32,701 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:32,702 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:24:32,702 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:32,703 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:32,704 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51121
2011-08-09 19:24:32,705 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51121: exiting
2011-08-09 19:24:32,705 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51121: exiting
2011-08-09 19:24:32,705 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51121: exiting
2011-08-09 19:24:32,705 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 51121: exiting
2011-08-09 19:24:32,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 51121: exiting
2011-08-09 19:24:32,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 51121: exiting
2011-08-09 19:24:32,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 51121: exiting
2011-08-09 19:24:32,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 51121: exiting
2011-08-09 19:24:32,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 51121: exiting
2011-08-09 19:24:32,707 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 51121: exiting
2011-08-09 19:24:32,707 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51121
2011-08-09 19:24:32,709 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
test testFsCloseAfterClusterShutdown start
2011-08-09 19:24:32,727 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:32,727 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:32,727 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:32,728 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:32,733 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:32,734 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:32,734 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:32,734 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:32,742 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:32,742 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:32,743 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:32,890 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:32,891 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:32,903 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:32,906 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:32,906 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:32,907 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:32,907 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:32,907 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:32,917 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:32,918 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:32,921 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:32,921 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:32,921 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:32,921 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:32,922 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:32,929 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:32,929 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:32,929 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:32,929 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:32,933 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:32,933 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:32,934 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:32,938 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:32,938 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:32,938 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:32,939 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:32,939 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:32,962 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:32,963 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:32,963 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 34 msecs
2011-08-09 19:24:32,963 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:32,966 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:32,967 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:32,967 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:32,967 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:32,967 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:32,968 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:32,971 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=38377
2011-08-09 19:24:32,971 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:38377
2011-08-09 19:24:32,972 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:32,972 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 38377: starting
2011-08-09 19:24:32,973 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 38377: starting
2011-08-09 19:24:32,973 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 38377: starting
2011-08-09 19:24:32,973 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 38377: starting
2011-08-09 19:24:32,973 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 38377: starting
2011-08-09 19:24:32,973 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 38377: starting
2011-08-09 19:24:32,974 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 38377: starting
2011-08-09 19:24:32,974 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 38377: starting
2011-08-09 19:24:32,974 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 38377: starting
2011-08-09 19:24:32,974 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 38377: starting
2011-08-09 19:24:32,974 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 38377: starting
2011-08-09 19:24:33,024 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:33,024 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:33,025 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:33,025 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:33,066 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:33,067 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:33,069 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:33,069 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:33,070 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34462 webServer.getConnectors()[0].getLocalPort() returned 34462
2011-08-09 19:24:33,070 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34462
2011-08-09 19:24:33,070 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:33,124 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34462
2011-08-09 19:24:33,125 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:34462
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:33,127 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 8 time(s).
2011-08-09 19:24:33,132 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:24:33,132 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:33,148 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:24:33,148 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:33,321 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:33,323 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54305
2011-08-09 19:24:33,323 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:33,326 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:33,327 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:33,327 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58830 webServer.getConnectors()[0].getLocalPort() returned 58830
2011-08-09 19:24:33,327 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58830
2011-08-09 19:24:33,328 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:33,397 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58830
2011-08-09 19:24:33,398 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:33,403 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:33,405 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=37351
2011-08-09 19:24:33,406 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:33,447 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 37351: starting
2011-08-09 19:24:33,447 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 37351: starting
2011-08-09 19:24:33,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 37351: starting
2011-08-09 19:24:33,448 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54305, storageID=, infoPort=58830, ipcPort=37351)
2011-08-09 19:24:33,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 37351: starting
2011-08-09 19:24:33,456 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54305 storage DS-2063375514-10.0.62.238-54305-1312910673453
2011-08-09 19:24:33,456 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54305
2011-08-09 19:24:33,462 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2063375514-10.0.62.238-54305-1312910673453 is assigned to data-node 127.0.0.1:54305
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:24:33,464 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54305, storageID=DS-2063375514-10.0.62.238-54305-1312910673453, infoPort=58830, ipcPort=37351)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:33,465 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:33,513 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:33,514 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54305 0 blocks shortCircuit first report.
2011-08-09 19:24:33,514 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:24:33,515 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:33,655 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 143 msecs
2011-08-09 19:24:33,656 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:33,656 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:33,674 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:24:33,675 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:33,868 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:33,869 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 42580
2011-08-09 19:24:33,869 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:33,872 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:33,873 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:33,873 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57427 webServer.getConnectors()[0].getLocalPort() returned 57427
2011-08-09 19:24:33,874 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57427
2011-08-09 19:24:33,874 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:33,955 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57427
2011-08-09 19:24:33,956 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:33,961 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:33,963 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=52114
2011-08-09 19:24:33,964 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:33,965 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 52114: starting
2011-08-09 19:24:33,966 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 52114: starting
2011-08-09 19:24:33,967 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 52114: starting
2011-08-09 19:24:33,967 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:42580, storageID=, infoPort=57427, ipcPort=52114)
2011-08-09 19:24:33,967 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 52114: starting
2011-08-09 19:24:33,973 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:42580 storage DS-525628140-10.0.62.238-42580-1312910673970
2011-08-09 19:24:33,974 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:42580
2011-08-09 19:24:33,988 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-525628140-10.0.62.238-42580-1312910673970 is assigned to data-node 127.0.0.1:42580
2011-08-09 19:24:33,989 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:42580, storageID=DS-525628140-10.0.62.238-42580-1312910673970, infoPort=57427, ipcPort=52114)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:24:33,990 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:33,995 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:33,996 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:42580 0 blocks shortCircuit first report.
2011-08-09 19:24:33,997 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:24:33,997 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:33,998 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:34,002 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:24:34,002 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:34,017 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:24:34,017 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:34,128 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 9 time(s).
2011-08-09 19:24:34,131 WARN  hdfs.DFSClient (DFSClient.java:run(1571)) - Problem renewing lease for DFSClient_-1371552601 for a period of 30 seconds. Will retry shortly...
java.net.ConnectException: Call to localhost/127.0.0.1:41716 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:791)
	at org.apache.hadoop.ipc.Client.call(Client.java:767)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1542)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1562)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:405)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:324)
	at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:196)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:884)
	at org.apache.hadoop.ipc.Client.call(Client.java:744)
	... 11 more
2011-08-09 19:24:34,213 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:34,214 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37242
2011-08-09 19:24:34,215 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:34,217 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:34,218 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:34,219 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45180 webServer.getConnectors()[0].getLocalPort() returned 45180
2011-08-09 19:24:34,219 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45180
2011-08-09 19:24:34,219 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:34,306 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45180
2011-08-09 19:24:34,307 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:34,312 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:34,314 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=48443
2011-08-09 19:24:34,315 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:34,315 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48443: starting
2011-08-09 19:24:34,316 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48443: starting
2011-08-09 19:24:34,317 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48443: starting
2011-08-09 19:24:34,317 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37242, storageID=, infoPort=45180, ipcPort=48443)
2011-08-09 19:24:34,318 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48443: starting
2011-08-09 19:24:34,324 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37242 storage DS-932467330-10.0.62.238-37242-1312910674321
2011-08-09 19:24:34,325 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37242
2011-08-09 19:24:34,331 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-932467330-10.0.62.238-37242-1312910674321 is assigned to data-node 127.0.0.1:37242
2011-08-09 19:24:34,332 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37242, storageID=DS-932467330-10.0.62.238-37242-1312910674321, infoPort=45180, ipcPort=48443)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:34,333 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:34,363 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:34,368 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37242 0 blocks shortCircuit first report.
2011-08-09 19:24:34,370 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 8 msecs
2011-08-09 19:24:34,370 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:34,371 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
createFile: Created /TestFileCreation/dhrubashutdown with 3 replica.
2011-08-09 19:24:34,376 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /TestFileCreation/dhrubashutdown: masked=rwxr-xr-x
2011-08-09 19:24:34,377 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/TestFileCreation/dhrubashutdown, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:34,379 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:34,379 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:34,380 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:34,380 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [3, 0, 0, 0, 3, 0, 17, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 1, 48, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -19]
2011-08-09 19:24:34,380 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 32, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 100, 104, 114, 117, 98, 97, 115, 104, 117, 116, 100, 111, 119, 110, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 54, 56, 50, 50, 52, 54, 57, 54, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:34,381 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 32, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 100, 104, 114, 117, 98, 97, 115, 104, 117, 116, 100, 111, 119, 110, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 4, 56, 49, 57, 50, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 54, 56, 50, 50, 52, 54, 57, 54, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:34,381 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:34,381 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:34,382 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 215
2011-08-09 19:24:34,385 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:34,385 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:34,385 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 215
2011-08-09 19:24:34,388 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestFileCreation/dhrubashutdown	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:34,390 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/TestFileCreation/dhrubashutdown, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:34,390 DEBUG hdfs.DFSClient (DFSClient.java:sync(3737)) - DFSClient flush() : saveOffset 0 bytesCurBlock 16 lastFlushOffset -1
2011-08-09 19:24:34,391 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:34,395 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestFileCreation/dhrubashutdown. blk_-3056398956807621127_1001
2011-08-09 19:24:34,396 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:42580
2011-08-09 19:24:34,396 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:37242
2011-08-09 19:24:34,397 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:54305
2011-08-09 19:24:34,397 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:42580
2011-08-09 19:24:34,397 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:34,400 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3056398956807621127_1001 src: /127.0.0.1:55873 dest: /127.0.0.1:42580
2011-08-09 19:24:34,402 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3056398956807621127_1001 src: /127.0.0.1:36283 dest: /127.0.0.1:37242
2011-08-09 19:24:34,404 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3056398956807621127_1001 src: /127.0.0.1:48568 dest: /127.0.0.1:54305
2011-08-09 19:24:34,406 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-3056398956807621127_1001 wrote packet seqno:0 size:45 offsetInBlock:0 lastPacketInBlock:false
2011-08-09 19:24:34,412 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:34,413 INFO  hdfs.StateChange (FSNamesystem.java:fsync(2430)) - BLOCK* NameSystem.fsync: file /TestFileCreation/dhrubashutdown for DFSClient_-168224696
2011-08-09 19:24:34,414 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 32, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 100, 104, 114, 117, 98, 97, 115, 104, 117, 116, 100, 111, 119, 110, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, -43, -107, 125, 87, -97, -101, 117, -7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 54, 56, 50, 50, 52, 54, 57, 54, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:34,414 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 32, 47, 84, 101, 115, 116, 70, 105, 108, 101, 67, 114, 101, 97, 116, 105, 111, 110, 47, 100, 104, 114, 117, 98, 97, 115, 104, 117, 116, 100, 111, 119, 110, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 55, 52, 51, 55, 57, 0, 4, 56, 49, 57, 50, 0, 0, 0, 1, -43, -107, 125, 87, -97, -101, 117, -7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 20, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 45, 49, 54, 56, 50, 50, 52, 54, 57, 54, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:34,416 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 162
2011-08-09 19:24:34,417 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 162
MiniDFSCluster Stopping DataNode 127.0.0.1:37242 from a total of 3 datanodes.
2011-08-09 19:24:34,437 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:34,438 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48443
2011-08-09 19:24:34,438 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 48443
2011-08-09 19:24:34,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48443: exiting
2011-08-09 19:24:34,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48443: exiting
2011-08-09 19:24:34,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48443: exiting
2011-08-09 19:24:34,440 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:34,441 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37242, storageID=DS-932467330-10.0.62.238-37242-1312910674321, infoPort=45180, ipcPort=48443):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:34,441 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 3
2011-08-09 19:24:34,441 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_-3056398956807621127_1001 2 Exception java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:34,442 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_-3056398956807621127_1001 1 Exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:48568 remote=/127.0.0.1:54305]. 59970 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:34,442 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-3056398956807621127_1001 terminating
2011-08-09 19:24:34,442 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno -2
2011-08-09 19:24:34,443 WARN  hdfs.DFSClient (DFSClient.java:run(3117)) - DFSOutputStream ResponseProcessor exception  for block blk_-3056398956807621127_1001java.io.IOException: Bad response 1 for block blk_-3056398956807621127_1001 from datanode 127.0.0.1:37242
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3082)

2011-08-09 19:24:34,442 INFO  datanode.DataNode (BlockReceiver.java:run(930)) - PacketResponder blk_-3056398956807621127_1001 1 : Thread is interrupted.
2011-08-09 19:24:34,443 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-3056398956807621127_1001 terminating
2011-08-09 19:24:34,443 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_-3056398956807621127_1001 bad datanode[1] 127.0.0.1:37242
2011-08-09 19:24:34,444 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_-3056398956807621127_1001 in pipeline 127.0.0.1:42580, 127.0.0.1:37242, 127.0.0.1:54305: bad datanode 127.0.0.1:37242
2011-08-09 19:24:34,444 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_-3056398956807621127_1001 java.io.IOException: Connection reset by peer
2011-08-09 19:24:34,444 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_-3056398956807621127_1001 received exception java.io.IOException: Connection reset by peer
2011-08-09 19:24:34,444 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:42580, storageID=DS-525628140-10.0.62.238-42580-1312910673970, infoPort=57427, ipcPort=52114):DataXceiver
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:237)
	at sun.nio.ch.IOUtil.read(IOUtil.java:210)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:236)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:34,446 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_-3056398956807621127_1001 java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 0 millis timeout left.
2011-08-09 19:24:34,448 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_-3056398956807621127_1001, targets=[127.0.0.1:42580, 127.0.0.1:54305])
2011-08-09 19:24:34,448 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:42580
2011-08-09 19:24:34,487 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_-3056398956807621127_1001 received exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 0 millis timeout left.
2011-08-09 19:24:34,488 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:37242, storageID=DS-932467330-10.0.62.238-37242-1312910674321, infoPort=45180, ipcPort=48443):DataXceiver
java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 0 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:274)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:34,488 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_-3056398956807621127_1001 java.io.EOFException: while trying to read 45 bytes
2011-08-09 19:24:34,488 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(780)) - PacketResponder 0 for block blk_-3056398956807621127_1001 Interrupted.
2011-08-09 19:24:34,488 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-3056398956807621127_1001 terminating
2011-08-09 19:24:34,489 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:54305 (dnReg=DatanodeRegistration(127.0.0.1:42580, storageID=DS-525628140-10.0.62.238-42580-1312910673970, infoPort=57427, ipcPort=52114))
2011-08-09 19:24:34,489 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_-3056398956807621127_1001 received exception java.io.EOFException: while trying to read 45 bytes
2011-08-09 19:24:34,489 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:54305, storageID=DS-2063375514-10.0.62.238-54305-1312910673453, infoPort=58830, ipcPort=37351):DataXceiver
java.io.EOFException: while trying to read 45 bytes
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:277)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:34,498 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:34,498 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:34,499 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_-3056398956807621127_1001(length=16), newblock=blk_-3056398956807621127_1002(length=16), datanode=127.0.0.1:42580
2011-08-09 19:24:34,511 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_-3056398956807621127_1001(length=16), newblock=blk_-3056398956807621127_1002(length=16), datanode=127.0.0.1:54305
2011-08-09 19:24:34,512 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2544)) - commitBlockSynchronization(lastblock=blk_-3056398956807621127_1001, newgenerationstamp=1002, newlength=16, newtargets=[127.0.0.1:42580, 127.0.0.1:54305], closeFile=false, deleteBlock=false)
2011-08-09 19:24:34,512 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2614)) - commitBlockSynchronization(blk_-3056398956807621127_1002) successful
2011-08-09 19:24:34,513 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:42580
2011-08-09 19:24:34,513 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:54305
2011-08-09 19:24:34,514 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:42580
2011-08-09 19:24:34,514 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:34,515 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3056398956807621127_1002 src: /127.0.0.1:55878 dest: /127.0.0.1:42580
2011-08-09 19:24:34,515 INFO  datanode.DataNode (FSDataset.java:writeToBlock(1162)) - Reopen already-open Block for append blk_-3056398956807621127_1002
2011-08-09 19:24:34,516 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3056398956807621127_1002 src: /127.0.0.1:48572 dest: /127.0.0.1:54305
2011-08-09 19:24:34,516 INFO  datanode.DataNode (FSDataset.java:writeToBlock(1162)) - Reopen already-open Block for append blk_-3056398956807621127_1002
2011-08-09 19:24:35,372 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:35,442 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:35,442 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37242, storageID=DS-932467330-10.0.62.238-37242-1312910674321, infoPort=45180, ipcPort=48443):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:35,443 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48443
2011-08-09 19:24:35,444 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:35,444 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:35,444 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:35,446 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:35,446 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=1, src=/TestFileCreation/dhrubashutdown, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:35,446 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-3056398956807621127_1002 wrote packet seqno:1 size:45 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:35,448 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:48572, dest: /127.0.0.1:54305, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_-168224696, offset: 0, srvID: DS-2063375514-10.0.62.238-54305-1312910673453, blockid: blk_-3056398956807621127_1002, duration: 930796436
2011-08-09 19:24:35,448 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-3056398956807621127_1002 terminating
2011-08-09 19:24:35,450 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:54305 is added to blk_-3056398956807621127_1002 size 16
2011-08-09 19:24:35,450 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:55878, dest: /127.0.0.1:42580, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_-168224696, offset: 0, srvID: DS-525628140-10.0.62.238-42580-1312910673970, blockid: blk_-3056398956807621127_1002, duration: 932332313
2011-08-09 19:24:35,450 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-3056398956807621127_1002 terminating
2011-08-09 19:24:35,451 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 1
2011-08-09 19:24:35,452 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-3056398956807621127_1002
2011-08-09 19:24:35,467 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 1 and requires 3
2011-08-09 19:24:35,468 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 14
2011-08-09 19:24:35,468 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 14
2011-08-09 19:24:35,470 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:42580 is added to blk_-3056398956807621127_1002 size 16
2011-08-09 19:24:35,871 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:35,872 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:35,873 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:36,133 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 0 time(s).
2011-08-09 19:24:36,275 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:38,447 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:38,447 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:38,448 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:38,850 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:38,904 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 1 time(s).
2011-08-09 19:24:39,251 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:39,252 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:39,253 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:39,655 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:39,655 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:39,656 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:39,905 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 2 time(s).
2011-08-09 19:24:40,057 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:40,058 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:40,058 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:40,460 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:40,461 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:40,461 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:40,462 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:40,863 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:40,864 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:40,905 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 3 time(s).
2011-08-09 19:24:41,264 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:41,265 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:41,265 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:41,266 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:41,672 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:41,672 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:41,906 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 4 time(s).
2011-08-09 19:24:42,073 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:42,074 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:42,074 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,075 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,476 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:42,476 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:42,476 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,477 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,878 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:42,879 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:42,879 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,880 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:42,906 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 5 time(s).
2011-08-09 19:24:43,281 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:43,282 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:43,282 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:43,283 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:43,684 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:43,685 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:43,685 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:43,686 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:43,907 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 6 time(s).
2011-08-09 19:24:44,087 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:44,088 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:44,488 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:44,489 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:44,489 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:44,490 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:44,891 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:44,892 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:44,907 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 7 time(s).
2011-08-09 19:24:45,292 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:45,293 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:45,293 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:45,294 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:45,696 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3960)) - Could not complete file /TestFileCreation/dhrubashutdown retrying...
2011-08-09 19:24:45,697 INFO  namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(1947)) - INodeFile "dhrubashutdown":jeff:supergroup:rw-r--r-- block blk_-3056398956807621127_1002 has replication 2 and requires 3
2011-08-09 19:24:45,697 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:45,698 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:45,699 INFO  hdfs.DFSClient (DFSClient.java:closeInternal(3953)) - Unable to close file because dfsclient  was unable to contact the HDFS servers. clientRunning true hdfsTimeout 10000
testFsCloseAfterClusterShutdown successful
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:24:45,758 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:45,858 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52114
2011-08-09 19:24:45,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 52114: exiting
2011-08-09 19:24:45,859 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 52114: exiting
2011-08-09 19:24:45,859 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 52114
2011-08-09 19:24:45,886 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 52114: exiting
2011-08-09 19:24:45,887 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:42580, storageID=DS-525628140-10.0.62.238-42580-1312910673970, infoPort=57427, ipcPort=52114):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:45,887 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:45,887 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:45,887 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:45,888 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:42580, storageID=DS-525628140-10.0.62.238-42580-1312910673970, infoPort=57427, ipcPort=52114):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:24:45,888 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52114
2011-08-09 19:24:45,888 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:45,889 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:45,889 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:45,890 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:24:45,908 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 8 time(s).
2011-08-09 19:24:45,927 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:46,027 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37351
2011-08-09 19:24:46,027 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 37351: exiting
2011-08-09 19:24:46,027 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 37351: exiting
2011-08-09 19:24:46,028 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 37351: exiting
2011-08-09 19:24:46,028 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 37351
2011-08-09 19:24:46,029 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:46,029 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54305, storageID=DS-2063375514-10.0.62.238-54305-1312910673453, infoPort=58830, ipcPort=37351):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:46,030 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:46,030 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:46,030 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54305, storageID=DS-2063375514-10.0.62.238-54305-1312910673453, infoPort=58830, ipcPort=37351):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:46,031 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37351
2011-08-09 19:24:46,031 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:46,032 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:46,032 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:46,033 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:46,043 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:46,044 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:46,044 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:46,045 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:46,045 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:46,046 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 6 Number of syncs: 18 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:20  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:22 
2011-08-09 19:24:46,046 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:46,047 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:46,048 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38377
2011-08-09 19:24:46,048 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 38377: exiting
2011-08-09 19:24:46,048 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 38377: exiting
2011-08-09 19:24:46,049 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 38377: exiting
2011-08-09 19:24:46,049 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 38377: exiting
2011-08-09 19:24:46,049 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 38377: exiting
2011-08-09 19:24:46,050 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 38377
2011-08-09 19:24:46,050 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 38377: exiting
2011-08-09 19:24:46,051 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 38377: exiting
2011-08-09 19:24:46,051 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 38377: exiting
2011-08-09 19:24:46,051 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 38377: exiting
2011-08-09 19:24:46,051 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 38377: exiting
2011-08-09 19:24:46,053 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
test testFileCreationSyncOnClose start
2011-08-09 19:24:46,081 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:46,081 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:46,081 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:46,082 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:46,088 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:46,088 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:46,088 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:46,089 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:46,100 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:46,100 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:46,101 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:46,101 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:46,101 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:46,112 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:24:46,114 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:24:46,115 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:46,137 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:24:46,138 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:24:46,138 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:24:46,149 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:24:46,149 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:24:46,153 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:46,153 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:24:46,153 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:24:46,153 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:24:46,153 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:24:46,159 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:24:46,159 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:24:46,159 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:24:46,159 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:24:46,165 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:24:46,165 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:24:46,166 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:24:46,169 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:24:46,169 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:24:46,320 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:24:46,321 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:24:46,321 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:46,322 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:24:46,323 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:24:46,323 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 164 msecs
2011-08-09 19:24:46,323 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:24:46,327 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:24:46,328 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:24:46,328 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:24:46,328 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:24:46,328 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:24:46,330 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:46,333 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=56105
2011-08-09 19:24:46,334 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:56105
2011-08-09 19:24:46,334 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:46,334 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 56105: starting
2011-08-09 19:24:46,335 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 56105: starting
2011-08-09 19:24:46,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 56105: starting
2011-08-09 19:24:46,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 56105: starting
2011-08-09 19:24:46,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 56105: starting
2011-08-09 19:24:46,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 56105: starting
2011-08-09 19:24:46,336 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 56105: starting
2011-08-09 19:24:46,337 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 56105: starting
2011-08-09 19:24:46,337 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 56105: starting
2011-08-09 19:24:46,337 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 56105: starting
2011-08-09 19:24:46,337 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 56105: starting
2011-08-09 19:24:46,350 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:24:46,351 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:24:46,351 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:24:46,351 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:24:46,352 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:24:46,352 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:24:46,394 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:46,394 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:46,395 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39831 webServer.getConnectors()[0].getLocalPort() returned 39831
2011-08-09 19:24:46,395 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39831
2011-08-09 19:24:46,395 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:46,451 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39831
2011-08-09 19:24:46,451 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:39831
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:24:46,458 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:24:46,458 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:46,475 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:24:46,475 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:46,647 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:46,648 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34983
2011-08-09 19:24:46,649 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:46,652 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:46,652 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:46,653 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 60429 webServer.getConnectors()[0].getLocalPort() returned 60429
2011-08-09 19:24:46,653 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 60429
2011-08-09 19:24:46,653 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:46,727 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:60429
2011-08-09 19:24:46,729 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:46,734 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:46,736 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=51915
2011-08-09 19:24:46,738 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:46,738 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51915: starting
2011-08-09 19:24:46,788 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51915: starting
2011-08-09 19:24:46,788 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34983, storageID=, infoPort=60429, ipcPort=51915)
2011-08-09 19:24:46,789 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51915: starting
2011-08-09 19:24:46,789 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51915: starting
2011-08-09 19:24:46,797 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34983 storage DS-1053752054-10.0.62.238-34983-1312910686792
2011-08-09 19:24:46,798 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34983
2011-08-09 19:24:46,803 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1053752054-10.0.62.238-34983-1312910686792 is assigned to data-node 127.0.0.1:34983
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:24:46,805 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34983, storageID=DS-1053752054-10.0.62.238-34983-1312910686792, infoPort=60429, ipcPort=51915)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:46,806 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:46,815 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:46,815 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:24:46,816 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:34983 0 blocks shortCircuit first report.
2011-08-09 19:24:46,817 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:46,817 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:24:46,818 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:46,818 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:46,832 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:24:46,832 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:46,909 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 9 time(s).
2011-08-09 19:24:46,914 WARN  hdfs.DFSClient (DFSClient.java:run(1571)) - Problem renewing lease for DFSClient_-1371552601 for a period of 30 seconds. Will retry shortly...
java.net.ConnectException: Call to localhost/127.0.0.1:41716 failed on connection exception: java.net.ConnectException: Connection refused
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:791)
	at org.apache.hadoop.ipc.Client.call(Client.java:767)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1542)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1562)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:405)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:324)
	at org.apache.hadoop.ipc.Client$Connection.access$1700(Client.java:196)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:884)
	at org.apache.hadoop.ipc.Client.call(Client.java:744)
	... 11 more
2011-08-09 19:24:47,013 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:47,014 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 33225
2011-08-09 19:24:47,014 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:47,017 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:47,018 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:47,018 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35973 webServer.getConnectors()[0].getLocalPort() returned 35973
2011-08-09 19:24:47,019 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35973
2011-08-09 19:24:47,019 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:47,103 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35973
2011-08-09 19:24:47,104 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:47,108 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:47,110 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49475
2011-08-09 19:24:47,111 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:47,112 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49475: starting
2011-08-09 19:24:47,112 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49475: starting
2011-08-09 19:24:47,155 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49475: starting
2011-08-09 19:24:47,155 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:33225, storageID=, infoPort=35973, ipcPort=49475)
2011-08-09 19:24:47,156 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49475: starting
2011-08-09 19:24:47,160 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:33225 storage DS-762088351-10.0.62.238-33225-1312910687158
2011-08-09 19:24:47,160 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:33225
2011-08-09 19:24:47,166 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-762088351-10.0.62.238-33225-1312910687158 is assigned to data-node 127.0.0.1:33225
2011-08-09 19:24:47,167 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:33225, storageID=DS-762088351-10.0.62.238-33225-1312910687158, infoPort=35973, ipcPort=49475)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:24:47,168 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:47,192 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:47,195 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:33225 0 blocks shortCircuit first report.
2011-08-09 19:24:47,195 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:24:47,196 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:47,196 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:24:47,196 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:47,198 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:47,210 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:24:47,211 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:24:47,423 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:24:47,424 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 39590
2011-08-09 19:24:47,424 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:24:47,427 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:24:47,428 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:24:47,428 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 50316 webServer.getConnectors()[0].getLocalPort() returned 50316
2011-08-09 19:24:47,429 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 50316
2011-08-09 19:24:47,429 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:24:47,506 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:50316
2011-08-09 19:24:47,507 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:24:47,512 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:24:47,514 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=53546
2011-08-09 19:24:47,515 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:24:47,516 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53546: starting
2011-08-09 19:24:47,557 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53546: starting
2011-08-09 19:24:47,558 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53546: starting
2011-08-09 19:24:47,558 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:39590, storageID=, infoPort=50316, ipcPort=53546)
2011-08-09 19:24:47,558 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53546: starting
2011-08-09 19:24:47,564 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:39590 storage DS-709126557-10.0.62.238-39590-1312910687561
2011-08-09 19:24:47,564 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:39590
2011-08-09 19:24:47,570 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-709126557-10.0.62.238-39590-1312910687561 is assigned to data-node 127.0.0.1:39590
2011-08-09 19:24:47,571 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:39590, storageID=DS-709126557-10.0.62.238-39590-1312910687561, infoPort=50316, ipcPort=53546)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:47,573 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:24:47,578 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:47,582 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:39590 0 blocks shortCircuit first report.
2011-08-09 19:24:47,583 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 6 msecs
2011-08-09 19:24:47,583 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:24:47,584 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /foo: masked=rwxr-xr-x
2011-08-09 19:24:47,584 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:24:47,586 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/foo, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:47,588 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:47,589 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:24:47,589 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 56, 56, 53, 50, 50, 51, 53, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:47,590 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 56, 56, 53, 50, 50, 51, 53, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:47,590 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:47,591 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:47,591 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 125
2011-08-09 19:24:47,595 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:24:47,596 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:24:47,596 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 125
2011-08-09 19:24:47,599 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:47,600 DEBUG hdfs.DFSClient (DFSClient.java:create(577)) - /bar: masked=rwxr-xr-x
2011-08-09 19:24:47,633 DEBUG hdfs.DFSClient (DFSClient.java:computePacketChunkSize(3437)) - computePacketChunkSize: src=/bar, chunkSize=516, chunksPerPacket=127, packetSize=65557
2011-08-09 19:24:47,635 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:47,635 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:24:47,636 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 56, 56, 53, 50, 50, 51, 53, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:47,636 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 56, 56, 53, 50, 50, 51, 53, 55, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:24:47,636 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 125
2011-08-09 19:24:47,637 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 125
2011-08-09 19:24:47,638 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/bar	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:24:47,639 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/foo, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:47,640 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:47,641 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo. blk_5531018065986487269_1002
2011-08-09 19:24:47,642 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:39590
2011-08-09 19:24:47,642 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:33225
2011-08-09 19:24:47,642 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:34983
2011-08-09 19:24:47,642 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:39590
2011-08-09 19:24:47,643 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:47,644 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5531018065986487269_1002 src: /127.0.0.1:58473 dest: /127.0.0.1:39590
2011-08-09 19:24:47,648 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5531018065986487269_1002 src: /127.0.0.1:53319 dest: /127.0.0.1:33225
2011-08-09 19:24:47,651 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5531018065986487269_1002 src: /127.0.0.1:48394 dest: /127.0.0.1:34983
2011-08-09 19:24:47,656 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_5531018065986487269_1002 wrote packet seqno:0 size:129 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:47,668 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:48394, dest: /127.0.0.1:34983, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-1053752054-10.0.62.238-34983-1312910686792, blockid: blk_5531018065986487269_1002, duration: 13669339
2011-08-09 19:24:47,670 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34983 is added to blk_5531018065986487269_1002 size 100
2011-08-09 19:24:47,671 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5531018065986487269_1002 terminating
2011-08-09 19:24:47,676 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:53319, dest: /127.0.0.1:33225, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-762088351-10.0.62.238-33225-1312910687158, blockid: blk_5531018065986487269_1002, duration: 20756771
2011-08-09 19:24:47,677 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5531018065986487269_1002 terminating
2011-08-09 19:24:47,680 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33225 is added to blk_5531018065986487269_1002 size 100
2011-08-09 19:24:47,713 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:58473, dest: /127.0.0.1:39590, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-709126557-10.0.62.238-39590-1312910687561, blockid: blk_5531018065986487269_1002, duration: 29366652
2011-08-09 19:24:47,714 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:47,714 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_5531018065986487269_1002 terminating
2011-08-09 19:24:47,717 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:39590 is added to blk_5531018065986487269_1002 size 100
2011-08-09 19:24:47,717 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_5531018065986487269_1002
2011-08-09 19:24:47,719 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 55, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, 76, -62, 31, -96, 93, 100, -125, -27, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:47,719 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 102, 111, 111, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 55, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 53, 56, 57, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, 76, -62, 31, -96, 93, 100, -125, -27, 0, 0, 0, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:47,719 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /foo is closed by DFSClient_88522357
2011-08-09 19:24:47,720 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:47,720 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:47,722 DEBUG hdfs.DFSClient (DFSClient.java:writeChunk(3666)) - DFSClient writeChunk allocating new packet seqno=0, src=/bar, packetSize=65557, chunksPerPacket=127, bytesCurBlock=0
2011-08-09 19:24:47,722 DEBUG hdfs.DFSClient (DFSClient.java:run(2932)) - Allocating new block
2011-08-09 19:24:47,723 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /bar. blk_-8029927064907074948_1002
2011-08-09 19:24:47,724 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:33225
2011-08-09 19:24:47,724 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:39590
2011-08-09 19:24:47,724 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3504)) - pipeline = 127.0.0.1:34983
2011-08-09 19:24:47,724 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3513)) - Connecting to 127.0.0.1:33225
2011-08-09 19:24:47,724 DEBUG hdfs.DFSClient (DFSClient.java:createBlockOutputStream(3520)) - Send buf size 131071
2011-08-09 19:24:47,725 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8029927064907074948_1002 src: /127.0.0.1:53321 dest: /127.0.0.1:33225
2011-08-09 19:24:47,728 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8029927064907074948_1002 src: /127.0.0.1:58477 dest: /127.0.0.1:39590
2011-08-09 19:24:47,730 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8029927064907074948_1002 src: /127.0.0.1:48397 dest: /127.0.0.1:34983
2011-08-09 19:24:47,732 DEBUG hdfs.DFSClient (DFSClient.java:run(2969)) - DataStreamer block blk_-8029927064907074948_1002 wrote packet seqno:0 size:229 offsetInBlock:0 lastPacketInBlock:true
2011-08-09 19:24:47,743 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:48397, dest: /127.0.0.1:34983, bytes: 200, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-1053752054-10.0.62.238-34983-1312910686792, blockid: blk_-8029927064907074948_1002, duration: 11573177
2011-08-09 19:24:47,743 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-8029927064907074948_1002 terminating
2011-08-09 19:24:47,744 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34983 is added to blk_-8029927064907074948_1002 size 200
2011-08-09 19:24:47,748 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:58477, dest: /127.0.0.1:39590, bytes: 200, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-709126557-10.0.62.238-39590-1312910687561, blockid: blk_-8029927064907074948_1002, duration: 16143876
2011-08-09 19:24:47,749 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-8029927064907074948_1002 terminating
2011-08-09 19:24:47,750 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:39590 is added to blk_-8029927064907074948_1002 size 200
2011-08-09 19:24:47,756 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:53321, dest: /127.0.0.1:33225, bytes: 200, op: HDFS_WRITE, cliID: DFSClient_88522357, offset: 0, srvID: DS-762088351-10.0.62.238-33225-1312910687158, blockid: blk_-8029927064907074948_1002, duration: 23415187
2011-08-09 19:24:47,756 DEBUG hdfs.DFSClient (DFSClient.java:run(3072)) - DFSClient received ack for seqno 0
2011-08-09 19:24:47,756 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-8029927064907074948_1002 terminating
2011-08-09 19:24:47,793 DEBUG hdfs.DFSClient (DFSClient.java:run(2999)) - Closing old block blk_-8029927064907074948_1002
2011-08-09 19:24:47,793 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33225 is added to blk_-8029927064907074948_1002 size 200
2011-08-09 19:24:47,795 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 55, 57, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, -112, -113, -9, -32, -5, -21, 50, 124, 0, 0, 0, 0, 0, 0, 0, -56, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:47,795 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 4, 47, 98, 97, 114, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 55, 57, 53, 0, 13, 49, 51, 49, 50, 57, 49, 48, 54, 56, 55, 54, 51, 54, 0, 8, 54, 55, 49, 48, 56, 56, 54, 52, 0, 0, 0, 1, -112, -113, -9, -32, -5, -21, 50, 124, 0, 0, 0, 0, 0, 0, 0, -56, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:24:47,795 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /bar is closed by DFSClient_88522357
2011-08-09 19:24:47,796 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:47,796 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 105
2011-08-09 19:24:47,799 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null
2011-08-09 19:24:47,800 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/bar	dst=null	perm=null
2011-08-09 19:24:47,801 WARN  hdfs.DFSClient (DFSClient.java:blockSeekTo(2158)) - blockSeekTo shortCircuitLocalReads false localhost alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:34983
2011-08-09 19:24:47,803 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:34983, dest: /127.0.0.1:48398, bytes: 104, op: HDFS_READ, cliID: DFSClient_88522357, offset: 0, srvID: DS-1053752054-10.0.62.238-34983-1312910686792, blockid: blk_5531018065986487269_1002, duration: 407998
2011-08-09 19:24:47,803 WARN  hdfs.DFSClient (DFSClient.java:blockSeekTo(2158)) - blockSeekTo shortCircuitLocalReads false localhost alexandria-dev/10.0.62.238 targetAddr /127.0.0.1:39590
2011-08-09 19:24:47,805 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:39590, dest: /127.0.0.1:58480, bytes: 204, op: HDFS_READ, cliID: DFSClient_88522357, offset: 0, srvID: DS-709126557-10.0.62.238-39590-1312910687561, blockid: blk_-8029927064907074948_1002, duration: 364125
test testFileCreationSyncOnClose completed
Shutting down the Mini HDFS Cluster
Shutting down DataNode 2
2011-08-09 19:24:47,852 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:47,952 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53546
2011-08-09 19:24:47,953 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53546: exiting
2011-08-09 19:24:47,953 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53546: exiting
2011-08-09 19:24:47,953 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53546: exiting
2011-08-09 19:24:47,953 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53546
2011-08-09 19:24:47,954 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:47,954 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:47,954 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:39590, storageID=DS-709126557-10.0.62.238-39590-1312910687561, infoPort=50316, ipcPort=53546):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:48,588 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:48,915 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 0 time(s).
2011-08-09 19:24:48,954 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:48,955 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:39590, storageID=DS-709126557-10.0.62.238-39590-1312910687561, infoPort=50316, ipcPort=53546):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:24:48,955 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53546
2011-08-09 19:24:48,956 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:48,956 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:48,956 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:48,962 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:24:48,964 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:48,965 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49475
2011-08-09 19:24:48,965 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49475: exiting
2011-08-09 19:24:48,966 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49475: exiting
2011-08-09 19:24:48,967 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49475: exiting
2011-08-09 19:24:48,967 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49475
2011-08-09 19:24:48,969 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:33225, storageID=DS-762088351-10.0.62.238-33225-1312910687158, infoPort=35973, ipcPort=49475):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:48,969 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:48,969 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:49,199 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:49,916 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 1 time(s).
2011-08-09 19:24:49,970 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:49,970 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:33225, storageID=DS-762088351-10.0.62.238-33225-1312910687158, infoPort=35973, ipcPort=49475):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:24:49,970 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49475
2011-08-09 19:24:49,970 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:49,971 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:49,971 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:49,973 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:24:50,015 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:50,116 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51915
2011-08-09 19:24:50,116 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51915: exiting
2011-08-09 19:24:50,116 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51915: exiting
2011-08-09 19:24:50,117 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51915: exiting
2011-08-09 19:24:50,117 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51915
2011-08-09 19:24:50,118 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:24:50,118 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:24:50,118 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34983, storageID=DS-1053752054-10.0.62.238-34983-1312910686792, infoPort=60429, ipcPort=51915):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:24:50,335 WARN  hdfs.DFSClient (DFSClient.java:run(1571)) - Problem renewing lease for DFSClient_-168224696 for a period of 5 seconds. Will retry shortly...
java.io.IOException: Call to localhost/127.0.0.1:38377 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:799)
	at org.apache.hadoop.ipc.Client.call(Client.java:767)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1542)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1562)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:375)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:521)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:466)
2011-08-09 19:24:50,820 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:24:50,916 INFO  ipc.Client (Client.java:handleConnectionFailure(389)) - Retrying connect to server: localhost/127.0.0.1:41716. Already tried 2 time(s).
2011-08-09 19:24:51,118 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:51,118 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34983, storageID=DS-1053752054-10.0.62.238-34983-1312910686792, infoPort=60429, ipcPort=51915):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:24:51,119 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51915
2011-08-09 19:24:51,119 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:24:51,120 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:24:51,120 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:24:51,121 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:24:51,123 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:24:51,223 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:51,224 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:51,224 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:24:51,224 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:24:51,224 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:24:51,225 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:51,226 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:24:51,227 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56105
2011-08-09 19:24:51,227 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 56105: exiting
2011-08-09 19:24:51,227 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 56105: exiting
2011-08-09 19:24:51,227 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 56105: exiting
2011-08-09 19:24:51,227 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 56105: exiting
2011-08-09 19:24:51,228 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 56105: exiting
2011-08-09 19:24:51,228 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 56105: exiting
2011-08-09 19:24:51,228 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 56105: exiting
2011-08-09 19:24:51,228 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 56105: exiting
2011-08-09 19:24:51,229 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 56105: exiting
2011-08-09 19:24:51,229 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 56105: exiting
2011-08-09 19:24:51,229 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 56105
2011-08-09 19:24:51,230 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
------------- ---------------- ---------------

Testcase: testFileCreation took 4.926 sec
Testcase: testDeleteOnExit took 1.688 sec
Testcase: testFileCreationError1 took 19.387 sec
Testcase: testFileCreationError2 took 7.632 sec
Testcase: testDFSClientDeath took 2.321 sec
Testcase: testFileCreationSimulated took 3.067 sec
Testcase: testConcurrentFileCreation took 1.992 sec
Testcase: testLeaseExpireHardLimit took 22.557 sec
Testcase: testFsClose took 4.781 sec
Testcase: testFsCloseAfterClusterShutdown took 13.343 sec
Testcase: testFileCreationSyncOnClose took 5.177 sec
