Testsuite: org.apache.hadoop.hdfs.TestDFSUpgrade
Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 73.553 sec
------------- Standard Output ---------------
2011-08-09 19:00:30,564 WARN  conf.Configuration (Configuration.java:<clinit>(191)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2011-08-09 19:00:30,810 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:00:30,812 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:00:30,812 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:00:30,813 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:00:30,897 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:00:30,898 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:00:30,898 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:00:31,082 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:00:31,269 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:00:31,272 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:00:31,311 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster has been successfully formatted.
2011-08-09 19:00:31,346 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 19:00:31,420 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:00:31,421 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:00:31,421 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:00:31,421 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:00:31,422 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:00:31,498 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:00:31,498 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:00:31,499 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:00:31,499 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:00:31,527 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:00:31,528 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:00:31,538 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:00:31,558 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:00:31,558 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:00:31,559 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:00:31,561 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:00:31,562 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:00:31,568 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:00:31,568 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 72 msecs
2011-08-09 19:00:31,570 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:00:31,579 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:00:31,580 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:00:31,580 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:00:31,581 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:00:31,581 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:00:31,606 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:00:31,611 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=51673
2011-08-09 19:00:31,615 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:51673
2011-08-09 19:00:31,615 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:00:31,616 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51673: starting
2011-08-09 19:00:31,617 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51673: starting
2011-08-09 19:00:31,617 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51673: starting
2011-08-09 19:00:31,618 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51673: starting
2011-08-09 19:00:31,619 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 51673: starting
2011-08-09 19:00:31,619 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 51673: starting
2011-08-09 19:00:31,619 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 51673: starting
2011-08-09 19:00:31,620 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 51673: starting
2011-08-09 19:00:31,620 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 51673: starting
2011-08-09 19:00:31,621 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 51673: starting
2011-08-09 19:00:31,621 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 51673: starting
2011-08-09 19:00:31,761 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:00:31,763 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:00:31,764 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:00:31,764 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:00:31,771 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:00:31,887 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 19:00:31,973 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:00:32,023 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:00:32,024 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42589 webServer.getConnectors()[0].getLocalPort() returned 42589
2011-08-09 19:00:32,024 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42589
2011-08-09 19:00:32,025 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:00:32,548 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42589
2011-08-09 19:00:32,548 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:42589
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/datanodeMaster
2011-08-09 19:00:32,599 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/datanodeMaster is not formatted.
2011-08-09 19:00:32,600 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:00:32,742 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:00:32,745 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48313
2011-08-09 19:00:32,749 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:00:32,757 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:00:32,760 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:00:32,761 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 38060 webServer.getConnectors()[0].getLocalPort() returned 38060
2011-08-09 19:00:32,777 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 38060
2011-08-09 19:00:32,777 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:00:32,946 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:38060
2011-08-09 19:00:32,948 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:00:33,001 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:00:33,003 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=33841
2011-08-09 19:00:33,017 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:00:33,017 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 33841: starting
2011-08-09 19:00:33,017 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 33841: starting
2011-08-09 19:00:33,038 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48313, storageID=, infoPort=38060, ipcPort=33841)
2011-08-09 19:00:33,039 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 33841: starting
2011-08-09 19:00:33,057 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 33841: starting
2011-08-09 19:01:31,002 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48313 storage DS-1340858226-10.0.62.238-48313-1312909290951
2011-08-09 19:01:31,006 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48313
2011-08-09 19:01:31,011 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1340858226-10.0.62.238-48313-1312909290951 is assigned to data-node 127.0.0.1:48313
2011-08-09 19:01:31,011 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48313, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=38060, ipcPort=33841)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/datanodeMaster/current'}
2011-08-09 19:01:31,013 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:01:31,020 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 1 volumes in 0 seconds
2011-08-09 19:01:31,033 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48313 0 blocks shortCircuit first report.
2011-08-09 19:01:31,036 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 16 msecs
2011-08-09 19:01:31,036 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:01:31,041 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 1 volumes in 0 seconds
2011-08-09 19:01:31,053 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/TestUpgrade	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:01:31,066 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:01:31,096 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file1. blk_4727902467617139242_1001
2011-08-09 19:01:31,165 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_4727902467617139242_1001 src: /127.0.0.1:54037 dest: /127.0.0.1:48313
2011-08-09 19:01:31,191 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_4727902467617139242_1001 size 1024
2011-08-09 19:01:31,195 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54037, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_4727902467617139242_1001, duration: 6473070
2011-08-09 19:01:31,196 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_4727902467617139242_1001 terminating
2011-08-09 19:01:31,201 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file1. blk_-2946743132398693438_1001
2011-08-09 19:01:31,203 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2946743132398693438_1001 src: /127.0.0.1:54038 dest: /127.0.0.1:48313
2011-08-09 19:01:31,207 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54038, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-2946743132398693438_1001, duration: 2534289
2011-08-09 19:01:31,209 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-2946743132398693438_1001 size 1024
2011-08-09 19:01:31,210 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-2946743132398693438_1001 terminating
2011-08-09 19:01:31,216 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file1. blk_-7208191464376374834_1001
2011-08-09 19:01:31,218 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7208191464376374834_1001 src: /127.0.0.1:54039 dest: /127.0.0.1:48313
2011-08-09 19:01:31,222 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54039, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-7208191464376374834_1001, duration: 2326661
2011-08-09 19:01:31,223 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-7208191464376374834_1001 size 1024
2011-08-09 19:01:31,223 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7208191464376374834_1001 terminating
2011-08-09 19:01:31,236 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file1. blk_-5111669877768692586_1001
2011-08-09 19:01:31,241 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-5111669877768692586_1001 src: /127.0.0.1:54040 dest: /127.0.0.1:48313
2011-08-09 19:01:31,244 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54040, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-5111669877768692586_1001, duration: 1400859
2011-08-09 19:01:31,253 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-5111669877768692586_1001 terminating
2011-08-09 19:01:31,253 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-5111669877768692586_1001 size 1024
2011-08-09 19:01:31,263 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /TestUpgrade/file1 is closed by DFSClient_1144721356
2011-08-09 19:01:31,274 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file2	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:01:31,276 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file2. blk_-1380604150896037728_1002
2011-08-09 19:01:31,278 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1380604150896037728_1002 src: /127.0.0.1:54041 dest: /127.0.0.1:48313
2011-08-09 19:01:31,280 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54041, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-1380604150896037728_1002, duration: 1033668
2011-08-09 19:01:31,281 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1380604150896037728_1002 terminating
2011-08-09 19:01:31,281 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-1380604150896037728_1002 size 1024
2011-08-09 19:01:31,283 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file2. blk_8794341832021438065_1002
2011-08-09 19:01:31,284 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8794341832021438065_1002 src: /127.0.0.1:54042 dest: /127.0.0.1:48313
2011-08-09 19:01:31,287 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54042, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_8794341832021438065_1002, duration: 1058259
2011-08-09 19:01:31,287 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_8794341832021438065_1002 size 1024
2011-08-09 19:01:31,288 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_8794341832021438065_1002 terminating
2011-08-09 19:01:31,290 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file2. blk_7877040971963779390_1002
2011-08-09 19:01:31,291 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_7877040971963779390_1002 src: /127.0.0.1:54043 dest: /127.0.0.1:48313
2011-08-09 19:01:31,293 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54043, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_7877040971963779390_1002, duration: 754502
2011-08-09 19:01:31,294 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_7877040971963779390_1002 terminating
2011-08-09 19:01:31,294 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_7877040971963779390_1002 size 1024
2011-08-09 19:01:31,326 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file2. blk_-1720719890451585763_1002
2011-08-09 19:01:31,327 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1720719890451585763_1002 src: /127.0.0.1:54044 dest: /127.0.0.1:48313
2011-08-09 19:01:31,331 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54044, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-1720719890451585763_1002, duration: 2725429
2011-08-09 19:01:31,332 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1720719890451585763_1002 terminating
2011-08-09 19:01:31,332 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-1720719890451585763_1002 size 1024
2011-08-09 19:01:31,335 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /TestUpgrade/file2 is closed by DFSClient_1144721356
2011-08-09 19:01:31,337 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:31,352 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits:8 
2011-08-09 19:01:31,355 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:31,363 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 501 saved in 0 seconds.
2011-08-09 19:01:31,363 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits.new is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:31,368 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:31,382 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:31,390 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file3	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:01:31,391 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file3. blk_-814496416625870395_1003
2011-08-09 19:01:31,393 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-814496416625870395_1003 src: /127.0.0.1:54045 dest: /127.0.0.1:48313
2011-08-09 19:01:31,396 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-814496416625870395_1003 size 1024
2011-08-09 19:01:31,397 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54045, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-814496416625870395_1003, duration: 1004326
2011-08-09 19:01:31,397 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-814496416625870395_1003 terminating
2011-08-09 19:01:31,399 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file3. blk_-1507967349496193830_1003
2011-08-09 19:01:31,404 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1507967349496193830_1003 src: /127.0.0.1:54046 dest: /127.0.0.1:48313
2011-08-09 19:01:31,407 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54046, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-1507967349496193830_1003, duration: 837498
2011-08-09 19:01:31,407 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1507967349496193830_1003 terminating
2011-08-09 19:01:31,408 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-1507967349496193830_1003 size 1024
2011-08-09 19:01:31,416 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file3. blk_-3453882379969128623_1003
2011-08-09 19:01:31,417 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3453882379969128623_1003 src: /127.0.0.1:54047 dest: /127.0.0.1:48313
2011-08-09 19:01:31,419 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54047, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-3453882379969128623_1003, duration: 1021093
2011-08-09 19:01:31,420 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-3453882379969128623_1003 terminating
2011-08-09 19:01:31,421 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-3453882379969128623_1003 size 1024
2011-08-09 19:01:31,463 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file3. blk_4477526865708489601_1003
2011-08-09 19:01:31,465 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_4477526865708489601_1003 src: /127.0.0.1:54048 dest: /127.0.0.1:48313
2011-08-09 19:01:31,467 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_4477526865708489601_1003 size 1024
2011-08-09 19:01:31,468 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54048, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_4477526865708489601_1003, duration: 1078380
2011-08-09 19:01:31,469 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_4477526865708489601_1003 terminating
2011-08-09 19:01:31,471 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /TestUpgrade/file3 is closed by DFSClient_1144721356
2011-08-09 19:01:31,476 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file4	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:01:31,478 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file4. blk_6820585740835573188_1004
2011-08-09 19:01:31,480 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6820585740835573188_1004 src: /127.0.0.1:54049 dest: /127.0.0.1:48313
2011-08-09 19:01:31,482 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54049, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_6820585740835573188_1004, duration: 1053788
2011-08-09 19:01:31,482 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6820585740835573188_1004 terminating
2011-08-09 19:01:31,482 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_6820585740835573188_1004 size 1024
2011-08-09 19:01:31,527 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file4. blk_-3085648537940891669_1004
2011-08-09 19:01:31,528 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-3085648537940891669_1004 src: /127.0.0.1:54050 dest: /127.0.0.1:48313
2011-08-09 19:01:31,530 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54050, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_-3085648537940891669_1004, duration: 806200
2011-08-09 19:01:31,531 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-3085648537940891669_1004 terminating
2011-08-09 19:01:31,530 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_-3085648537940891669_1004 size 1024
2011-08-09 19:01:31,532 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file4. blk_6726991102755610567_1004
2011-08-09 19:01:31,567 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6726991102755610567_1004 src: /127.0.0.1:54051 dest: /127.0.0.1:48313
2011-08-09 19:01:31,570 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_6726991102755610567_1004 size 1024
2011-08-09 19:01:31,570 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54051, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_6726991102755610567_1004, duration: 1150755
2011-08-09 19:01:31,571 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6726991102755610567_1004 terminating
2011-08-09 19:01:31,572 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /TestUpgrade/file4. blk_6104672576152548243_1004
2011-08-09 19:01:31,573 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6104672576152548243_1004 src: /127.0.0.1:54052 dest: /127.0.0.1:48313
2011-08-09 19:01:31,575 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54052, dest: /127.0.0.1:48313, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1144721356, offset: 0, srvID: DS-1340858226-10.0.62.238-48313-1312909290951, blockid: blk_6104672576152548243_1004, duration: 542124
2011-08-09 19:01:31,576 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6104672576152548243_1004 terminating
2011-08-09 19:01:31,582 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48313 is added to blk_6104672576152548243_1004 size 1024
2011-08-09 19:01:31,584 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /TestUpgrade/file4 is closed by DFSClient_1144721356
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:01:31,608 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:31,709 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33841
2011-08-09 19:01:31,710 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 33841: exiting
2011-08-09 19:01:31,710 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 33841: exiting
2011-08-09 19:01:31,710 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 33841: exiting
2011-08-09 19:01:31,710 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 33841
2011-08-09 19:01:31,711 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:31,712 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:01:31,713 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48313, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=38060, ipcPort=33841):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:01:32,049 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:01:32,712 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:32,713 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48313, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=38060, ipcPort=33841):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/datanodeMaster/current'}
2011-08-09 19:01:32,713 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33841
2011-08-09 19:01:32,714 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:32,714 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:01:32,715 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:01:32,715 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:01:32,785 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:32,887 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:32,888 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:32,889 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits:5  /home/jeff/hadoop-20-warehouse/build/test/data/namenodeMaster/current/edits:3 
2011-08-09 19:01:32,913 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51673
2011-08-09 19:01:32,914 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51673: exiting
2011-08-09 19:01:32,914 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51673: exiting
2011-08-09 19:01:32,914 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51673: exiting
2011-08-09 19:01:32,914 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 51673: exiting
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 51673: exiting
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 51673: exiting
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 51673: exiting
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 51673: exiting
2011-08-09 19:01:32,916 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51673
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 51673: exiting
2011-08-09 19:01:32,915 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 51673: exiting
2011-08-09 19:01:32,917 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:32,954 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:32,954 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 0*** Normal NameNode upgrade: numDirs=1
2011-08-09 19:01:33,090 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:33,094 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:33,094 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:33,094 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:33,094 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:33,095 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:33,181 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:33,182 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:33,182 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:33,183 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:33,186 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:33,187 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:33,188 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:33,192 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:33,193 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:33,193 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:33,195 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:33,195 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:33,196 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:33,200 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:33,201 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909293201
2011-08-09 19:01:33,208 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:33,208 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:33,243 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:33,244 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:33,244 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:33,245 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 64 msecs
2011-08-09 19:01:33,252 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:33,253 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:33,254 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:33,255 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:33,258 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=47910
2011-08-09 19:01:33,259 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:47910
2011-08-09 19:01:33,259 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:33,259 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47910: starting
2011-08-09 19:01:33,260 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47910: starting
2011-08-09 19:01:33,261 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47910: starting
2011-08-09 19:01:33,261 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47910: starting
2011-08-09 19:01:33,261 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 47910: starting
2011-08-09 19:01:33,261 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 47910: starting
2011-08-09 19:01:33,262 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 47910: starting
2011-08-09 19:01:33,262 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 47910: starting
2011-08-09 19:01:33,262 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 47910: starting
2011-08-09 19:01:33,262 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 47910: starting
2011-08-09 19:01:33,263 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 47910: starting
2011-08-09 19:01:33,314 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:33,315 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:33,317 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:33,317 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59138 webServer.getConnectors()[0].getLocalPort() returned 59138
2011-08-09 19:01:33,317 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59138
2011-08-09 19:01:33,317 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:33,456 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59138
2011-08-09 19:01:33,457 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:59138
Shutting down the Mini HDFS Cluster
2011-08-09 19:01:33,459 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:33,560 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:33,561 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:33,562 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0 
2011-08-09 19:01:33,565 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47910
2011-08-09 19:01:33,565 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47910: exiting
2011-08-09 19:01:33,566 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47910: exiting
2011-08-09 19:01:33,566 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47910: exiting
2011-08-09 19:01:33,566 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 47910: exiting
2011-08-09 19:01:33,566 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 47910: exiting
2011-08-09 19:01:33,567 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 47910: exiting
2011-08-09 19:01:33,567 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 47910: exiting
2011-08-09 19:01:33,567 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 47910: exiting
2011-08-09 19:01:33,567 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 47910: exiting
2011-08-09 19:01:33,567 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 47910: exiting
2011-08-09 19:01:33,569 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47910
2011-08-09 19:01:33,570 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:33,571 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:33,572 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 1*** Normal DataNode upgrade: numDirs=1
2011-08-09 19:01:33,618 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:33,641 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:33,641 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:33,642 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:33,642 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:33,642 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:33,649 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:33,650 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:33,650 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:33,650 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:33,654 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:33,655 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:33,655 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:33,659 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:33,659 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:33,660 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:33,660 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:33,660 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:33,661 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:33,662 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:33,662 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909293662
2011-08-09 19:01:33,668 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:33,669 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:33,708 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:33,708 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:33,709 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:33,709 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 60 msecs
2011-08-09 19:01:33,709 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:33,710 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:33,717 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:33,722 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:33,724 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=42303
2011-08-09 19:01:33,725 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:42303
2011-08-09 19:01:33,725 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:33,746 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 42303: starting
2011-08-09 19:01:33,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 42303: starting
2011-08-09 19:01:33,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 42303: starting
2011-08-09 19:01:33,746 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 42303: starting
2011-08-09 19:01:33,747 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 42303: starting
2011-08-09 19:01:33,747 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 42303: starting
2011-08-09 19:01:33,747 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 42303: starting
2011-08-09 19:01:33,748 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 42303: starting
2011-08-09 19:01:33,748 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 42303: starting
2011-08-09 19:01:33,748 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 42303: starting
2011-08-09 19:01:33,749 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 42303: starting
2011-08-09 19:01:33,770 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:33,772 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:33,773 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:33,774 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 41139 webServer.getConnectors()[0].getLocalPort() returned 41139
2011-08-09 19:01:33,775 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 41139
2011-08-09 19:01:33,794 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:33,977 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:41139
2011-08-09 19:01:33,978 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:41139
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1
2011-08-09 19:01:34,135 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909293662
2011-08-09 19:01:34,206 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:34,282 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data1 is complete.
2011-08-09 19:01:34,375 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:01:34,376 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 36563
2011-08-09 19:01:34,377 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:01:34,377 INFO  datanode.DataNode (DataNode.java:startDataNode(359)) - Periodic Block Verification is disabled because verification is turned off by configuration.
2011-08-09 19:01:34,381 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:34,382 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:34,389 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 50356 webServer.getConnectors()[0].getLocalPort() returned 50356
2011-08-09 19:01:34,389 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 50356
2011-08-09 19:01:34,390 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:34,476 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:50356
2011-08-09 19:01:34,477 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:01:34,482 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:34,485 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=56692
2011-08-09 19:01:34,486 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:34,515 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 56692: starting
2011-08-09 19:01:34,515 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 56692: starting
2011-08-09 19:01:34,517 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 56692: starting
2011-08-09 19:01:34,517 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:36563, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=50356, ipcPort=56692)
2011-08-09 19:01:34,517 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 56692: starting
2011-08-09 19:01:34,520 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:36563 storage DS-1340858226-10.0.62.238-48313-1312909290951
2011-08-09 19:01:34,521 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:36563
2011-08-09 19:01:34,522 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:36563, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=50356, ipcPort=56692)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current'}
2011-08-09 19:01:34,523 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 10000msec Initial delay: 0msec
2011-08-09 19:01:34,530 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 1 volumes in 0 seconds
2011-08-09 19:01:34,533 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:36563 16 blocks shortCircuit first report.
2011-08-09 19:01:34,533 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:01:34,541 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 16
2011-08-09 19:01:34,542 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:01:34,542 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:01:34,542 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:01:34,543 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:01:34,543 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:01:34,544 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 1 datanodes
2011-08-09 19:01:34,544 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:01:34,545 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 16 blocks got processed in 18 msecs
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:01:34,588 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:34,589 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56692
2011-08-09 19:01:34,589 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 56692: exiting
2011-08-09 19:01:34,589 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 56692: exiting
2011-08-09 19:01:34,589 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 56692: exiting
2011-08-09 19:01:34,590 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 56692
2011-08-09 19:01:34,627 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:34,627 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:36563, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=50356, ipcPort=56692):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:01:34,628 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:34,628 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:36563, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=50356, ipcPort=56692):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current'}
2011-08-09 19:01:34,629 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56692
2011-08-09 19:01:34,629 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:34,630 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:01:34,630 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:01:34,631 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:01:34,634 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:34,736 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0 
2011-08-09 19:01:34,736 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:34,736 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:34,743 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 42303
2011-08-09 19:01:34,746 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 42303: exiting
2011-08-09 19:01:34,746 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 42303
2011-08-09 19:01:34,747 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:34,747 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 42303: exiting
2011-08-09 19:01:34,747 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 42303: exiting
2011-08-09 19:01:34,747 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 42303: exiting
2011-08-09 19:01:34,748 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 42303: exiting
2011-08-09 19:01:34,748 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 42303: exiting
2011-08-09 19:01:34,748 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 42303: exiting
2011-08-09 19:01:34,748 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 42303: exiting
2011-08-09 19:01:34,748 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 42303: exiting
2011-08-09 19:01:34,749 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 42303: exiting
2011-08-09 19:01:34,751 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:34,751 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 2*** NameNode upgrade with existing previous dir: numDirs=1
2011-08-09 19:01:34,808 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:34,812 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:34,813 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:34,813 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:34,813 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:34,813 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:34,821 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:34,821 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:34,821 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:34,821 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:34,824 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:34,825 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:34,825 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:34,829 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: previous fs state should not exist during upgrade. Finalize or rollback first.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:474)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:157)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:34,830 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:34,830 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 3*** DataNode upgrade with existing previous dir: numDirs=1
2011-08-09 19:01:34,858 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:34,862 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:34,862 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:34,862 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:34,862 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:34,862 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:34,868 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:34,868 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:34,868 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:34,868 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:34,872 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:34,872 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:34,873 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:34,876 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:34,876 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:34,877 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:34,877 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:34,877 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:34,878 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:34,879 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:34,879 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909294879
2011-08-09 19:01:34,885 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:34,885 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:35,031 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:35,032 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:35,032 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:35,033 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 165 msecs
2011-08-09 19:01:35,033 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:35,033 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:35,056 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:35,057 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:35,061 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=50740
2011-08-09 19:01:35,062 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:50740
2011-08-09 19:01:35,063 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:35,063 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50740: starting
2011-08-09 19:01:35,086 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50740: starting
2011-08-09 19:01:35,086 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50740: starting
2011-08-09 19:01:35,086 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 50740: starting
2011-08-09 19:01:35,087 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 50740: starting
2011-08-09 19:01:35,087 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 50740: starting
2011-08-09 19:01:35,087 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 50740: starting
2011-08-09 19:01:35,087 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 50740: starting
2011-08-09 19:01:35,087 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 50740: starting
2011-08-09 19:01:35,088 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 50740: starting
2011-08-09 19:01:35,088 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50740: starting
2011-08-09 19:01:35,096 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:35,097 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:35,098 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:35,098 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49786 webServer.getConnectors()[0].getLocalPort() returned 49786
2011-08-09 19:01:35,098 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49786
2011-08-09 19:01:35,098 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:35,283 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49786
2011-08-09 19:01:35,284 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:49786
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1
2011-08-09 19:01:35,517 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909294879
2011-08-09 19:01:35,604 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:35,629 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data1 is complete.
2011-08-09 19:01:35,716 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:01:35,717 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 55306
2011-08-09 19:01:35,718 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:01:35,723 INFO  datanode.DataNode (DataNode.java:startDataNode(359)) - Periodic Block Verification is disabled because verification is turned off by configuration.
2011-08-09 19:01:35,726 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:35,727 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:35,734 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 53444 webServer.getConnectors()[0].getLocalPort() returned 53444
2011-08-09 19:01:35,734 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 53444
2011-08-09 19:01:35,735 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:35,835 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:53444
2011-08-09 19:01:35,836 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:01:35,840 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:35,843 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34475
2011-08-09 19:01:35,844 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:35,845 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34475: starting
2011-08-09 19:01:35,846 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34475: starting
2011-08-09 19:01:35,847 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34475: starting
2011-08-09 19:01:35,847 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:55306, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=53444, ipcPort=34475)
2011-08-09 19:01:35,850 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:55306 storage DS-1340858226-10.0.62.238-48313-1312909290951
2011-08-09 19:01:35,851 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:55306
2011-08-09 19:01:35,851 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34475: starting
2011-08-09 19:01:35,852 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:55306, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=53444, ipcPort=34475)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current'}
2011-08-09 19:01:35,853 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 10000msec Initial delay: 0msec
2011-08-09 19:01:35,901 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 1 volumes in 0 seconds
2011-08-09 19:01:35,903 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:55306 16 blocks shortCircuit first report.
2011-08-09 19:01:35,903 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:01:35,907 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 16
2011-08-09 19:01:35,907 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:01:35,907 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:01:35,907 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:01:35,908 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 1 secs.
2011-08-09 19:01:35,909 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:01:35,909 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 1 datanodes
2011-08-09 19:01:35,909 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:01:35,910 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 16 blocks got processed in 11 msecs
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:01:35,995 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:36,096 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34475
2011-08-09 19:01:36,096 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34475: exiting
2011-08-09 19:01:36,098 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34475: exiting
2011-08-09 19:01:36,097 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34475
2011-08-09 19:01:36,098 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:55306, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=53444, ipcPort=34475):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:01:36,098 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34475: exiting
2011-08-09 19:01:36,099 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:36,099 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:01:36,100 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:55306, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=53444, ipcPort=34475):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current'}
2011-08-09 19:01:36,100 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34475
2011-08-09 19:01:36,101 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:36,101 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:01:36,102 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:01:36,102 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:01:36,118 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:36,223 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:36,220 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:36,224 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0 
2011-08-09 19:01:36,229 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50740
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 50740: exiting
2011-08-09 19:01:36,230 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 50740: exiting
2011-08-09 19:01:36,231 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50740
2011-08-09 19:01:36,231 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 50740: exiting
2011-08-09 19:01:36,232 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 50740: exiting
2011-08-09 19:01:36,233 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:36,236 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:36,236 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 4*** DataNode upgrade with future stored layout version in current: numDirs=1
2011-08-09 19:01:36,258 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:36,261 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:36,261 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:36,262 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:36,262 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:36,262 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:36,268 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:36,268 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:36,268 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:36,269 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:36,272 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:36,272 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:36,273 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:36,277 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:36,277 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:36,277 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:36,278 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:36,278 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:36,278 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:36,280 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:36,280 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909296280
2011-08-09 19:01:36,286 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:36,287 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:36,323 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:36,323 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:36,324 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:36,324 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 56 msecs
2011-08-09 19:01:36,324 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:36,324 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:36,326 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:36,327 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:36,329 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=35946
2011-08-09 19:01:36,330 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:35946
2011-08-09 19:01:36,330 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:36,330 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 35946: starting
2011-08-09 19:01:36,365 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 35946: starting
2011-08-09 19:01:36,365 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 35946: starting
2011-08-09 19:01:36,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 35946: starting
2011-08-09 19:01:36,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 35946: starting
2011-08-09 19:01:36,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 35946: starting
2011-08-09 19:01:36,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 35946: starting
2011-08-09 19:01:36,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 35946: starting
2011-08-09 19:01:36,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 35946: starting
2011-08-09 19:01:36,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 35946: starting
2011-08-09 19:01:36,368 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 35946: starting
2011-08-09 19:01:36,441 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:36,442 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:36,444 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:36,444 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58370 webServer.getConnectors()[0].getLocalPort() returned 58370
2011-08-09 19:01:36,444 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58370
2011-08-09 19:01:36,444 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:36,558 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58370
2011-08-09 19:01:36,559 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:58370
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1
2011-08-09 19:01:36,719 INFO  datanode.DataNode (DataNode.java:<init>(227)) - Failed to start datanode org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1. Reported: -2147483648. Expecting = -27.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:662)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.getFields(DataStorage.java:173)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:227)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:308)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1379)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1334)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:485)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:526)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startDataNodeShouldFail(TestDFSUpgrade.java:114)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)

Shutting down the Mini HDFS Cluster
2011-08-09 19:01:36,857 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:36,859 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:36,859 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:36,865 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0 
2011-08-09 19:01:36,868 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35946
2011-08-09 19:01:36,868 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 35946: exiting
2011-08-09 19:01:36,868 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 35946: exiting
2011-08-09 19:01:36,868 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 35946: exiting
2011-08-09 19:01:36,869 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 35946: exiting
2011-08-09 19:01:36,870 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 35946: exiting
2011-08-09 19:01:36,871 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 35946
2011-08-09 19:01:36,873 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:36,875 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:36,875 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 5*** DataNode upgrade with newer fsscTime in current: numDirs=1
2011-08-09 19:01:36,893 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:36,922 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:36,922 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:36,922 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:36,922 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:36,922 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:36,930 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:36,930 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:36,930 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:36,930 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:36,934 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:36,934 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:36,934 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:36,938 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:36,938 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:36,938 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:36,938 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:36,939 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:36,939 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:36,940 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:36,940 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909296940
2011-08-09 19:01:36,946 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:36,946 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:37,133 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:37,134 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:37,135 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:37,135 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 205 msecs
2011-08-09 19:01:37,135 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:37,135 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:37,177 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:37,181 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=36760
2011-08-09 19:01:37,182 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:36760
2011-08-09 19:01:37,182 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:37,183 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36760: starting
2011-08-09 19:01:37,183 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36760: starting
2011-08-09 19:01:37,183 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36760: starting
2011-08-09 19:01:37,183 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36760: starting
2011-08-09 19:01:37,184 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 36760: starting
2011-08-09 19:01:37,184 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 36760: starting
2011-08-09 19:01:37,184 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 36760: starting
2011-08-09 19:01:37,184 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 36760: starting
2011-08-09 19:01:37,185 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 36760: starting
2011-08-09 19:01:37,185 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 36760: starting
2011-08-09 19:01:37,186 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 36760: starting
2011-08-09 19:01:37,186 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:37,267 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:37,269 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:37,270 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:37,270 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35076 webServer.getConnectors()[0].getLocalPort() returned 35076
2011-08-09 19:01:37,270 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35076
2011-08-09 19:01:37,270 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:37,327 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35076
2011-08-09 19:01:37,328 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:35076
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1
2011-08-09 19:01:37,435 INFO  datanode.DataNode (DataNode.java:<init>(227)) - Failed to start datanode java.io.IOException: Datanode state: LV = -27 CTime = 9223372036854775807 is newer than the namespace state: LV = -27 CTime = 1312909296940
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:249)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:308)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1379)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1334)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:485)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:526)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startDataNodeShouldFail(TestDFSUpgrade.java:114)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)

Shutting down the Mini HDFS Cluster
2011-08-09 19:01:37,466 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:37,566 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:37,582 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0 
2011-08-09 19:01:37,567 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:37,589 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36760
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 36760: exiting
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 36760: exiting
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 36760: exiting
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 36760: exiting
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 36760: exiting
2011-08-09 19:01:37,590 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 36760: exiting
2011-08-09 19:01:37,591 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 36760: exiting
2011-08-09 19:01:37,591 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36760
2011-08-09 19:01:37,591 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36760: exiting
2011-08-09 19:01:37,591 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36760: exiting
2011-08-09 19:01:37,591 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36760: exiting
2011-08-09 19:01:37,592 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:37,594 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,595 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 6*** NameNode upgrade with no edits file: numDirs=1
2011-08-09 19:01:37,636 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,639 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,640 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,640 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,640 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,640 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,645 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,649 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,650 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,650 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,653 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
java.io.IOException: Edits file is not found in [/home/jeff/hadoop-20-warehouse/build/test/data/name1]
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:935)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:480)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:202)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:37,654 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,654 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 7*** NameNode upgrade with no image file: numDirs=1
2011-08-09 19:01:37,685 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,692 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,692 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,692 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,692 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,693 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,700 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,700 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,700 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,700 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,704 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,704 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,704 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,708 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
java.io.IOException: Image file is not found in [/home/jeff/hadoop-20-warehouse/build/test/data/name1]
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:933)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:480)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:210)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:37,708 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,709 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 8*** NameNode upgrade with corrupt version file: numDirs=1
2011-08-09 19:01:37,784 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,787 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,787 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,788 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,788 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,788 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,793 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,794 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,794 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,794 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,798 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,798 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,799 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,802 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: file VERSION is invalid.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:647)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:37,803 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,803 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 9*** NameNode upgrade with old layout version in current: numDirs=1
2011-08-09 19:01:37,824 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,827 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,827 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,828 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,828 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,828 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,834 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,834 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,834 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,834 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,837 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,838 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,838 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,841 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: file VERSION has image MD5 digest when version is -6
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:654)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:37,842 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,842 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 10*** NameNode upgrade with future layout version in current: numDirs=1
2011-08-09 19:01:37,865 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,868 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,868 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,868 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,868 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,868 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,874 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,874 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,874 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,875 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,878 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,878 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,878 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,881 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory /home/jeff/hadoop-20-warehouse/build/test/data/name1. Reported: -2147483648. Expecting = -27.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:662)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:236)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:37,943 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:37,944 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 11*** Normal NameNode upgrade: numDirs=2
2011-08-09 19:01:37,973 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:37,976 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,976 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:37,976 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:37,976 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:37,977 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:37,982 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:37,982 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:37,982 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:37,982 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:37,991 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:37,991 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:37,991 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:37,995 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:37,996 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:37,996 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:37,996 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:37,996 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:37,997 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:37,998 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:37,998 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909297998
2011-08-09 19:01:38,007 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:38,007 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,032 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:38,033 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909297998
2011-08-09 19:01:38,035 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:38,036 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,048 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name2 is complete.
2011-08-09 19:01:38,048 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,049 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,050 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:38,050 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 68 msecs
2011-08-09 19:01:38,051 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:38,051 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:38,090 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:38,092 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:38,094 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=33864
2011-08-09 19:01:38,095 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:33864
2011-08-09 19:01:38,095 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:38,095 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 33864: starting
2011-08-09 19:01:38,118 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 33864: starting
2011-08-09 19:01:38,118 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 33864: starting
2011-08-09 19:01:38,118 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 33864: starting
2011-08-09 19:01:38,118 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 33864: starting
2011-08-09 19:01:38,119 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 33864: starting
2011-08-09 19:01:38,119 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 33864: starting
2011-08-09 19:01:38,120 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 33864: starting
2011-08-09 19:01:38,120 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 33864: starting
2011-08-09 19:01:38,120 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 33864: starting
2011-08-09 19:01:38,121 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 33864: starting
2011-08-09 19:01:38,129 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:38,130 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:38,131 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:38,131 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 50147 webServer.getConnectors()[0].getLocalPort() returned 50147
2011-08-09 19:01:38,131 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 50147
2011-08-09 19:01:38,132 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:38,246 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:50147
2011-08-09 19:01:38,246 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:50147
Shutting down the Mini HDFS Cluster
2011-08-09 19:01:38,347 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:38,448 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:38,448 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:38,448 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits:0 
2011-08-09 19:01:38,455 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33864
2011-08-09 19:01:38,455 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 33864: exiting
2011-08-09 19:01:38,455 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 33864: exiting
2011-08-09 19:01:38,455 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 33864: exiting
2011-08-09 19:01:38,456 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 33864: exiting
2011-08-09 19:01:38,456 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 33864: exiting
2011-08-09 19:01:38,456 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 33864: exiting
2011-08-09 19:01:38,456 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 33864: exiting
2011-08-09 19:01:38,456 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 33864: exiting
2011-08-09 19:01:38,457 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 33864: exiting
2011-08-09 19:01:38,457 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 33864: exiting
2011-08-09 19:01:38,457 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 33864
2011-08-09 19:01:38,459 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:38,461 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:38,461 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 12*** Normal DataNode upgrade: numDirs=2
2011-08-09 19:01:38,493 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:38,496 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:38,496 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:38,496 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:38,496 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:38,496 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:38,500 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:38,501 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:38,501 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:38,501 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:38,504 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:38,505 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:38,505 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:38,509 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:38,509 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:38,509 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:38,509 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:38,510 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:38,510 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:38,512 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:38,512 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909298512
2011-08-09 19:01:38,521 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:38,521 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,636 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:38,637 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909298512
2011-08-09 19:01:38,640 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:38,640 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,652 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name2 is complete.
2011-08-09 19:01:38,653 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,653 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:38,654 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:38,654 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 154 msecs
2011-08-09 19:01:38,655 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:38,655 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:38,656 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:38,699 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:38,701 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=47540
2011-08-09 19:01:38,702 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:47540
2011-08-09 19:01:38,702 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:38,703 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47540: starting
2011-08-09 19:01:38,704 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47540: starting
2011-08-09 19:01:38,704 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47540: starting
2011-08-09 19:01:38,704 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47540: starting
2011-08-09 19:01:38,705 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 47540: starting
2011-08-09 19:01:38,705 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 47540: starting
2011-08-09 19:01:38,705 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 47540: starting
2011-08-09 19:01:38,706 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 47540: starting
2011-08-09 19:01:38,706 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 47540: starting
2011-08-09 19:01:38,706 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 47540: starting
2011-08-09 19:01:38,706 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 47540: starting
2011-08-09 19:01:38,717 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:38,718 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:38,719 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:38,719 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35708 webServer.getConnectors()[0].getLocalPort() returned 35708
2011-08-09 19:01:38,720 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35708
2011-08-09 19:01:38,720 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:38,772 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35708
2011-08-09 19:01:38,773 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:35708
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/data2
2011-08-09 19:01:38,935 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909298512
2011-08-09 19:01:38,936 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909298512
2011-08-09 19:01:39,043 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data2HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:39,054 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:39,099 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data1 is complete.
2011-08-09 19:01:39,102 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data2 is complete.
2011-08-09 19:01:39,299 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:01:39,300 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 47530
2011-08-09 19:01:39,301 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:01:39,301 INFO  datanode.DataNode (DataNode.java:startDataNode(359)) - Periodic Block Verification is disabled because verification is turned off by configuration.
2011-08-09 19:01:39,304 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:39,305 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:39,305 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57938 webServer.getConnectors()[0].getLocalPort() returned 57938
2011-08-09 19:01:39,305 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57938
2011-08-09 19:01:39,305 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:39,430 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57938
2011-08-09 19:01:39,431 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:01:39,442 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:39,444 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41482
2011-08-09 19:01:39,445 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:39,446 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41482: starting
2011-08-09 19:01:39,446 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41482: starting
2011-08-09 19:01:39,488 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:47530, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=57938, ipcPort=41482)
2011-08-09 19:01:39,490 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41482: starting
2011-08-09 19:01:39,488 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41482: starting
2011-08-09 19:01:39,493 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:47530 storage DS-1340858226-10.0.62.238-48313-1312909290951
2011-08-09 19:01:39,494 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:47530
2011-08-09 19:01:39,496 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:47530, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=57938, ipcPort=41482)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/data2/current'}
2011-08-09 19:01:39,497 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 10000msec Initial delay: 0msec
2011-08-09 19:01:39,509 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:01:39,511 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:47530 16 blocks shortCircuit first report.
2011-08-09 19:01:39,512 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:01:39,516 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 16
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:01:39,517 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:01:39,517 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:01:39,518 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:01:39,574 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 1 secs.
2011-08-09 19:01:39,575 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:01:39,575 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 1 datanodes
2011-08-09 19:01:39,575 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:01:39,576 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:39,578 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 16 blocks got processed in 72 msecs
2011-08-09 19:01:39,677 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41482
2011-08-09 19:01:39,677 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41482: exiting
2011-08-09 19:01:39,677 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41482
2011-08-09 19:01:39,678 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41482: exiting
2011-08-09 19:01:39,678 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:01:39,679 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:47530, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=57938, ipcPort=41482):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:01:39,677 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41482: exiting
2011-08-09 19:01:39,679 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:40,679 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:40,679 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:47530, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=57938, ipcPort=41482):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/data2/current'}
2011-08-09 19:01:40,680 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41482
2011-08-09 19:01:40,681 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:40,681 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:01:40,681 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:01:40,682 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:01:40,699 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:40,800 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:40,801 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits:0 
2011-08-09 19:01:40,801 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:40,808 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47540
2011-08-09 19:01:40,809 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47540: exiting
2011-08-09 19:01:40,809 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47540: exiting
2011-08-09 19:01:40,809 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47540: exiting
2011-08-09 19:01:40,809 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 47540: exiting
2011-08-09 19:01:40,810 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 47540: exiting
2011-08-09 19:01:40,810 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 47540: exiting
2011-08-09 19:01:40,810 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 47540: exiting
2011-08-09 19:01:40,811 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 47540: exiting
2011-08-09 19:01:40,811 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47540
2011-08-09 19:01:40,810 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 47540: exiting
2011-08-09 19:01:40,811 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 47540: exiting
2011-08-09 19:01:40,813 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:40,819 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:40,820 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 13*** NameNode upgrade with existing previous dir: numDirs=2
2011-08-09 19:01:40,879 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:40,882 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:40,883 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:40,883 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:40,883 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:40,883 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:40,888 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:40,889 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:40,889 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:40,889 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:40,893 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:40,893 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:40,894 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:40,897 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: previous fs state should not exist during upgrade. Finalize or rollback first.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:474)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:157)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:40,899 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:40,899 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 14*** DataNode upgrade with existing previous dir: numDirs=2
2011-08-09 19:01:40,930 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:40,933 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:40,933 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:40,933 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:40,933 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:40,933 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:40,938 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:40,939 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:40,939 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:40,939 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:40,942 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:40,942 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:40,944 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:40,948 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:40,948 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:40,948 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:40,949 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:40,949 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:40,949 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:40,951 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:40,951 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909300951
2011-08-09 19:01:40,981 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:40,981 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:41,016 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:41,017 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909300951
2011-08-09 19:01:41,019 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:41,019 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:41,031 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name2 is complete.
2011-08-09 19:01:41,032 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:41,032 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:41,033 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:41,033 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 95 msecs
2011-08-09 19:01:41,033 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:41,034 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:41,076 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:41,077 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:41,079 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=43700
2011-08-09 19:01:41,080 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:43700
2011-08-09 19:01:41,080 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:41,081 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 43700: starting
2011-08-09 19:01:41,081 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 43700: starting
2011-08-09 19:01:41,081 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 43700: starting
2011-08-09 19:01:41,081 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 43700: starting
2011-08-09 19:01:41,082 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 43700: starting
2011-08-09 19:01:41,123 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 43700: starting
2011-08-09 19:01:41,123 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 43700: starting
2011-08-09 19:01:41,123 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 43700: starting
2011-08-09 19:01:41,124 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 43700: starting
2011-08-09 19:01:41,124 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 43700: starting
2011-08-09 19:01:41,124 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 43700: starting
2011-08-09 19:01:41,152 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:41,154 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:41,154 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:41,155 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 47765 webServer.getConnectors()[0].getLocalPort() returned 47765
2011-08-09 19:01:41,155 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 47765
2011-08-09 19:01:41,155 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:41,206 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:47765
2011-08-09 19:01:41,208 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:47765
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/data2
2011-08-09 19:01:41,464 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909300951
2011-08-09 19:01:41,466 INFO  common.Storage (DataStorage.java:run(279)) - Upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909300951
2011-08-09 19:01:41,575 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:41,590 INFO  common.Storage (DataStorage.java:run(297)) - Completed upgrading storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data2HardLinkStats: 1 Directories, including 0 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 32 files, total 32 linkable files.  Also physically copied 1 other files.
2011-08-09 19:01:41,634 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data1 is complete.
2011-08-09 19:01:41,637 INFO  common.Storage (DataStorage.java:doUpgrade(348)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/data2 is complete.
2011-08-09 19:01:41,807 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:01:41,808 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 52626
2011-08-09 19:01:41,809 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:01:41,809 INFO  datanode.DataNode (DataNode.java:startDataNode(359)) - Periodic Block Verification is disabled because verification is turned off by configuration.
2011-08-09 19:01:41,812 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:41,812 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:41,813 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48356 webServer.getConnectors()[0].getLocalPort() returned 48356
2011-08-09 19:01:41,813 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48356
2011-08-09 19:01:41,813 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:41,876 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48356
2011-08-09 19:01:41,877 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:01:41,882 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:41,884 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=52498
2011-08-09 19:01:41,886 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:41,922 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 52498: starting
2011-08-09 19:01:41,922 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:52626, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=48356, ipcPort=52498)
2011-08-09 19:01:41,923 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 52498: starting
2011-08-09 19:01:41,948 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 52498: starting
2011-08-09 19:01:41,949 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 52498: starting
2011-08-09 19:01:41,949 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:52626 storage DS-1340858226-10.0.62.238-48313-1312909290951
2011-08-09 19:01:41,950 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:52626
2011-08-09 19:01:41,952 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:52626, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=48356, ipcPort=52498)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/data2/current'}
2011-08-09 19:01:41,953 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 10000msec Initial delay: 0msec
Shutting down the Mini HDFS Cluster
Shutting down DataNode 0
2011-08-09 19:01:42,016 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:01:42,018 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:52626 16 blocks shortCircuit first report.
2011-08-09 19:01:42,019 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:42,019 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:01:42,024 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 16
2011-08-09 19:01:42,032 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:01:42,032 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 1
2011-08-09 19:01:42,032 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:01:42,034 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 1 secs.
2011-08-09 19:01:42,034 INFO  hdfs.StateChange (FSNamesystem.java:leave(5274)) - STATE* Safe mode is OFF.
2011-08-09 19:01:42,034 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 1 racks and 1 datanodes
2011-08-09 19:01:42,034 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 1 blocks
2011-08-09 19:01:42,036 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 16 blocks got processed in 77 msecs
2011-08-09 19:01:42,137 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52498
2011-08-09 19:01:42,137 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 52498: exiting
2011-08-09 19:01:42,137 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 52498: exiting
2011-08-09 19:01:42,137 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 52498: exiting
2011-08-09 19:01:42,138 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 52498
2011-08-09 19:01:42,138 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:42,139 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:52626, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=48356, ipcPort=52498):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:01:42,140 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:42,140 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:52626, storageID=DS-1340858226-10.0.62.238-48313-1312909290951, infoPort=48356, ipcPort=52498):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/data2/current'}
2011-08-09 19:01:42,141 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52498
2011-08-09 19:01:42,142 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:01:42,142 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:01:42,143 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:01:42,143 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:01:42,234 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:42,336 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:42,336 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:42,337 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits:0 
2011-08-09 19:01:42,344 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 43700
2011-08-09 19:01:42,344 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 43700: exiting
2011-08-09 19:01:42,345 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 43700: exiting
2011-08-09 19:01:42,345 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 43700: exiting
2011-08-09 19:01:42,345 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 43700: exiting
2011-08-09 19:01:42,345 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 43700: exiting
2011-08-09 19:01:42,345 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 43700: exiting
2011-08-09 19:01:42,346 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 43700: exiting
2011-08-09 19:01:42,346 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 43700: exiting
2011-08-09 19:01:42,346 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 43700: exiting
2011-08-09 19:01:42,346 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 43700: exiting
2011-08-09 19:01:42,347 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 43700
2011-08-09 19:01:42,349 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:42,355 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:42,355 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 15*** DataNode upgrade with future stored layout version in current: numDirs=2
2011-08-09 19:01:42,388 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:42,395 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:42,395 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:42,396 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:42,396 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:42,396 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:42,402 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:42,403 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:42,403 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:42,403 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:42,406 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:42,406 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:42,407 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:42,411 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:42,411 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:42,411 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:42,412 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:42,412 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:42,412 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:42,414 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:42,414 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909302414
2011-08-09 19:01:42,424 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:42,424 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:42,584 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:42,585 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909302414
2011-08-09 19:01:42,587 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:42,587 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:42,600 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name2 is complete.
2011-08-09 19:01:42,601 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:42,602 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:42,603 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:42,603 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 201 msecs
2011-08-09 19:01:42,603 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:42,604 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:42,605 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:42,607 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:42,609 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=54272
2011-08-09 19:01:42,610 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:54272
2011-08-09 19:01:42,610 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:42,610 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54272: starting
2011-08-09 19:01:42,611 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54272: starting
2011-08-09 19:01:42,611 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54272: starting
2011-08-09 19:01:42,612 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54272: starting
2011-08-09 19:01:42,612 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 54272: starting
2011-08-09 19:01:42,612 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 54272: starting
2011-08-09 19:01:42,612 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 54272: starting
2011-08-09 19:01:42,613 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 54272: starting
2011-08-09 19:01:42,613 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 54272: starting
2011-08-09 19:01:42,613 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 54272: starting
2011-08-09 19:01:42,613 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 54272: starting
2011-08-09 19:01:42,663 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:42,664 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:42,665 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:42,665 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 50258 webServer.getConnectors()[0].getLocalPort() returned 50258
2011-08-09 19:01:42,666 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 50258
2011-08-09 19:01:42,666 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:42,729 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:50258
2011-08-09 19:01:42,730 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:50258
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/data2
2011-08-09 19:01:42,913 INFO  datanode.DataNode (DataNode.java:<init>(227)) - Failed to start datanode org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory /home/jeff/hadoop-20-warehouse/build/test/data/data1. Reported: -2147483648. Expecting = -27.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:662)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.getFields(DataStorage.java:173)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:227)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:308)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1379)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1334)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:485)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:526)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startDataNodeShouldFail(TestDFSUpgrade.java:114)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:179)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)

Shutting down the Mini HDFS Cluster
2011-08-09 19:01:42,956 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:43,057 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:43,058 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:43,058 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits:0 
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54272
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 54272: exiting
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54272: exiting
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54272: exiting
2011-08-09 19:01:43,066 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 54272: exiting
2011-08-09 19:01:43,066 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54272
2011-08-09 19:01:43,066 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 54272: exiting
2011-08-09 19:01:43,071 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,071 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 16*** DataNode upgrade with newer fsscTime in current: numDirs=2
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 54272: exiting
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 54272: exiting
2011-08-09 19:01:43,077 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 54272: exiting
2011-08-09 19:01:43,065 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 54272: exiting
2011-08-09 19:01:43,067 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54272: exiting
2011-08-09 19:01:43,129 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:43,132 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,133 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:43,133 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:43,133 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:43,133 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:43,139 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:43,139 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:43,139 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:43,140 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:43,143 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,143 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:43,144 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:43,147 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 4
2011-08-09 19:01:43,148 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 25% of the image
2011-08-09 19:01:43,148 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 50% of the image
2011-08-09 19:01:43,148 INFO  common.Storage (FSImage.java:loadFSImage(1043)) - Loaded 75% of the image
2011-08-09 19:01:43,148 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:01:43,148 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 501 loaded in 0 seconds.
2011-08-09 19:01:43,149 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits of size 648 edits # 6 loaded in 0 seconds.
2011-08-09 19:01:43,150 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name1.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909303150
2011-08-09 19:01:43,159 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:43,159 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:43,195 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name1 is complete.
2011-08-09 19:01:43,195 INFO  common.Storage (FSImage.java:doUpgrade(491)) - Upgrading image directory /home/jeff/hadoop-20-warehouse/build/test/data/name2.
   old LV = -27; old CTime = 0.
   new LV = -27; new CTime = 1312909303150
2011-08-09 19:01:43,197 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 829 saved in 0 seconds.
2011-08-09 19:01:43,198 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:43,210 INFO  common.Storage (FSImage.java:doUpgrade(514)) - Upgrade of /home/jeff/hadoop-20-warehouse/build/test/data/name2 is complete.
2011-08-09 19:01:43,210 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:43,211 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:01:43,211 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:01:43,211 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 72 msecs
2011-08-09 19:01:43,212 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5472)) - STATE* Safe mode ON. 
The ratio of reported blocks 0.00000000 has not reached the threshold 0.99900001. Safe blocks = 0, Total blocks = 16.Safe mode will be turned off automatically.
2011-08-09 19:01:43,212 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:01:43,213 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:01:43,215 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:01:43,217 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=53113
2011-08-09 19:01:43,218 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:53113
2011-08-09 19:01:43,218 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:01:43,218 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53113: starting
2011-08-09 19:01:43,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53113: starting
2011-08-09 19:01:43,219 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53113: starting
2011-08-09 19:01:43,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53113: starting
2011-08-09 19:01:43,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 53113: starting
2011-08-09 19:01:43,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 53113: starting
2011-08-09 19:01:43,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 53113: starting
2011-08-09 19:01:43,220 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 53113: starting
2011-08-09 19:01:43,221 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 53113: starting
2011-08-09 19:01:43,221 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 53113: starting
2011-08-09 19:01:43,221 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 53113: starting
2011-08-09 19:01:43,267 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:01:43,269 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:01:43,269 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:01:43,270 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36077 webServer.getConnectors()[0].getLocalPort() returned 36077
2011-08-09 19:01:43,270 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36077
2011-08-09 19:01:43,270 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:01:43,323 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36077
2011-08-09 19:01:43,323 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:36077
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/data2
2011-08-09 19:01:43,557 INFO  datanode.DataNode (DataNode.java:<init>(227)) - Failed to start datanode java.io.IOException: Datanode state: LV = -27 CTime = 9223372036854775807 is newer than the namespace state: LV = -27 CTime = 1312909303150
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:249)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:148)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:308)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:225)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1379)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1334)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:485)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:526)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startDataNodeShouldFail(TestDFSUpgrade.java:114)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)

Shutting down the Mini HDFS Cluster
2011-08-09 19:01:43,560 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:01:43,660 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/name2/current/edits:0 
2011-08-09 19:01:43,661 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:01:43,660 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:01:43,668 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53113
2011-08-09 19:01:43,668 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53113: exiting
2011-08-09 19:01:43,668 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53113: exiting
2011-08-09 19:01:43,669 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 53113: exiting
2011-08-09 19:01:43,669 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 53113: exiting
2011-08-09 19:01:43,669 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53113: exiting
2011-08-09 19:01:43,669 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53113
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 53113: exiting
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 53113: exiting
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 53113: exiting
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 53113: exiting
2011-08-09 19:01:43,670 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 53113: exiting
2011-08-09 19:01:43,675 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,675 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 17*** NameNode upgrade with no edits file: numDirs=2
2011-08-09 19:01:43,702 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:43,705 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,705 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:43,705 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:43,705 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:43,705 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:43,711 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:43,711 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:43,711 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:43,711 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:43,714 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,715 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:43,716 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:43,719 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
java.io.IOException: Edits file is not found in [/home/jeff/hadoop-20-warehouse/build/test/data/name1, /home/jeff/hadoop-20-warehouse/build/test/data/name2]
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:935)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:480)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:202)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:43,721 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,721 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 18*** NameNode upgrade with no image file: numDirs=2
2011-08-09 19:01:43,749 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:43,752 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,752 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:43,752 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:43,752 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:43,752 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:43,757 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:43,757 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:43,757 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:43,758 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:43,761 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,761 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:43,761 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:43,765 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
java.io.IOException: Image file is not found in [/home/jeff/hadoop-20-warehouse/build/test/data/name1, /home/jeff/hadoop-20-warehouse/build/test/data/name2]
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:933)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade(FSImage.java:480)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:446)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:210)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:43,766 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,766 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 19*** NameNode upgrade with corrupt version file: numDirs=2
2011-08-09 19:01:43,907 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:43,910 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,910 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:43,911 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:43,911 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:43,911 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:43,917 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:43,917 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:43,917 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:43,917 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:43,920 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,920 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:43,921 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:43,924 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: file VERSION is invalid.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:647)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:43,925 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,925 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 20*** NameNode upgrade with old layout version in current: numDirs=2
2011-08-09 19:01:43,963 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:43,967 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,967 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:43,967 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:43,968 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:43,968 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:43,974 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:43,974 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:43,974 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:43,975 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:43,978 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:43,978 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:43,979 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:43,982 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/jeff/hadoop-20-warehouse/build/test/data/name1 is in an inconsistent state: file VERSION has image MD5 digest when version is -6
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:654)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:43,983 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(54)) - ============================================================
2011-08-09 19:01:43,983 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:log(55)) - ***TEST 21*** NameNode upgrade with future layout version in current: numDirs=2
2011-08-09 19:01:44,024 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:01:44,027 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:44,027 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:01:44,027 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:01:44,027 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:01:44,027 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:01:44,033 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:01:44,034 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:01:44,034 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:01:44,034 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:01:44,037 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:01:44,037 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:01:44,038 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:01:44,041 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(347)) - FSNamesystem initialization failed.
org.apache.hadoop.hdfs.server.common.IncorrectVersionException: Unexpected version of storage directory /home/jeff/hadoop-20-warehouse/build/test/data/name1. Reported: -2147483648. Expecting = -27.
	at org.apache.hadoop.hdfs.server.common.Storage.getFields(Storage.java:662)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.getFields(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:238)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.read(Storage.java:227)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:394)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.loadFSImage(FSDirectory.java:151)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initialize(FSNamesystem.java:369)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:345)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:273)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:357)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1246)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:342)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:260)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.startNameNodeShouldFail(TestDFSUpgrade.java:101)
	at org.apache.hadoop.hdfs.TestDFSUpgrade.testUpgrade(TestDFSUpgrade.java:236)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:01:44,042 INFO  hdfs.TestDFSUpgrade (TestDFSUpgrade.java:tearDown(242)) - Shutting down MiniDFSCluster
Shutting down the Mini HDFS Cluster
------------- ---------------- ---------------

Testcase: testUpgrade took 73.534 sec
