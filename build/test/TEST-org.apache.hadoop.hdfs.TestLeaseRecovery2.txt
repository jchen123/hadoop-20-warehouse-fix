Testsuite: org.apache.hadoop.hdfs.TestLeaseRecovery2
Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 162.735 sec
------------- Standard Output ---------------
2011-08-09 19:55:40,920 WARN  conf.Configuration (Configuration.java:<clinit>(191)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2011-08-09 19:55:41,262 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:55:41,264 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:55:41,265 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:55:41,265 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:55:41,298 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:55:41,299 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:55:41,299 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:55:41,407 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:55:41,543 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:55:41,547 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:55:41,549 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:55:41,550 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:55:41,557 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:55:41,582 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:55:41,585 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:55:41,586 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:55:41,587 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 0
2011-08-09 19:55:41,587 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049088 written 512 bytes  at offset 1048576
2011-08-09 19:55:41,588 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 5
2011-08-09 19:55:41,599 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:55:41,619 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 19:55:41,690 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:55:41,690 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:55:41,691 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:55:41,691 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:55:41,691 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:55:41,767 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:55:41,768 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:55:41,768 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:55:41,768 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:55:41,794 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:55:41,795 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:55:41,805 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:55:41,812 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:55:41,812 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:55:41,813 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:55:41,815 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:55:41,816 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:55:41,817 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:55:41,818 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:55:41,819 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 53 msecs
2011-08-09 19:55:41,820 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:55:41,831 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:55:41,831 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:55:41,831 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:55:41,832 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:55:41,832 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:55:41,858 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:55:41,862 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=57846
2011-08-09 19:55:41,866 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:57846
2011-08-09 19:55:41,867 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:55:41,869 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57846: starting
2011-08-09 19:55:41,869 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57846: starting
2011-08-09 19:55:41,870 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57846: starting
2011-08-09 19:55:41,879 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57846: starting
2011-08-09 19:55:41,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 57846: starting
2011-08-09 19:55:41,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 57846: starting
2011-08-09 19:55:41,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 57846: starting
2011-08-09 19:55:41,881 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 57846: starting
2011-08-09 19:55:41,881 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 57846: starting
2011-08-09 19:55:41,881 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 57846: starting
2011-08-09 19:55:41,897 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 57846: starting
2011-08-09 19:55:41,969 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:55:41,970 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:55:41,970 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:55:41,971 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:55:41,973 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:pendingReplicationCheck(201)) - PendingReplicationMonitor checking Q
2011-08-09 19:55:41,977 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:55:42,056 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 19:55:42,157 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:55:42,165 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:55:42,166 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59171 webServer.getConnectors()[0].getLocalPort() returned 59171
2011-08-09 19:55:42,167 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59171
2011-08-09 19:55:42,167 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:55:42,631 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59171
2011-08-09 19:55:42,631 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:59171
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:55:42,678 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:55:42,678 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:55:42,696 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:55:42,696 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:55:42,846 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:55:42,847 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48788
2011-08-09 19:55:42,850 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:55:42,857 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:55:42,860 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:55:42,860 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 47197 webServer.getConnectors()[0].getLocalPort() returned 47197
2011-08-09 19:55:42,861 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 47197
2011-08-09 19:55:42,861 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:55:43,077 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:47197
2011-08-09 19:55:43,080 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:55:43,107 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49590
2011-08-09 19:55:43,109 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:55:43,129 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:55:43,150 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49590: starting
2011-08-09 19:55:43,151 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49590: starting
2011-08-09 19:55:43,153 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49590: starting
2011-08-09 19:55:43,154 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48788, storageID=, infoPort=47197, ipcPort=49590)
2011-08-09 19:55:43,156 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49590: starting
2011-08-09 19:56:14,629 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48788 storage DS-574479426-10.0.62.238-48788-1312912574624
2011-08-09 19:56:14,635 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48788
2011-08-09 19:56:14,641 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-574479426-10.0.62.238-48788-1312912574624 is assigned to data-node 127.0.0.1:48788
2011-08-09 19:56:14,641 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:56:14,642 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:56:14,654 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:14,656 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:56:14,656 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48788 0 blocks shortCircuit first report.
2011-08-09 19:56:14,656 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:14,657 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:56:14,657 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:56:14,658 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:14,673 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:56:14,673 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:14,768 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:56:14,769 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 33808
2011-08-09 19:56:14,770 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:56:14,773 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:56:14,774 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:56:14,781 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 56663 webServer.getConnectors()[0].getLocalPort() returned 56663
2011-08-09 19:56:14,782 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 56663
2011-08-09 19:56:14,782 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:56:15,112 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:56663
2011-08-09 19:56:15,113 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:56:15,151 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:56:15,171 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60980
2011-08-09 19:56:15,198 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:56:15,201 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60980: starting
2011-08-09 19:56:15,252 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60980: starting
2011-08-09 19:56:15,255 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60980: starting
2011-08-09 19:56:15,257 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:33808, storageID=, infoPort=56663, ipcPort=60980)
2011-08-09 19:56:15,257 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60980: starting
2011-08-09 19:56:15,262 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:33808 storage DS-277678909-10.0.62.238-33808-1312912575260
2011-08-09 19:56:15,263 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:33808
2011-08-09 19:56:15,279 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-277678909-10.0.62.238-33808-1312912575260 is assigned to data-node 127.0.0.1:33808
2011-08-09 19:56:15,291 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
Starting DataNode 2 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6
2011-08-09 19:56:15,332 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:56:15,381 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5 is not formatted.
2011-08-09 19:56:15,381 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:15,384 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:15,387 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:33808 0 blocks shortCircuit first report.
2011-08-09 19:56:15,388 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 5 msecs
2011-08-09 19:56:15,389 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:56:15,389 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:15,398 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6 is not formatted.
2011-08-09 19:56:15,398 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:15,510 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:56:15,512 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 56616
2011-08-09 19:56:15,512 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:56:15,517 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:56:15,518 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:56:15,519 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48011 webServer.getConnectors()[0].getLocalPort() returned 48011
2011-08-09 19:56:15,519 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48011
2011-08-09 19:56:15,519 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:56:15,736 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48011
2011-08-09 19:56:15,737 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:56:15,751 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:56:15,782 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=46091
2011-08-09 19:56:15,783 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:56:15,817 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 46091: starting
2011-08-09 19:56:15,818 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 46091: starting
2011-08-09 19:56:15,818 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:56616, storageID=, infoPort=48011, ipcPort=46091)
2011-08-09 19:56:15,818 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 46091: starting
2011-08-09 19:56:15,817 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 46091: starting
2011-08-09 19:56:15,825 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:56616 storage DS-1212468723-10.0.62.238-56616-1312912575824
2011-08-09 19:56:15,825 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:56616
2011-08-09 19:56:15,832 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1212468723-10.0.62.238-56616-1312912575824 is assigned to data-node 127.0.0.1:56616
2011-08-09 19:56:15,833 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
Starting DataNode 3 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8
2011-08-09 19:56:15,870 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:56:15,883 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:15,884 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:56616 0 blocks shortCircuit first report.
2011-08-09 19:56:15,884 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:56:15,885 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:56:15,886 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:15,886 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7 is not formatted.
2011-08-09 19:56:15,886 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:15,903 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8 is not formatted.
2011-08-09 19:56:15,903 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:16,009 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:56:16,010 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44003
2011-08-09 19:56:16,011 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:56:16,014 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:56:16,015 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:56:16,015 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 32903 webServer.getConnectors()[0].getLocalPort() returned 32903
2011-08-09 19:56:16,016 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 32903
2011-08-09 19:56:16,016 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:56:16,106 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:32903
2011-08-09 19:56:16,108 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:56:16,113 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:56:16,115 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60852
2011-08-09 19:56:16,117 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:56:16,117 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60852: starting
2011-08-09 19:56:16,159 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60852: starting
2011-08-09 19:56:16,159 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60852: starting
2011-08-09 19:56:16,181 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44003, storageID=, infoPort=32903, ipcPort=60852)
2011-08-09 19:56:16,182 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60852: starting
2011-08-09 19:56:16,187 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44003 storage DS-923530740-10.0.62.238-44003-1312912576184
2011-08-09 19:56:16,187 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44003
2011-08-09 19:56:16,193 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-923530740-10.0.62.238-44003-1312912576184 is assigned to data-node 127.0.0.1:44003
2011-08-09 19:56:16,194 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
2011-08-09 19:56:16,195 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
Starting DataNode 4 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10
2011-08-09 19:56:16,203 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:16,206 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:44003 0 blocks shortCircuit first report.
2011-08-09 19:56:16,206 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:56:16,207 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9 is not formatted.
2011-08-09 19:56:16,207 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:16,207 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:56:16,208 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:16,222 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10 is not formatted.
2011-08-09 19:56:16,223 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:56:16,432 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:56:16,433 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 49989
2011-08-09 19:56:16,434 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:56:16,437 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:56:16,438 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:56:16,446 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34951 webServer.getConnectors()[0].getLocalPort() returned 34951
2011-08-09 19:56:16,446 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34951
2011-08-09 19:56:16,447 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:56:16,632 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34951
2011-08-09 19:56:16,633 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:56:16,702 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:56:16,707 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=58463
2011-08-09 19:56:16,712 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:56:16,720 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 58463: starting
2011-08-09 19:56:16,722 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 58463: starting
2011-08-09 19:56:16,722 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 58463: starting
2011-08-09 19:56:16,722 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:49989, storageID=, infoPort=34951, ipcPort=58463)
2011-08-09 19:56:16,723 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 58463: starting
2011-08-09 19:56:16,726 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:49989 storage DS-1407648578-10.0.62.238-49989-1312912576725
2011-08-09 19:56:16,727 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:49989
2011-08-09 19:56:16,733 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1407648578-10.0.62.238-49989-1312912576725 is assigned to data-node 127.0.0.1:49989
2011-08-09 19:56:16,733 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:56:16,768 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:56:16,772 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:16,773 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:49989 0 blocks shortCircuit first report.
2011-08-09 19:56:16,774 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:56:16,774 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:56:16,775 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:56:16,806 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(49)) - seed=-6002918330399662461
2011-08-09 19:56:16,806 INFO  hdfs.AppendTestUtil (AppendTestUtil.java:initialValue(59)) - main: seed=-3684328457123397870
filestr=/foo875571745
2011-08-09 19:56:16,817 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:56:16,817 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -23]
2011-08-09 19:56:16,820 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 57, 53, 56, 53, 49, 53, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:56:16,821 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 0, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 57, 53, 56, 53, 49, 53, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:56:16,822 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:56:16,822 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:56:16,822 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 130
2011-08-09 19:56:16,829 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(284)) - Preallocating Edit log, current size 4
2011-08-09 19:56:16,829 DEBUG namenode.FSNamesystem (FSEditLog.java:preallocate(289)) - Edit log size is now 1049092 written 512 bytes  at offset 1048580
2011-08-09 19:56:16,829 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 130
2011-08-09 19:56:16,834 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/foo875571745	dst=null	perm=jeff:supergroup:rw-r--r--
size=9332
2011-08-09 19:56:16,844 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-4856947659772128003_1001
2011-08-09 19:56:16,850 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:16,933 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:16,933 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4856947659772128003_1001 src: /127.0.0.1:50452 dest: /127.0.0.1:56616
2011-08-09 19:56:16,939 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4856947659772128003 of size 0
2011-08-09 19:56:16,939 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4856947659772128003_1001.meta of size 0
2011-08-09 19:56:16,940 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:16,942 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:16,943 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4856947659772128003_1001 src: /127.0.0.1:47410 dest: /127.0.0.1:44003
2011-08-09 19:56:16,944 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4856947659772128003 of size 0
2011-08-09 19:56:16,944 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4856947659772128003_1001.meta of size 0
2011-08-09 19:56:16,945 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:16,945 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:16,945 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4856947659772128003_1001 src: /127.0.0.1:33667 dest: /127.0.0.1:33808
2011-08-09 19:56:16,946 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-4856947659772128003 of size 0
2011-08-09 19:56:16,946 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-4856947659772128003_1001.meta of size 0
2011-08-09 19:56:16,946 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:16,947 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:16,947 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:16,948 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:16,948 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:16,955 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4856947659772128003_1001 of length 1036 seqno 0 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:16,956 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 0 to ack queue.
2011-08-09 19:56:16,956 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4856947659772128003_1001 of length 1036 seqno 0 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:16,957 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 0 to ack queue.
2011-08-09 19:56:16,955 INFO  hdfs.AppendTestUtil (TestLeaseRecovery2.java:testBlockSynchronization(81)) - sync
2011-08-09 19:56:16,957 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4856947659772128003_1001 of length 1036 seqno 0 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:16,959 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 0 to ack queue.
2011-08-09 19:56:16,960 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-4856947659772128003_1001 acking for packet 0
2011-08-09 19:56:16,961 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-4856947659772128003_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-4856947659772128003_1001.meta
2011-08-09 19:56:16,961 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-4856947659772128003 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-4856947659772128003
2011-08-09 19:56:16,962 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:33667, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-4856947659772128003_1001, duration: 3329102
2011-08-09 19:56:16,962 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4856947659772128003_1001 terminating
2011-08-09 19:56:16,962 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 0
2011-08-09 19:56:16,963 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 0
2011-08-09 19:56:16,964 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_-4856947659772128003_1001 size 1024
2011-08-09 19:56:16,967 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4856947659772128003_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current/blk_-4856947659772128003_1001.meta
2011-08-09 19:56:16,967 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4856947659772128003 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current/blk_-4856947659772128003
2011-08-09 19:56:16,967 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:47410, dest: /127.0.0.1:44003, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-923530740-10.0.62.238-44003-1312912576184, blockid: blk_-4856947659772128003_1001, duration: 16552173
2011-08-09 19:56:16,968 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-4856947659772128003_1001 responded my status  for seqno 0
2011-08-09 19:56:16,968 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4856947659772128003_1001 1 responded other status  for seqno 0
2011-08-09 19:56:16,968 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-4856947659772128003_1001 terminating
2011-08-09 19:56:16,969 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 0
2011-08-09 19:56:16,969 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44003 is added to blk_-4856947659772128003_1001 size 1024
2011-08-09 19:56:16,969 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 0
2011-08-09 19:56:16,971 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4856947659772128003_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4856947659772128003_1001.meta
2011-08-09 19:56:16,971 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4856947659772128003 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4856947659772128003
2011-08-09 19:56:16,973 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-4856947659772128003_1001 size 1024
2011-08-09 19:56:16,974 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50452, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-4856947659772128003_1001, duration: 16208169
2011-08-09 19:56:16,974 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-4856947659772128003_1001 responded my status  for seqno 0
2011-08-09 19:56:16,975 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-4856947659772128003_1001 Closing down.
2011-08-09 19:56:16,975 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-4856947659772128003_1001 Closing down.
2011-08-09 19:56:16,975 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-4856947659772128003_1001 Closing down.
2011-08-09 19:56:16,976 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4856947659772128003_1001 2 responded other status  for seqno 0
2011-08-09 19:56:17,003 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-4856947659772128003_1001 terminating
2011-08-09 19:56:17,011 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,011 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,011 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Number of active connections is: 2
2011-08-09 19:56:17,014 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_2676346411578617259_1001
2011-08-09 19:56:17,015 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,016 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,016 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2676346411578617259_1001 src: /127.0.0.1:50455 dest: /127.0.0.1:56616
2011-08-09 19:56:17,023 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_2676346411578617259 of size 0
2011-08-09 19:56:17,023 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_2676346411578617259_1001.meta of size 0
2011-08-09 19:56:17,023 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,024 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,024 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2676346411578617259_1001 src: /127.0.0.1:54980 dest: /127.0.0.1:48788
2011-08-09 19:56:17,025 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_2676346411578617259 of size 0
2011-08-09 19:56:17,025 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_2676346411578617259_1001.meta of size 0
2011-08-09 19:56:17,025 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,026 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,026 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2676346411578617259_1001 src: /127.0.0.1:33670 dest: /127.0.0.1:33808
2011-08-09 19:56:17,027 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_2676346411578617259 of size 0
2011-08-09 19:56:17,027 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_2676346411578617259_1001.meta of size 0
2011-08-09 19:56:17,027 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,028 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,028 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,028 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,028 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,072 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_2676346411578617259_1001 of length 1036 seqno 1 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,073 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 1 to ack queue.
2011-08-09 19:56:17,073 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_2676346411578617259_1001 of length 1036 seqno 1 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,073 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_2676346411578617259_1001 of length 1036 seqno 1 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,074 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 1 to ack queue.
2011-08-09 19:56:17,074 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 1 to ack queue.
2011-08-09 19:56:17,079 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_2676346411578617259_1001 acking for packet 1
2011-08-09 19:56:17,082 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_2676346411578617259_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_2676346411578617259_1001.meta
2011-08-09 19:56:17,082 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_2676346411578617259 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_2676346411578617259
2011-08-09 19:56:17,083 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:33670, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_2676346411578617259_1001, duration: 53856111
2011-08-09 19:56:17,083 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_2676346411578617259_1001 terminating
2011-08-09 19:56:17,083 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_2676346411578617259_1001 size 1024
2011-08-09 19:56:17,083 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 1
2011-08-09 19:56:17,084 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 1
2011-08-09 19:56:17,085 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_2676346411578617259_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_2676346411578617259_1001.meta
2011-08-09 19:56:17,085 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_2676346411578617259 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_2676346411578617259
2011-08-09 19:56:17,085 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:54980, dest: /127.0.0.1:48788, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-574479426-10.0.62.238-48788-1312912574624, blockid: blk_2676346411578617259_1001, duration: 13417010
2011-08-09 19:56:17,085 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48788 is added to blk_2676346411578617259_1001 size 1024
2011-08-09 19:56:17,086 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_2676346411578617259_1001 responded my status  for seqno 1
2011-08-09 19:56:17,086 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_2676346411578617259_1001 1 responded other status  for seqno 1
2011-08-09 19:56:17,086 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_2676346411578617259_1001 terminating
2011-08-09 19:56:17,087 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 1
2011-08-09 19:56:17,087 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 1
2011-08-09 19:56:17,088 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_2676346411578617259_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_2676346411578617259_1001.meta
2011-08-09 19:56:17,088 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_2676346411578617259 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_2676346411578617259
2011-08-09 19:56:17,089 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50455, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_2676346411578617259_1001, duration: 59145563
2011-08-09 19:56:17,089 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_2676346411578617259_1001 responded my status  for seqno 1
2011-08-09 19:56:17,089 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_2676346411578617259_1001 Closing down.
2011-08-09 19:56:17,089 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_2676346411578617259_1001 2 responded other status  for seqno 1
2011-08-09 19:56:17,090 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_2676346411578617259_1001 terminating
2011-08-09 19:56:17,091 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_2676346411578617259_1001 Closing down.
2011-08-09 19:56:17,091 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_2676346411578617259_1001 size 1024
2011-08-09 19:56:17,091 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_2676346411578617259_1001 Closing down.
2011-08-09 19:56:17,093 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,093 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-7247974470154199534_1001
2011-08-09 19:56:17,093 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,094 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Number of active connections is: 2
2011-08-09 19:56:17,094 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,095 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,095 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7247974470154199534_1001 src: /127.0.0.1:50458 dest: /127.0.0.1:56616
2011-08-09 19:56:17,096 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-7247974470154199534 of size 0
2011-08-09 19:56:17,096 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-7247974470154199534_1001.meta of size 0
2011-08-09 19:56:17,097 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,097 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,097 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7247974470154199534_1001 src: /127.0.0.1:55500 dest: /127.0.0.1:49989
2011-08-09 19:56:17,098 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-7247974470154199534 of size 0
2011-08-09 19:56:17,099 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-7247974470154199534_1001.meta of size 0
2011-08-09 19:56:17,099 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,100 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,100 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7247974470154199534_1001 src: /127.0.0.1:33673 dest: /127.0.0.1:33808
2011-08-09 19:56:17,101 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-7247974470154199534 of size 0
2011-08-09 19:56:17,101 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-7247974470154199534_1001.meta of size 0
2011-08-09 19:56:17,101 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,101 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,101 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,116 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,116 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,155 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-7247974470154199534_1001 of length 1036 seqno 2 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,156 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 2 to ack queue.
2011-08-09 19:56:17,156 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-7247974470154199534_1001 of length 1036 seqno 2 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,156 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 2 to ack queue.
2011-08-09 19:56:17,156 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-7247974470154199534_1001 of length 1036 seqno 2 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,157 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 2 to ack queue.
2011-08-09 19:56:17,157 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-7247974470154199534_1001 acking for packet 2
2011-08-09 19:56:17,158 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-7247974470154199534_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-7247974470154199534_1001.meta
2011-08-09 19:56:17,158 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-7247974470154199534 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-7247974470154199534
2011-08-09 19:56:17,159 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:33673, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-7247974470154199534_1001, duration: 55759733
2011-08-09 19:56:17,159 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7247974470154199534_1001 terminating
2011-08-09 19:56:17,173 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 2
2011-08-09 19:56:17,174 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 2
2011-08-09 19:56:17,181 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-7247974470154199534_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current/blk_-7247974470154199534_1001.meta
2011-08-09 19:56:17,181 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-7247974470154199534 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current/blk_-7247974470154199534
2011-08-09 19:56:17,182 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:55500, dest: /127.0.0.1:49989, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1407648578-10.0.62.238-49989-1312912576725, blockid: blk_-7247974470154199534_1001, duration: 45931714
2011-08-09 19:56:17,182 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-7247974470154199534_1001 responded my status  for seqno 2
2011-08-09 19:56:17,182 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 2
2011-08-09 19:56:17,182 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 2
2011-08-09 19:56:17,182 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-7247974470154199534_1001 1 responded other status  for seqno 2
2011-08-09 19:56:17,182 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-7247974470154199534_1001 terminating
2011-08-09 19:56:17,187 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-7247974470154199534_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-7247974470154199534_1001.meta
2011-08-09 19:56:17,187 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-7247974470154199534 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-7247974470154199534
2011-08-09 19:56:17,187 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50458, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-7247974470154199534_1001, duration: 51806895
2011-08-09 19:56:17,187 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_-7247974470154199534_1001 size 1024
2011-08-09 19:56:17,187 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-7247974470154199534_1001 responded my status  for seqno 2
2011-08-09 19:56:17,188 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-7247974470154199534_1001 2 responded other status  for seqno 2
2011-08-09 19:56:17,188 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-7247974470154199534_1001 terminating
2011-08-09 19:56:17,189 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-7247974470154199534_1001 Closing down.
2011-08-09 19:56:17,188 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49989 is added to blk_-7247974470154199534_1001 size 1024
2011-08-09 19:56:17,189 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-7247974470154199534_1001 Closing down.
2011-08-09 19:56:17,189 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-7247974470154199534_1001 size 1024
2011-08-09 19:56:17,189 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,190 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-7247974470154199534_1001 Closing down.
2011-08-09 19:56:17,191 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):Number of active connections is: 2
2011-08-09 19:56:17,192 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_1118486569214090774_1001
2011-08-09 19:56:17,192 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,193 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,194 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,194 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_1118486569214090774_1001 src: /127.0.0.1:50461 dest: /127.0.0.1:56616
2011-08-09 19:56:17,195 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_1118486569214090774 of size 0
2011-08-09 19:56:17,195 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_1118486569214090774_1001.meta of size 0
2011-08-09 19:56:17,197 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,199 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,199 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_1118486569214090774_1001 src: /127.0.0.1:54986 dest: /127.0.0.1:48788
2011-08-09 19:56:17,199 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_1118486569214090774 of size 0
2011-08-09 19:56:17,199 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_1118486569214090774_1001.meta of size 0
2011-08-09 19:56:17,200 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,200 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,200 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_1118486569214090774_1001 src: /127.0.0.1:47420 dest: /127.0.0.1:44003
2011-08-09 19:56:17,201 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_1118486569214090774 of size 0
2011-08-09 19:56:17,201 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_1118486569214090774_1001.meta of size 0
2011-08-09 19:56:17,201 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,202 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,202 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,202 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,202 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,246 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_1118486569214090774_1001 of length 1036 seqno 3 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,246 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 3 to ack queue.
2011-08-09 19:56:17,246 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_1118486569214090774_1001 of length 1036 seqno 3 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,246 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 3 to ack queue.
2011-08-09 19:56:17,246 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_1118486569214090774_1001 of length 1036 seqno 3 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,247 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 3 to ack queue.
2011-08-09 19:56:17,247 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_1118486569214090774_1001 acking for packet 3
2011-08-09 19:56:17,248 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_1118486569214090774_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current/blk_1118486569214090774_1001.meta
2011-08-09 19:56:17,248 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_1118486569214090774 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current/blk_1118486569214090774
2011-08-09 19:56:17,249 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44003 is added to blk_1118486569214090774_1001 size 1024
2011-08-09 19:56:17,249 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:47420, dest: /127.0.0.1:44003, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-923530740-10.0.62.238-44003-1312912576184, blockid: blk_1118486569214090774_1001, duration: 45665397
2011-08-09 19:56:17,249 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 3
2011-08-09 19:56:17,249 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_1118486569214090774_1001 terminating
2011-08-09 19:56:17,249 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 3
2011-08-09 19:56:17,251 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_1118486569214090774_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current/blk_1118486569214090774_1001.meta
2011-08-09 19:56:17,251 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_1118486569214090774 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current/blk_1118486569214090774
2011-08-09 19:56:17,252 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:54986, dest: /127.0.0.1:48788, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-574479426-10.0.62.238-48788-1312912574624, blockid: blk_1118486569214090774_1001, duration: 48344216
2011-08-09 19:56:17,252 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 3
2011-08-09 19:56:17,252 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48788 is added to blk_1118486569214090774_1001 size 1024
2011-08-09 19:56:17,252 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 3
2011-08-09 19:56:17,253 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_1118486569214090774_1001 responded my status  for seqno 3
2011-08-09 19:56:17,253 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_1118486569214090774_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_1118486569214090774_1001.meta
2011-08-09 19:56:17,253 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_1118486569214090774 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_1118486569214090774
2011-08-09 19:56:17,253 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_1118486569214090774_1001 1 responded other status  for seqno 3
2011-08-09 19:56:17,253 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_1118486569214090774_1001 terminating
2011-08-09 19:56:17,254 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_1118486569214090774_1001 size 1024
2011-08-09 19:56:17,254 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50461, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_1118486569214090774_1001, duration: 49750694
2011-08-09 19:56:17,255 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_1118486569214090774_1001 Closing down.
2011-08-09 19:56:17,255 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_1118486569214090774_1001 Closing down.
2011-08-09 19:56:17,255 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_1118486569214090774_1001 responded my status  for seqno 3
2011-08-09 19:56:17,260 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_1118486569214090774_1001 Closing down.
2011-08-09 19:56:17,260 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Number of active connections is: 2
2011-08-09 19:56:17,261 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Number of active connections is: 2
2011-08-09 19:56:17,262 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_1118486569214090774_1001 2 responded other status  for seqno 3
2011-08-09 19:56:17,262 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_1118486569214090774_1001 terminating
2011-08-09 19:56:17,262 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,263 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-4891787451115894708_1001
2011-08-09 19:56:17,264 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,266 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,266 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4891787451115894708_1001 src: /127.0.0.1:50464 dest: /127.0.0.1:56616
2011-08-09 19:56:17,266 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4891787451115894708 of size 0
2011-08-09 19:56:17,267 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4891787451115894708_1001.meta of size 0
2011-08-09 19:56:17,267 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,268 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,268 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4891787451115894708_1001 src: /127.0.0.1:47422 dest: /127.0.0.1:44003
2011-08-09 19:56:17,268 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4891787451115894708 of size 0
2011-08-09 19:56:17,268 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4891787451115894708_1001.meta of size 0
2011-08-09 19:56:17,269 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,269 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,269 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4891787451115894708_1001 src: /127.0.0.1:55507 dest: /127.0.0.1:49989
2011-08-09 19:56:17,270 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4891787451115894708 of size 0
2011-08-09 19:56:17,270 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4891787451115894708_1001.meta of size 0
2011-08-09 19:56:17,271 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,271 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,271 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,271 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,271 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,273 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4891787451115894708_1001 of length 1036 seqno 4 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,273 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 4 to ack queue.
2011-08-09 19:56:17,274 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4891787451115894708_1001 of length 1036 seqno 4 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,274 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 4 to ack queue.
2011-08-09 19:56:17,274 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4891787451115894708_1001 of length 1036 seqno 4 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,275 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 4 to ack queue.
2011-08-09 19:56:17,275 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-4891787451115894708_1001 acking for packet 4
2011-08-09 19:56:17,276 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4891787451115894708_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current/blk_-4891787451115894708_1001.meta
2011-08-09 19:56:17,276 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4891787451115894708 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current/blk_-4891787451115894708
2011-08-09 19:56:17,276 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:55507, dest: /127.0.0.1:49989, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1407648578-10.0.62.238-49989-1312912576725, blockid: blk_-4891787451115894708_1001, duration: 4081385
2011-08-09 19:56:17,277 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4891787451115894708_1001 terminating
2011-08-09 19:56:17,278 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 4
2011-08-09 19:56:17,278 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 4
2011-08-09 19:56:17,278 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49989 is added to blk_-4891787451115894708_1001 size 1024
2011-08-09 19:56:17,279 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4891787451115894708_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current/blk_-4891787451115894708_1001.meta
2011-08-09 19:56:17,279 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/tmp/blk_-4891787451115894708 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current/blk_-4891787451115894708
2011-08-09 19:56:17,279 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:47422, dest: /127.0.0.1:44003, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-923530740-10.0.62.238-44003-1312912576184, blockid: blk_-4891787451115894708_1001, duration: 6761880
2011-08-09 19:56:17,280 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-4891787451115894708_1001 responded my status  for seqno 4
2011-08-09 19:56:17,280 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 4
2011-08-09 19:56:17,280 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4891787451115894708_1001 1 responded other status  for seqno 4
2011-08-09 19:56:17,280 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-4891787451115894708_1001 terminating
2011-08-09 19:56:17,280 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 4
2011-08-09 19:56:17,281 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44003 is added to blk_-4891787451115894708_1001 size 1024
2011-08-09 19:56:17,282 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4891787451115894708_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4891787451115894708_1001.meta
2011-08-09 19:56:17,282 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4891787451115894708 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4891787451115894708
2011-08-09 19:56:17,283 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-4891787451115894708_1001 size 1024
2011-08-09 19:56:17,283 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50464, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-4891787451115894708_1001, duration: 8878723
2011-08-09 19:56:17,283 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-4891787451115894708_1001 responded my status  for seqno 4
2011-08-09 19:56:17,284 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4891787451115894708_1001 2 responded other status  for seqno 4
2011-08-09 19:56:17,286 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-4891787451115894708_1001 terminating
2011-08-09 19:56:17,287 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-4891787451115894708_1001 Closing down.
2011-08-09 19:56:17,288 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,288 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-4891787451115894708_1001 Closing down.
2011-08-09 19:56:17,288 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_149483588303812173_1001
2011-08-09 19:56:17,288 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Number of active connections is: 2
2011-08-09 19:56:17,288 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-4891787451115894708_1001 Closing down.
2011-08-09 19:56:17,289 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,290 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):Number of active connections is: 2
2011-08-09 19:56:17,291 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,291 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_149483588303812173_1001 src: /127.0.0.1:50467 dest: /127.0.0.1:56616
2011-08-09 19:56:17,292 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_149483588303812173 of size 0
2011-08-09 19:56:17,292 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_149483588303812173_1001.meta of size 0
2011-08-09 19:56:17,292 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,292 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,293 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_149483588303812173_1001 src: /127.0.0.1:54992 dest: /127.0.0.1:48788
2011-08-09 19:56:17,293 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_149483588303812173 of size 0
2011-08-09 19:56:17,293 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_149483588303812173_1001.meta of size 0
2011-08-09 19:56:17,294 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,294 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,294 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_149483588303812173_1001 src: /127.0.0.1:33682 dest: /127.0.0.1:33808
2011-08-09 19:56:17,295 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_149483588303812173 of size 0
2011-08-09 19:56:17,295 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_149483588303812173_1001.meta of size 0
2011-08-09 19:56:17,295 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,295 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,295 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,295 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,296 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,297 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_149483588303812173_1001 of length 1036 seqno 5 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,297 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 5 to ack queue.
2011-08-09 19:56:17,297 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_149483588303812173_1001 of length 1036 seqno 5 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,297 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 5 to ack queue.
2011-08-09 19:56:17,297 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_149483588303812173_1001 of length 1036 seqno 5 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,298 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 5 to ack queue.
2011-08-09 19:56:17,298 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_149483588303812173_1001 acking for packet 5
2011-08-09 19:56:17,298 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_149483588303812173_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_149483588303812173_1001.meta
2011-08-09 19:56:17,299 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_149483588303812173 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_149483588303812173
2011-08-09 19:56:17,299 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:33682, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_149483588303812173_1001, duration: 2361362
2011-08-09 19:56:17,299 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_149483588303812173_1001 terminating
2011-08-09 19:56:17,300 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 5
2011-08-09 19:56:17,300 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 5
2011-08-09 19:56:17,301 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_149483588303812173_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_149483588303812173_1001.meta
2011-08-09 19:56:17,301 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_149483588303812173 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_149483588303812173
2011-08-09 19:56:17,301 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_149483588303812173_1001 size 1024
2011-08-09 19:56:17,301 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:54992, dest: /127.0.0.1:48788, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-574479426-10.0.62.238-48788-1312912574624, blockid: blk_149483588303812173_1001, duration: 4256321
2011-08-09 19:56:17,302 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_149483588303812173_1001 responded my status  for seqno 5
2011-08-09 19:56:17,302 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_149483588303812173_1001 1 responded other status  for seqno 5
2011-08-09 19:56:17,302 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_149483588303812173_1001 terminating
2011-08-09 19:56:17,302 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 5
2011-08-09 19:56:17,302 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 5
2011-08-09 19:56:17,302 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48788 is added to blk_149483588303812173_1001 size 1024
2011-08-09 19:56:17,304 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_149483588303812173_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_149483588303812173_1001.meta
2011-08-09 19:56:17,305 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_149483588303812173 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_149483588303812173
2011-08-09 19:56:17,305 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50467, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_149483588303812173_1001, duration: 7919926
2011-08-09 19:56:17,305 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_149483588303812173_1001 responded my status  for seqno 5
2011-08-09 19:56:17,306 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_149483588303812173_1001 2 responded other status  for seqno 5
2011-08-09 19:56:17,306 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_149483588303812173_1001 terminating
2011-08-09 19:56:17,308 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_149483588303812173_1001 size 1024
2011-08-09 19:56:17,309 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_149483588303812173_1001 Closing down.
2011-08-09 19:56:17,309 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,309 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-2352619832800241837_1001
2011-08-09 19:56:17,309 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_149483588303812173_1001 Closing down.
2011-08-09 19:56:17,310 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,310 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_149483588303812173_1001 Closing down.
2011-08-09 19:56:17,311 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,312 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Number of active connections is: 2
2011-08-09 19:56:17,312 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,312 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2352619832800241837_1001 src: /127.0.0.1:50470 dest: /127.0.0.1:56616
2011-08-09 19:56:17,313 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-2352619832800241837 of size 0
2011-08-09 19:56:17,313 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-2352619832800241837_1001.meta of size 0
2011-08-09 19:56:17,314 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,314 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,314 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2352619832800241837_1001 src: /127.0.0.1:33684 dest: /127.0.0.1:33808
2011-08-09 19:56:17,315 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-2352619832800241837 of size 0
2011-08-09 19:56:17,315 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-2352619832800241837_1001.meta of size 0
2011-08-09 19:56:17,315 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,316 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,316 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2352619832800241837_1001 src: /127.0.0.1:54996 dest: /127.0.0.1:48788
2011-08-09 19:56:17,316 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_-2352619832800241837 of size 0
2011-08-09 19:56:17,316 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_-2352619832800241837_1001.meta of size 0
2011-08-09 19:56:17,317 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,317 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,317 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,317 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,317 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,319 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-2352619832800241837_1001 of length 1036 seqno 6 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,319 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 6 to ack queue.
2011-08-09 19:56:17,320 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-2352619832800241837_1001 of length 1036 seqno 6 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,320 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 6 to ack queue.
2011-08-09 19:56:17,320 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-2352619832800241837_1001 of length 1036 seqno 6 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,320 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 6 to ack queue.
2011-08-09 19:56:17,321 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-2352619832800241837_1001 acking for packet 6
2011-08-09 19:56:17,322 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_-2352619832800241837_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current/blk_-2352619832800241837_1001.meta
2011-08-09 19:56:17,322 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/tmp/blk_-2352619832800241837 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current/blk_-2352619832800241837
2011-08-09 19:56:17,323 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:54996, dest: /127.0.0.1:48788, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-574479426-10.0.62.238-48788-1312912574624, blockid: blk_-2352619832800241837_1001, duration: 5263183
2011-08-09 19:56:17,323 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48788 is added to blk_-2352619832800241837_1001 size 1024
2011-08-09 19:56:17,324 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 6
2011-08-09 19:56:17,324 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 6
2011-08-09 19:56:17,325 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-2352619832800241837_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-2352619832800241837_1001.meta
2011-08-09 19:56:17,325 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_-2352619832800241837 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_-2352619832800241837
2011-08-09 19:56:17,325 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:33684, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-2352619832800241837_1001, duration: 6842921
2011-08-09 19:56:17,326 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_-2352619832800241837_1001 size 1024
2011-08-09 19:56:17,326 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-2352619832800241837_1001 responded my status  for seqno 6
2011-08-09 19:56:17,326 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 6
2011-08-09 19:56:17,326 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-2352619832800241837_1001 terminating
2011-08-09 19:56:17,326 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 6
2011-08-09 19:56:17,328 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-2352619832800241837_1001 1 responded other status  for seqno 6
2011-08-09 19:56:17,328 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-2352619832800241837_1001 terminating
2011-08-09 19:56:17,329 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-2352619832800241837_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-2352619832800241837_1001.meta
2011-08-09 19:56:17,329 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-2352619832800241837 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-2352619832800241837
2011-08-09 19:56:17,333 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-2352619832800241837_1001 size 1024
2011-08-09 19:56:17,333 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50470, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-2352619832800241837_1001, duration: 10306998
2011-08-09 19:56:17,334 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-2352619832800241837_1001 Closing down.
2011-08-09 19:56:17,334 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-2352619832800241837_1001 Closing down.
2011-08-09 19:56:17,334 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-2352619832800241837_1001 Closing down.
2011-08-09 19:56:17,334 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,335 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Number of active connections is: 2
2011-08-09 19:56:17,335 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-2352619832800241837_1001 responded my status  for seqno 6
2011-08-09 19:56:17,340 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-2352619832800241837_1001 2 responded other status  for seqno 6
2011-08-09 19:56:17,342 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-6635419261993486984_1001
2011-08-09 19:56:17,343 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-2352619832800241837_1001 terminating
2011-08-09 19:56:17,343 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:56:17,343 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 3
2011-08-09 19:56:17,345 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,345 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6635419261993486984_1001 src: /127.0.0.1:50473 dest: /127.0.0.1:56616
2011-08-09 19:56:17,345 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_-6635419261993486984 of size 0
2011-08-09 19:56:17,345 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_-6635419261993486984_1001.meta of size 0
2011-08-09 19:56:17,346 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,346 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,346 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6635419261993486984_1001 src: /127.0.0.1:47431 dest: /127.0.0.1:44003
2011-08-09 19:56:17,347 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_-6635419261993486984 of size 0
2011-08-09 19:56:17,347 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_-6635419261993486984_1001.meta of size 0
2011-08-09 19:56:17,347 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,348 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,348 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-6635419261993486984_1001 src: /127.0.0.1:55516 dest: /127.0.0.1:49989
2011-08-09 19:56:17,348 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-6635419261993486984 of size 0
2011-08-09 19:56:17,349 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-6635419261993486984_1001.meta of size 0
2011-08-09 19:56:17,349 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,349 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,349 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,349 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,349 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,350 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-6635419261993486984_1001 of length 1036 seqno 7 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,351 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 7 to ack queue.
2011-08-09 19:56:17,359 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-6635419261993486984_1001 of length 1036 seqno 7 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,359 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 7 to ack queue.
2011-08-09 19:56:17,360 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-6635419261993486984_1001 of length 1036 seqno 7 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,360 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 7 to ack queue.
2011-08-09 19:56:17,360 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-6635419261993486984_1001 acking for packet 7
2011-08-09 19:56:17,361 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-6635419261993486984_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current/blk_-6635419261993486984_1001.meta
2011-08-09 19:56:17,361 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/tmp/blk_-6635419261993486984 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current/blk_-6635419261993486984
2011-08-09 19:56:17,361 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:55516, dest: /127.0.0.1:49989, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1407648578-10.0.62.238-49989-1312912576725, blockid: blk_-6635419261993486984_1001, duration: 9767657
2011-08-09 19:56:17,362 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-6635419261993486984_1001 terminating
2011-08-09 19:56:17,362 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 7
2011-08-09 19:56:17,362 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 7
2011-08-09 19:56:17,364 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_-6635419261993486984_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current/blk_-6635419261993486984_1001.meta
2011-08-09 19:56:17,364 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49989 is added to blk_-6635419261993486984_1001 size 1024
2011-08-09 19:56:17,365 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/tmp/blk_-6635419261993486984 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current/blk_-6635419261993486984
2011-08-09 19:56:17,365 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:47431, dest: /127.0.0.1:44003, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-923530740-10.0.62.238-44003-1312912576184, blockid: blk_-6635419261993486984_1001, duration: 4661804
2011-08-09 19:56:17,365 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:44003 is added to blk_-6635419261993486984_1001 size 1024
2011-08-09 19:56:17,366 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-6635419261993486984_1001 responded my status  for seqno 7
2011-08-09 19:56:17,366 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-6635419261993486984_1001 1 responded other status  for seqno 7
2011-08-09 19:56:17,366 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-6635419261993486984_1001 terminating
2011-08-09 19:56:17,366 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 7
2011-08-09 19:56:17,367 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 7
2011-08-09 19:56:17,367 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_-6635419261993486984_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_-6635419261993486984_1001.meta
2011-08-09 19:56:17,367 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_-6635419261993486984 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_-6635419261993486984
2011-08-09 19:56:17,368 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50473, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-6635419261993486984_1001, duration: 8184287
2011-08-09 19:56:17,368 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-6635419261993486984_1001 responded my status  for seqno 7
2011-08-09 19:56:17,368 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-6635419261993486984_1001 Closing down.
2011-08-09 19:56:17,368 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-6635419261993486984_1001 2 responded other status  for seqno 7
2011-08-09 19:56:17,368 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-6635419261993486984_1001 terminating
2011-08-09 19:56:17,369 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-6635419261993486984_1001 size 1024
2011-08-09 19:56:17,370 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_-4328182094134921138_1001
2011-08-09 19:56:17,371 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,372 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,372 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-6635419261993486984_1001 Closing down.
2011-08-09 19:56:17,372 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,372 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Number of active connections is: 2
2011-08-09 19:56:17,372 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4328182094134921138_1001 src: /127.0.0.1:50476 dest: /127.0.0.1:56616
2011-08-09 19:56:17,373 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-6635419261993486984_1001 Closing down.
2011-08-09 19:56:17,373 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):Number of active connections is: 2
2011-08-09 19:56:17,373 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4328182094134921138 of size 0
2011-08-09 19:56:17,373 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4328182094134921138_1001.meta of size 0
2011-08-09 19:56:17,374 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,374 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,374 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4328182094134921138_1001 src: /127.0.0.1:55518 dest: /127.0.0.1:49989
2011-08-09 19:56:17,375 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4328182094134921138 of size 0
2011-08-09 19:56:17,375 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4328182094134921138_1001.meta of size 0
2011-08-09 19:56:17,375 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,376 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,376 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-4328182094134921138_1001 src: /127.0.0.1:33691 dest: /127.0.0.1:33808
2011-08-09 19:56:17,376 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_-4328182094134921138 of size 0
2011-08-09 19:56:17,377 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_-4328182094134921138_1001.meta of size 0
2011-08-09 19:56:17,377 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,377 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,377 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,377 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,377 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,378 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4328182094134921138_1001 of length 1036 seqno 8 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,379 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4328182094134921138_1001 of length 1036 seqno 8 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,379 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 8 to ack queue.
2011-08-09 19:56:17,379 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_-4328182094134921138_1001 of length 1036 seqno 8 offsetInBlock 0 lastPacketInBlock true
2011-08-09 19:56:17,379 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 8 to ack queue.
2011-08-09 19:56:17,379 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 8 to ack queue.
2011-08-09 19:56:17,380 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_-4328182094134921138_1001 acking for packet 8
2011-08-09 19:56:17,380 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_-4328182094134921138_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_-4328182094134921138_1001.meta
2011-08-09 19:56:17,381 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/tmp/blk_-4328182094134921138 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current/blk_-4328182094134921138
2011-08-09 19:56:17,381 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:33691, dest: /127.0.0.1:33808, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-4328182094134921138_1001, duration: 2859624
2011-08-09 19:56:17,381 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-4328182094134921138_1001 terminating
2011-08-09 19:56:17,382 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33808 is added to blk_-4328182094134921138_1001 size 1024
2011-08-09 19:56:17,382 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 8
2011-08-09 19:56:17,382 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 8
2011-08-09 19:56:17,383 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4328182094134921138_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current/blk_-4328182094134921138_1001.meta
2011-08-09 19:56:17,383 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/tmp/blk_-4328182094134921138 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current/blk_-4328182094134921138
2011-08-09 19:56:17,384 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:49989 is added to blk_-4328182094134921138_1001 size 1024
2011-08-09 19:56:17,384 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:55518, dest: /127.0.0.1:49989, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1407648578-10.0.62.238-49989-1312912576725, blockid: blk_-4328182094134921138_1001, duration: 5201983
2011-08-09 19:56:17,385 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_-4328182094134921138_1001 responded my status  for seqno 8
2011-08-09 19:56:17,385 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 8
2011-08-09 19:56:17,385 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4328182094134921138_1001 1 responded other status  for seqno 8
2011-08-09 19:56:17,385 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 8
2011-08-09 19:56:17,385 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-4328182094134921138_1001 terminating
2011-08-09 19:56:17,386 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4328182094134921138_1001.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4328182094134921138_1001.meta
2011-08-09 19:56:17,386 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/tmp/blk_-4328182094134921138 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current/blk_-4328182094134921138
2011-08-09 19:56:17,386 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:50476, dest: /127.0.0.1:56616, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-4328182094134921138_1001, duration: 7426136
2011-08-09 19:56:17,387 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_-4328182094134921138_1001 responded my status  for seqno 8
2011-08-09 19:56:17,387 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_-4328182094134921138_1001 2 responded other status  for seqno 8
2011-08-09 19:56:17,411 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_-4328182094134921138_1001 terminating
2011-08-09 19:56:17,411 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:56616 is added to blk_-4328182094134921138_1001 size 1024
2011-08-09 19:56:17,412 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /foo875571745. blk_5318931119202285481_1001
2011-08-09 19:56:17,412 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 1 for block blk_-4328182094134921138_1001 Closing down.
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 0 for block blk_-4328182094134921138_1001 Closing down.
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):Number of active connections is: 2
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (BlockReceiver.java:close(754)) - PacketResponder 2 for block blk_-4328182094134921138_1001 Closing down.
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:56:17,413 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:56:17,414 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,414 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5318931119202285481_1001 src: /127.0.0.1:50479 dest: /127.0.0.1:56616
2011-08-09 19:56:17,415 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_5318931119202285481 of size 0
2011-08-09 19:56:17,415 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_5318931119202285481_1001.meta of size 0
2011-08-09 19:56:17,415 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,415 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,416 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5318931119202285481_1001 src: /127.0.0.1:55004 dest: /127.0.0.1:48788
2011-08-09 19:56:17,416 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_5318931119202285481 of size 0
2011-08-09 19:56:17,416 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_5318931119202285481_1001.meta of size 0
2011-08-09 19:56:17,417 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:56:17,417 DEBUG datanode.DataNode (DataXceiver.java:writeBlock(247)) - writeBlock receive buf size 131071 tcp no delay true
2011-08-09 19:56:17,417 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5318931119202285481_1001 src: /127.0.0.1:33694 dest: /127.0.0.1:33808
2011-08-09 19:56:17,418 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1223)) - writeTo blockfile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_5318931119202285481 of size 0
2011-08-09 19:56:17,418 DEBUG datanode.DataNode (FSDataset.java:writeToBlock(1224)) - writeTo metafile is /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_5318931119202285481_1001.meta of size 0
2011-08-09 19:56:17,418 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 0 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,418 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 1 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,418 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 1 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,419 INFO  datanode.DataNode (DataXceiver.java:writeBlock(343)) - Datanode 2 got response for connect ack  from downstream datanode with firstbadlink as 
2011-08-09 19:56:17,419 INFO  datanode.DataNode (DataXceiver.java:writeBlock(375)) - Datanode 2 forwarding connect ack to upstream firstbadlink is 
2011-08-09 19:56:17,420 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_5318931119202285481_1001 of length 124 seqno 9 offsetInBlock 0 lastPacketInBlock false
2011-08-09 19:56:17,420 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_5318931119202285481_1001 of length 124 seqno 9 offsetInBlock 0 lastPacketInBlock false
2011-08-09 19:56:17,420 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 2 adding seqno 9 to ack queue.
2011-08-09 19:56:17,420 DEBUG datanode.DataNode (BlockReceiver.java:receivePacket(402)) - Receiving one packet for block blk_5318931119202285481_1001 of length 124 seqno 9 offsetInBlock 0 lastPacketInBlock false
2011-08-09 19:56:17,420 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 0 adding seqno 9 to ack queue.
2011-08-09 19:56:17,421 DEBUG datanode.DataNode (BlockReceiver.java:lastDataNodeRun(802)) - PacketResponder 0 for block blk_5318931119202285481_1001 acking for packet 9
2011-08-09 19:56:17,421 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 1 got seqno = 9
2011-08-09 19:56:17,421 DEBUG datanode.DataNode (BlockReceiver.java:run(893)) - PacketResponder 1 seqno = 9 for block blk_5318931119202285481_1001 waiting for local datanode to finish write.
2011-08-09 19:56:17,421 DEBUG datanode.DataNode (BlockReceiver.java:enqueue(736)) - PacketResponder 1 adding seqno 9 to ack queue.
2011-08-09 19:56:17,421 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 1 seqno = 9
2011-08-09 19:56:17,422 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 1 for block blk_5318931119202285481_1001 responded my status  for seqno 9
2011-08-09 19:56:17,422 DEBUG datanode.DataNode (BlockReceiver.java:run(887)) - PacketResponder 2 got seqno = 9
2011-08-09 19:56:17,422 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_5318931119202285481_1001 1 responded other status  for seqno 9
2011-08-09 19:56:17,422 DEBUG datanode.DataNode (BlockReceiver.java:run(903)) - PacketResponder 2 seqno = 9
2011-08-09 19:56:17,422 DEBUG datanode.DataNode (BlockReceiver.java:run(968)) - PacketResponder 2 for block blk_5318931119202285481_1001 responded my status  for seqno 9
2011-08-09 19:56:17,423 DEBUG datanode.DataNode (BlockReceiver.java:run(990)) - PacketResponder blk_5318931119202285481_1001 2 responded other status  for seqno 9
2011-08-09 19:56:17,423 INFO  hdfs.StateChange (FSNamesystem.java:fsync(2430)) - BLOCK* NameSystem.fsync: file /foo875571745 for DFSClient_19585158
2011-08-09 19:56:17,424 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 10, -68, -104, -89, -42, 46, -98, 20, -3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 37, 36, 74, -31, -90, 8, -19, -85, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -101, 106, 5, -98, -19, 91, -34, 18, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 15, -123, -87, -101, -44, 13, 30, 22, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -68, 28, -31, 59, 35, -122, 8, 76, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 2, 19, 18, -120, 20, -103, 118, 77, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -33, 89, -48, -70, 14, 103, 23, 83, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -93, -22, 65, 86, 81, 23, -11, 120, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -61, -17, 53, 81, 43, -31, -72, 78, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 73, -48, -93, -84, 8, -46, -73, -87, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 57, 53, 56, 53, 49, 53, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:56:17,424 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [0, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 10, -68, -104, -89, -42, 46, -98, 20, -3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 37, 36, 74, -31, -90, 8, -19, -85, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -101, 106, 5, -98, -19, 91, -34, 18, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 15, -123, -87, -101, -44, 13, 30, 22, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -68, 28, -31, 59, 35, -122, 8, 76, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 2, 19, 18, -120, 20, -103, 118, 77, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -33, 89, -48, -70, 14, 103, 23, 83, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -93, -22, 65, 86, 81, 23, -11, 120, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -61, -17, 53, 81, 43, -31, -72, 78, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 73, -48, -93, -84, 8, -46, -73, -87, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, -23, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92, 0, 18, 68, 70, 83, 67, 108, 105, 101, 110, 116, 95, 49, 57, 53, 56, 53, 49, 53, 56, 0, 9, 49, 50, 55, 46, 48, 46, 48, 46, 49]
2011-08-09 19:56:17,424 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 357
2011-08-09 19:56:17,430 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 357
2011-08-09 19:56:17,432 INFO  hdfs.AppendTestUtil (TestLeaseRecovery2.java:testBlockSynchronization(83)) - leasechecker.interruptAndJoin()
2011-08-09 19:56:17,435 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:56:17,441 INFO  hdfs.AppendTestUtil (TestLeaseRecovery2.java:testBlockSynchronization(102)) - i=0
2011-08-09 19:56:17,443 WARN  hdfs.StateChange (FSNamesystem.java:startFileInternal(1590)) - DIR* NameSystem.startFile: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
2011-08-09 19:56:17,444 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 57846, call create(/foo875571745, rwxr-xr-x, DFSClient_1579240028, false, 3, 1024) from 127.0.0.1:59147: error: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1517)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:56:48,419 DEBUG datanode.DataNode (BlockReceiver.java:run(882)) - PacketResponder 1 got -1
2011-08-09 19:56:48,419 DEBUG datanode.DataNode (BlockReceiver.java:run(882)) - PacketResponder 2 got -1
2011-08-09 19:57:07,757 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_-4856947659772128003_1001
2011-08-09 19:57:18,949 INFO  namenode.FSNamesystem (FSNamesystem.java:startFileInternal(1514)) - startFile: recover lease [Lease.  Holder: DFSClient_19585158, pendingcreates: 1], src=/foo875571745
2011-08-09 19:57:18,950 INFO  namenode.FSNamesystem (FSNamesystem.java:internalReleaseLease(2452)) - Recovering lease=[Lease.  Holder: DFSClient_19585158, pendingcreates: 1], src=/foo875571745
2011-08-09 19:57:18,951 INFO  hdfs.StateChange (INodeFileUnderConstruction.java:assignPrimaryDatanode(163)) - BLOCK* blk_5318931119202285481_1001 recovery started, primary=127.0.0.1:56616
2011-08-09 19:57:18,951 WARN  hdfs.StateChange (FSNamesystem.java:startFileInternal(1590)) - DIR* NameSystem.startFile: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
2011-08-09 19:57:18,951 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 57846, call create(/foo875571745, rwxr-xr-x, DFSClient_1579240028, false, 3, 1024) from 127.0.0.1:59148: error: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /foo875571745 for DFSClient_1579240028 on client 127.0.0.1, because this file is already being created by DFSClient_19585158 on 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1517)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:19,438 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - NameNode calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:19,438 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:19,438 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:19,440 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1001 length 116 genstamp 1001
2011-08-09 19:57:19,441 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091))
2011-08-09 19:57:19,447 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:19,447 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1001 length 116 genstamp 1001
2011-08-09 19:57:19,452 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:33808 (dnReg=DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091))
2011-08-09 19:57:19,456 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:19,457 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1001 length 116 genstamp 1001
2011-08-09 19:57:19,458 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1001 node:127.0.0.1:56616, block:blk_5318931119202285481_1001 node:127.0.0.1:48788, block:blk_5318931119202285481_1001 node:127.0.0.1:33808], closeFile=true
2011-08-09 19:57:19,459 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:57:19,460 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [10, 0, 0, 0, 0, 0, 0, 3, -22]
2011-08-09 19:57:19,460 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5318931119202285481_1001(length=116), newblock=blk_5318931119202285481_1002(length=116), datanode=127.0.0.1:56616
2011-08-09 19:57:19,461 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5318931119202285481_1001 java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:56616 remote=/127.0.0.1:50479]. 0 millis timeout left.
2011-08-09 19:57:19,461 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5318931119202285481_1001 received exception java.io.IOException: Interrupted receiveBlock
2011-08-09 19:57:19,461 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):DataXceiver
java.io.IOException: Interrupted receiveBlock
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:582)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:57:19,462 WARN  hdfs.DFSClient (DFSClient.java:run(3117)) - DFSOutputStream ResponseProcessor exception  for block blk_5318931119202285481_1001java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$ResponseProcessor.run(DFSClient.java:3071)

2011-08-09 19:57:19,462 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 6
2011-08-09 19:57:19,463 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_5318931119202285481_1001 2 Exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 88957 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:57:19,463 INFO  datanode.DataNode (BlockReceiver.java:run(930)) - PacketResponder blk_5318931119202285481_1001 2 : Thread is interrupted.
2011-08-09 19:57:19,463 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 2 for block blk_5318931119202285481_1001 terminating
2011-08-09 19:57:19,462 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:19,474 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:19,463 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5318931119202285481_1001 java.io.EOFException: while trying to read 145 bytes
2011-08-09 19:57:19,502 INFO  datanode.DataNode (BlockReceiver.java:run(915)) - PacketResponder blk_5318931119202285481_1001 1 Exception java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:33694 remote=/127.0.0.1:33808]. 28918 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:877)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:57:19,503 INFO  datanode.DataNode (BlockReceiver.java:run(930)) - PacketResponder blk_5318931119202285481_1001 1 : Thread is interrupted.
2011-08-09 19:57:19,503 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5318931119202285481_1001 terminating
2011-08-09 19:57:19,503 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5318931119202285481_1001 received exception java.io.EOFException: while trying to read 145 bytes
2011-08-09 19:57:19,505 INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(569)) - Exception in receiveBlock for block blk_5318931119202285481_1001 java.io.EOFException: while trying to read 145 bytes
2011-08-09 19:57:19,506 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(780)) - PacketResponder 0 for block blk_5318931119202285481_1001 Interrupted.
2011-08-09 19:57:19,506 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5318931119202285481_1001 terminating
2011-08-09 19:57:19,506 INFO  datanode.DataNode (DataXceiver.java:writeBlock(404)) - writeBlock blk_5318931119202285481_1001 received exception java.io.EOFException: while trying to read 145 bytes
2011-08-09 19:57:19,506 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):DataXceiver
java.io.EOFException: while trying to read 145 bytes
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:277)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:57:19,506 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:57:19,506 ERROR datanode.DataNode (DataXceiver.java:run(154)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):DataXceiver
java.io.EOFException: while trying to read 145 bytes
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:277)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:321)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:537)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:385)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:120)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:57:19,507 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Number of active connections is: 2
2011-08-09 19:57:19,508 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:19,508 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:19,511 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:19,512 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1001 length 116 genstamp 1001
2011-08-09 19:57:19,513 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:19,513 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:19,513 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1001 length 116 genstamp 1001
2011-08-09 19:57:19,513 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1001 node:127.0.0.1:48788, block:blk_5318931119202285481_1001 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:19,514 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6049)) - blk_5318931119202285481_1001 is beening recovered, ignoring this request.
2011-08-09 19:57:19,514 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is beening recovered, ignoring this request.
java.io.IOException: blk_5318931119202285481_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:19,515 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@61e58565) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is beening recovered, ignoring this request.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6050)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:19,466 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_5318931119202285481_1002.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_5318931119202285481_1002.meta
2011-08-09 19:57:19,521 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/tmp/blk_5318931119202285481 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current/blk_5318931119202285481
2011-08-09 19:57:19,522 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5318931119202285481_1002 of size 116 as part of lease recovery.
2011-08-09 19:57:19,522 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 1 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Will retry...
2011-08-09 19:57:19,523 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5318931119202285481_1002 on 127.0.0.1:56616 size 116 But it does not belong to any file.
2011-08-09 19:57:19,524 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5318931119202285481_1001(length=116), newblock=blk_5318931119202285481_1002(length=116), datanode=127.0.0.1:48788
2011-08-09 19:57:19,524 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_5318931119202285481_1002.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_5318931119202285481_1002.meta
2011-08-09 19:57:19,524 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/tmp/blk_5318931119202285481 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current/blk_5318931119202285481
2011-08-09 19:57:19,525 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5318931119202285481_1002 of size 116 as part of lease recovery.
2011-08-09 19:57:19,526 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5318931119202285481_1002 on 127.0.0.1:48788 size 116 But it does not belong to any file.
2011-08-09 19:57:19,537 INFO  datanode.DataNode (DataNode.java:updateBlock(1519)) - oldblock=blk_5318931119202285481_1001(length=116), newblock=blk_5318931119202285481_1002(length=116), datanode=127.0.0.1:33808
2011-08-09 19:57:19,538 DEBUG datanode.DataNode (FSDataset.java:addBlock(131)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_5318931119202285481_1002.meta to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_5318931119202285481_1002.meta
2011-08-09 19:57:19,538 DEBUG datanode.DataNode (FSDataset.java:addBlock(132)) - addBlock: Moved /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/tmp/blk_5318931119202285481 to /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current/blk_5318931119202285481
2011-08-09 19:57:19,538 INFO  datanode.DataNode (DataNode.java:updateBlock(1527)) - Received block blk_5318931119202285481_1002 of size 116 as part of lease recovery.
2011-08-09 19:57:19,539 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3784)) - BLOCK* NameSystem.addStoredBlock: addStoredBlock request received for blk_5318931119202285481_1002 on 127.0.0.1:33808 size 116 But it does not belong to any file.
2011-08-09 19:57:19,541 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2544)) - commitBlockSynchronization(lastblock=blk_5318931119202285481_1001, newgenerationstamp=1002, newlength=116, newtargets=[127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808], closeFile=true, deleteBlock=false)
2011-08-09 19:57:19,541 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 54, 51, 57, 53, 52, 49, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 10, -68, -104, -89, -42, 46, -98, 20, -3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 37, 36, 74, -31, -90, 8, -19, -85, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -101, 106, 5, -98, -19, 91, -34, 18, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 15, -123, -87, -101, -44, 13, 30, 22, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -68, 28, -31, 59, 35, -122, 8, 76, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 2, 19, 18, -120, 20, -103, 118, 77, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -33, 89, -48, -70, 14, 103, 23, 83, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -93, -22, 65, 86, 81, 23, -11, 120, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -61, -17, 53, 81, 43, -31, -72, 78, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 73, -48, -93, -84, 8, -46, -73, -87, 0, 0, 0, 0, 0, 0, 0, 116, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:57:19,542 DEBUG namenode.FSNamesystem (FSEditLog.java:write(200)) - Transaction written: [9, 0, 0, 0, 5, 0, 13, 47, 102, 111, 111, 56, 55, 53, 53, 55, 49, 55, 52, 53, 0, 1, 51, 0, 13, 49, 51, 49, 50, 57, 49, 50, 54, 51, 57, 53, 52, 49, 0, 13, 49, 51, 49, 50, 57, 49, 50, 53, 55, 54, 56, 49, 56, 0, 4, 49, 48, 50, 52, 0, 0, 0, 10, -68, -104, -89, -42, 46, -98, 20, -3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 37, 36, 74, -31, -90, 8, -19, -85, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -101, 106, 5, -98, -19, 91, -34, 18, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 15, -123, -87, -101, -44, 13, 30, 22, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -68, 28, -31, 59, 35, -122, 8, 76, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 2, 19, 18, -120, 20, -103, 118, 77, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -33, 89, -48, -70, 14, 103, 23, 83, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -93, -22, 65, 86, 81, 23, -11, 120, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, -61, -17, 53, 81, 43, -31, -72, 78, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, -23, 73, -48, -93, -84, 8, -46, -73, -87, 0, 0, 0, 0, 0, 0, 0, 116, 0, 0, 0, 0, 0, 0, 3, -22, 4, 106, 101, 102, 102, 10, 115, 117, 112, 101, 114, 103, 114, 111, 117, 112, 1, -92]
2011-08-09 19:57:19,542 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:13  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:57:19,542 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 339
2011-08-09 19:57:19,544 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 339
2011-08-09 19:57:19,544 INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(2625)) - commitBlockSynchronization(newblock=blk_5318931119202285481_1002, file=/foo875571745, newgenerationstamp=1002, newlength=116, newtargets=[127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808]) successful
2011-08-09 19:57:20,523 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:20,524 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:20,526 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:20,526 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:20,528 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:20,528 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:20,528 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:20,529 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:20,529 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:20,529 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:48788, block:blk_5318931119202285481_1002 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:20,530 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:20,530 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:20,531 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@13f4cf6f) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:20,532 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 2 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Will retry...
2011-08-09 19:57:21,532 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:21,533 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:21,535 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:21,536 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:21,537 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:21,537 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:21,538 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:21,539 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:21,539 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:21,539 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:48788, block:blk_5318931119202285481_1002 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:21,540 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:21,541 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:21,542 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@322b2057) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:21,543 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 3 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Will retry...
2011-08-09 19:57:22,543 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:22,543 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:22,545 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:22,546 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:22,548 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:22,548 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:22,557 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:22,557 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:22,558 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:22,558 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:48788, block:blk_5318931119202285481_1002 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:22,558 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:22,559 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 8 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:22,568 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@312cfd62) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:22,569 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 4 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Will retry...
2011-08-09 19:57:23,569 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:23,569 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:23,571 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:23,571 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:23,573 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:23,573 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:23,573 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:23,574 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:23,574 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:23,574 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:48788, block:blk_5318931119202285481_1002 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:23,575 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:23,575 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 4 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:23,576 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@40395aaf) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:23,576 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 5 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Will retry...
2011-08-09 19:57:24,577 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3153)) - Error Recovery for block blk_5318931119202285481_1001 bad datanode[0] 127.0.0.1:56616
2011-08-09 19:57:24,577 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3208)) - Error Recovery for block blk_5318931119202285481_1001 in pipeline 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808: bad datanode 127.0.0.1:56616
2011-08-09 19:57:24,579 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:48788, 127.0.0.1:33808])
2011-08-09 19:57:24,579 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:48788 (dnReg=DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980))
2011-08-09 19:57:24,581 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:24,581 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:24,581 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:33808
2011-08-09 19:57:24,581 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:24,582 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:24,582 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:48788, block:blk_5318931119202285481_1002 node:127.0.0.1:33808], closeFile=false
2011-08-09 19:57:24,582 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:24,582 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:24,583 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 60980, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2f8bbc98) from 127.0.0.1:46033: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:24,584 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3246)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:33808 failed 6 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788, 127.0.0.1:33808. Marking primary datanode as bad.
2011-08-09 19:57:25,587 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:25,588 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:25,598 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:25,598 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:25,600 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:25,600 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:25,600 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:25,600 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:25,601 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:25,601 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:25,601 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@410c6406) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:25,602 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 1 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Will retry...
2011-08-09 19:57:26,604 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:26,605 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:26,607 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:26,607 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:26,610 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:26,610 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:26,611 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:26,611 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:26,611 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:26,612 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:26,612 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@3aeebf17) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:26,613 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 2 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Will retry...
2011-08-09 19:57:27,615 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:27,616 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:27,617 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:27,618 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:27,618 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:27,618 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:27,619 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:27,619 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:27,619 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:27,620 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 8 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:27,620 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@74a638fc) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:27,621 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 3 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Will retry...
2011-08-09 19:57:28,623 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:28,624 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:28,626 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:28,626 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:28,626 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:28,627 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:28,627 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:28,627 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:28,627 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:28,628 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 4 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:28,628 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@2bd648e2) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:28,629 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 4 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Will retry...
2011-08-09 19:57:29,631 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:29,632 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:29,633 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:29,633 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:29,634 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:29,634 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:29,634 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:29,634 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:29,635 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:29,635 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:29,636 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@7c5438e1) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:29,636 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 5 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Will retry...
2011-08-09 19:57:30,639 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616, 127.0.0.1:48788])
2011-08-09 19:57:30,640 INFO  datanode.DataNode (DataNode.java:recoverBlock(1626)) - Creating IDNPP for non-local id 127.0.0.1:56616 (dnReg=DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590))
2011-08-09 19:57:30,645 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:30,645 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:30,646 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:48788
2011-08-09 19:57:30,646 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:30,646 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:30,647 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616, block:blk_5318931119202285481_1002 node:127.0.0.1:48788], closeFile=false
2011-08-09 19:57:30,647 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:30,647 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:30,648 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 49590, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@3f9ab00e) from 127.0.0.1:33194: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:30,649 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3246)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:48788 failed 6 times.  Pipeline was 127.0.0.1:56616, 127.0.0.1:48788. Marking primary datanode as bad.
2011-08-09 19:57:31,652 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:31,653 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:31,653 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:31,653 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:31,654 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:31,654 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:31,655 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:31,655 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@4e3e97cd) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:31,657 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 1 times.  Pipeline was 127.0.0.1:56616. Will retry...
2011-08-09 19:57:32,658 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:32,659 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:32,659 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:32,660 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:32,660 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:32,660 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:32,660 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 8 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:32,661 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@796528a2) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:32,662 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 2 times.  Pipeline was 127.0.0.1:56616. Will retry...
2011-08-09 19:57:33,664 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:33,665 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:33,665 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:33,665 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:33,665 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:33,666 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:33,666 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 4 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:33,667 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@659adc2c) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:33,668 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 3 times.  Pipeline was 127.0.0.1:56616. Will retry...
2011-08-09 19:57:34,676 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:34,678 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:34,678 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:34,678 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:34,678 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:34,679 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:34,679 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:34,680 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@14a97f68) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:34,681 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 4 times.  Pipeline was 127.0.0.1:56616. Will retry...
2011-08-09 19:57:35,683 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:35,684 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:35,684 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:35,684 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:35,685 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:35,685 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:35,685 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 6 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:35,686 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 0 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@273f212a) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:35,687 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3266)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 5 times.  Pipeline was 127.0.0.1:56616. Will retry...
2011-08-09 19:57:36,688 INFO  datanode.DataNode (DataNode.java:logRecoverBlock(1789)) - Client calls recoverBlock(block=blk_5318931119202285481_1001, targets=[127.0.0.1:56616])
2011-08-09 19:57:36,689 INFO  datanode.DataNode (DataNode.java:recoverBlock(1623)) - Skipping IDNPP creation for local id 127.0.0.1:56616
2011-08-09 19:57:36,689 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1478)) - block=blk_5318931119202285481_1001
2011-08-09 19:57:36,690 DEBUG datanode.DataNode (DataNode.java:getBlockMetaDataInfo(1488)) - getBlockMetaDataInfo successful block=blk_5318931119202285481_1002 length 116 genstamp 1002
2011-08-09 19:57:36,690 DEBUG datanode.DataNode (DataNode.java:syncBlock(1689)) - block=blk_5318931119202285481_1001, (length=116), syncList=[block:blk_5318931119202285481_1002 node:127.0.0.1:56616], closeFile=false
2011-08-09 19:57:36,690 INFO  namenode.FSNamesystem (FSNamesystem.java:nextGenerationStampForBlock(6038)) - blk_5318931119202285481_1001 is already commited, storedBlock == null.
2011-08-09 19:57:36,690 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 2 on 57846, call nextGenerationStamp(blk_5318931119202285481_1001) from 127.0.0.1:59115: error: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:36,691 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 1 on 46091, call recoverBlock(blk_5318931119202285481_1001, false, [Lorg.apache.hadoop.hdfs.protocol.DatanodeInfo;@4c767fb3) from 127.0.0.1:56908: error: org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

org.apache.hadoop.ipc.RemoteException: java.io.IOException: blk_5318931119202285481_1001 is already commited, storedBlock == null.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.nextGenerationStampForBlock(FSNamesystem.java:6039)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.nextGenerationStamp(NameNode.java:623)
	at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy5.nextGenerationStamp(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(DataNode.java:1703)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1660)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(DataNode.java:1745)
	at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:57:36,692 WARN  hdfs.DFSClient (DFSClient.java:processDatanodeError(3260)) - Error Recovery for block blk_5318931119202285481_1001 failed  because recovery from primary datanode 127.0.0.1:56616 failed 6 times.  Pipeline was 127.0.0.1:56616. Aborting...
2011-08-09 19:57:40,932 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_-2352619832800241837_1001
2011-08-09 19:57:55,771 INFO  datanode.DataBlockScanner (DataBlockScanner.java:verifyBlock(435)) - Verification succeeded for blk_1118486569214090774_1001
2011-08-09 19:58:18,955 WARN  hdfs.StateChange (FSNamesystem.java:startFileInternal(1590)) - DIR* NameSystem.startFile: failed to create file /foo875571745 on client 127.0.0.1 either because the filename is invalid or the file exists
2011-08-09 19:58:18,955 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 4 on 57846, call create(/foo875571745, rwxr-xr-x, DFSClient_1579240028, false, 3, 1024) from 127.0.0.1:59155: error: java.io.IOException: failed to create file /foo875571745 on client 127.0.0.1 either because the filename is invalid or the file exists
java.io.IOException: failed to create file /foo875571745 on client 127.0.0.1 either because the filename is invalid or the file exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1541)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:58:18,957 INFO  hdfs.AppendTestUtil (TestLeaseRecovery2.java:testBlockSynchronization(109)) - done
org.apache.hadoop.ipc.RemoteException: java.io.IOException: failed to create file /foo875571745 on client 127.0.0.1 either because the filename is invalid or the file exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1541)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)

	at org.apache.hadoop.ipc.Client.call(Client.java:764)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:223)
	at $Proxy4.create(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy4.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.<init>(DFSClient.java:3353)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:578)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:195)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:527)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:508)
	at org.apache.hadoop.hdfs.TestLeaseRecovery2.testBlockSynchronization(TestLeaseRecovery2.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:421)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:912)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:766)
2011-08-09 19:58:18,957 INFO  hdfs.AppendTestUtil (TestLeaseRecovery2.java:testBlockSynchronization(128)) - Lease for file /foo875571745 is recovered. Validating its contents now...
File size is good. Now validating sizes from datanodes...
2011-08-09 19:58:18,965 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/foo875571745	dst=null	perm=null
2011-08-09 19:58:18,970 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,972 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33705, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-4856947659772128003_1001, duration: 868879
2011-08-09 19:58:18,974 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:58:18,974 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:58:18,975 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33706, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_2676346411578617259_1001, duration: 326703
2011-08-09 19:58:18,976 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:58:18,976 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:58:18,978 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,979 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33707, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-7247974470154199534_1001, duration: 2216495
2011-08-09 19:58:18,979 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:56616, dest: /127.0.0.1:50495, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_1118486569214090774_1001, duration: 295961
2011-08-09 19:58:18,980 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:58:18,980 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,981 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:58:18,982 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:56616, dest: /127.0.0.1:50496, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-1212468723-10.0.62.238-56616-1312912575824, blockid: blk_-4891787451115894708_1001, duration: 297638
2011-08-09 19:58:18,982 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Number of active connections is: 2
2011-08-09 19:58:18,982 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,984 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:58:18,984 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33710, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_149483588303812173_1001, duration: 1261259
2011-08-09 19:58:18,984 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 3
2011-08-09 19:58:18,985 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33711, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-2352619832800241837_1001, duration: 296241
2011-08-09 19:58:18,985 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:58:18,986 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,987 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:44003, dest: /127.0.0.1:47456, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-923530740-10.0.62.238-44003-1312912576184, blockid: blk_-6635419261993486984_1001, duration: 297917
2011-08-09 19:58:18,987 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 1
2011-08-09 19:58:18,988 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Number of active connections is: 2
2011-08-09 19:58:18,989 DEBUG datanode.DataNode (DataXceiver.java:<init>(68)) - Number of active connections is: 2
2011-08-09 19:58:18,989 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33713, bytes: 1032, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_-4328182094134921138_1001, duration: 1202850
2011-08-09 19:58:18,990 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 3
Shutting down the Mini HDFS Cluster
Shutting down DataNode 4
2011-08-09 19:58:18,991 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:33808, dest: /127.0.0.1:33714, bytes: 120, op: HDFS_READ, cliID: DFSClient_19585158, offset: 0, srvID: DS-277678909-10.0.62.238-33808-1312912575260, blockid: blk_5318931119202285481_1002, duration: 294844
2011-08-09 19:58:18,991 DEBUG datanode.DataNode (DataXceiver.java:run(157)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Number of active connections is: 2
2011-08-09 19:58:19,004 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:19,108 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58463
2011-08-09 19:58:19,109 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 58463: exiting
2011-08-09 19:58:19,109 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 58463
2011-08-09 19:58:19,110 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 58463: exiting
2011-08-09 19:58:19,110 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 58463: exiting
2011-08-09 19:58:19,111 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:58:19,112 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:58:19,110 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:19,331 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:58:19,389 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:49989, storageID=DS-1407648578-10.0.62.238-49989-1312912576725, infoPort=34951, ipcPort=58463):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data9/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data10/current'}
2011-08-09 19:58:19,390 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58463
2011-08-09 19:58:19,390 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:19,391 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:58:19,391 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:58:20,112 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:20,114 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 3
2011-08-09 19:58:20,117 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:20,217 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60852
2011-08-09 19:58:20,218 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60852: exiting
2011-08-09 19:58:20,218 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60852: exiting
2011-08-09 19:58:20,219 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60852: exiting
2011-08-09 19:58:20,219 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60852
2011-08-09 19:58:20,220 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:58:20,221 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:20,221 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:58:20,221 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:58:20,222 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44003, storageID=DS-923530740-10.0.62.238-44003-1312912576184, infoPort=32903, ipcPort=60852):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data7/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data8/current'}
2011-08-09 19:58:20,222 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60852
2011-08-09 19:58:20,222 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:20,223 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:58:20,223 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:58:20,224 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 2
2011-08-09 19:58:20,258 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:20,360 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46091
2011-08-09 19:58:20,360 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 46091: exiting
2011-08-09 19:58:20,360 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 46091: exiting
2011-08-09 19:58:20,360 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 46091
2011-08-09 19:58:20,361 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 46091: exiting
2011-08-09 19:58:20,362 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:20,362 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:58:20,362 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:58:20,432 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:58:20,493 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:56616, storageID=DS-1212468723-10.0.62.238-56616-1312912575824, infoPort=48011, ipcPort=46091):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data5/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data6/current'}
2011-08-09 19:58:20,494 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46091
2011-08-09 19:58:20,494 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:20,495 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:58:20,495 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:58:21,362 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:21,364 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 1
2011-08-09 19:58:21,428 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:21,429 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60980
2011-08-09 19:58:21,432 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60980: exiting
2011-08-09 19:58:21,432 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60980: exiting
2011-08-09 19:58:21,432 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60980: exiting
2011-08-09 19:58:21,433 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60980
2011-08-09 19:58:21,435 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:21,436 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:58:21,436 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:58:21,958 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:58:21,960 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:33808, storageID=DS-277678909-10.0.62.238-33808-1312912575260, infoPort=56663, ipcPort=60980):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:58:21,961 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60980
2011-08-09 19:58:21,961 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:21,962 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:58:21,963 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:58:22,436 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:22,437 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:58:22,479 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:22,580 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49590
2011-08-09 19:58:22,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49590: exiting
2011-08-09 19:58:22,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49590: exiting
2011-08-09 19:58:22,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49590: exiting
2011-08-09 19:58:22,581 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49590
2011-08-09 19:58:22,582 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:22,582 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:58:22,582 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:58:23,178 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:58:23,289 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48788, storageID=DS-574479426-10.0.62.238-48788-1312912574624, infoPort=47197, ipcPort=49590):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:58:23,290 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49590
2011-08-09 19:58:23,290 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:23,290 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:58:23,291 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:58:23,582 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:58:23,582 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:58:23,600 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:58:23,701 DEBUG namenode.FSNamesystem (PendingReplicationBlocks.java:run(188)) - PendingReplicationMonitor thread received exception. java.lang.InterruptedException: sleep interrupted
2011-08-09 19:58:23,702 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:58:23,702 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:58:23,703 DEBUG namenode.LeaseManager (LeaseManager.java:run(374)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:371)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:58:23,703 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 5 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:15  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:58:23,703 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:58:23,705 DEBUG namenode.FSNamesystem (FSEditLog.java:flushAndSync(261)) - Flushing buffer of size: 1
2011-08-09 19:58:23,706 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57846
2011-08-09 19:58:23,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57846: exiting
2011-08-09 19:58:23,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57846: exiting
2011-08-09 19:58:23,706 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57846: exiting
2011-08-09 19:58:23,707 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 57846: exiting
2011-08-09 19:58:23,707 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57846
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 57846: exiting
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 57846: exiting
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 57846: exiting
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 57846: exiting
2011-08-09 19:58:23,708 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 57846: exiting
2011-08-09 19:58:23,709 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 57846: exiting
------------- ---------------- ---------------

Testcase: testBlockSynchronization took 162.719 sec
