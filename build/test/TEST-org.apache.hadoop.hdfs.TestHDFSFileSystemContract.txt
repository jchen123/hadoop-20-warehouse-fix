Testsuite: org.apache.hadoop.hdfs.TestHDFSFileSystemContract
Tests run: 27, Failures: 0, Errors: 0, Time elapsed: 82.427 sec
------------- Standard Output ---------------
2011-08-09 19:42:33,131 WARN  conf.Configuration (Configuration.java:<clinit>(191)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively
2011-08-09 19:42:33,542 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:33,544 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:33,545 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:33,545 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:33,576 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:33,576 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:33,577 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:33,673 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:33,754 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:33,757 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:33,789 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:33,792 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:33,793 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:33,804 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:33,823 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
2011-08-09 19:42:33,920 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:33,920 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:33,921 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:33,921 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:33,921 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:33,998 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:33,999 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:33,999 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:33,999 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:34,025 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:34,026 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:34,035 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:34,042 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:34,043 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:34,043 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:34,046 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:34,047 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:34,048 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:34,049 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:34,049 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 52 msecs
2011-08-09 19:42:34,051 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:34,061 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:34,062 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:34,062 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:34,063 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:34,063 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:34,094 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:34,100 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=34199
2011-08-09 19:42:34,104 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:34199
2011-08-09 19:42:34,105 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:34,107 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34199: starting
2011-08-09 19:42:34,107 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34199: starting
2011-08-09 19:42:34,108 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34199: starting
2011-08-09 19:42:34,108 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34199: starting
2011-08-09 19:42:34,109 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 34199: starting
2011-08-09 19:42:34,110 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 34199: starting
2011-08-09 19:42:34,119 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 34199: starting
2011-08-09 19:42:34,119 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 34199: starting
2011-08-09 19:42:34,120 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 34199: starting
2011-08-09 19:42:34,120 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 34199: starting
2011-08-09 19:42:34,126 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 34199: starting
2011-08-09 19:42:34,258 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:34,259 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:34,260 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:34,260 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:34,269 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:34,376 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2011-08-09 19:42:34,461 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:34,531 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:34,532 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34659 webServer.getConnectors()[0].getLocalPort() returned 34659
2011-08-09 19:42:34,532 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34659
2011-08-09 19:42:34,532 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:35,060 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34659
2011-08-09 19:42:35,060 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:34659
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:35,170 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:35,171 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:35,193 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:35,194 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:35,343 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:35,344 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54075
2011-08-09 19:42:35,347 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:35,369 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:35,372 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:35,373 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35667 webServer.getConnectors()[0].getLocalPort() returned 35667
2011-08-09 19:42:35,373 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35667
2011-08-09 19:42:35,373 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:35,563 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35667
2011-08-09 19:42:35,565 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:35,602 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=54003
2011-08-09 19:42:35,616 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:35,622 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:35,623 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54003: starting
2011-08-09 19:42:35,623 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54003: starting
2011-08-09 19:42:35,624 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54003: starting
2011-08-09 19:42:35,624 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54075, storageID=, infoPort=35667, ipcPort=54003)
2011-08-09 19:42:35,627 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54003: starting
2011-08-09 19:42:35,667 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54075 storage DS-1776216684-10.0.62.238-54075-1312911755664
2011-08-09 19:42:35,671 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54075
2011-08-09 19:42:35,678 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1776216684-10.0.62.238-54075-1312911755664 is assigned to data-node 127.0.0.1:54075
2011-08-09 19:42:35,679 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54075, storageID=DS-1776216684-10.0.62.238-54075-1312911755664, infoPort=35667, ipcPort=54003)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:35,680 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:35,686 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:35,688 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54075 0 blocks shortCircuit first report.
2011-08-09 19:42:35,689 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:42:35,690 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:35,691 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:35,698 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:35,698 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:35,716 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:35,716 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:35,843 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:35,844 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37431
2011-08-09 19:42:35,845 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:35,848 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:35,849 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:35,849 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58689 webServer.getConnectors()[0].getLocalPort() returned 58689
2011-08-09 19:42:35,850 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58689
2011-08-09 19:42:35,850 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:36,133 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58689
2011-08-09 19:42:36,134 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:36,168 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:36,171 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=57461
2011-08-09 19:42:36,172 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:36,172 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57461: starting
2011-08-09 19:42:36,173 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57461: starting
2011-08-09 19:42:36,173 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57461: starting
2011-08-09 19:42:36,174 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37431, storageID=, infoPort=58689, ipcPort=57461)
2011-08-09 19:42:36,174 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57461: starting
2011-08-09 19:42:36,191 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37431 storage DS-125828409-10.0.62.238-37431-1312911756188
2011-08-09 19:42:36,192 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37431
2011-08-09 19:42:36,208 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-125828409-10.0.62.238-37431-1312911756188 is assigned to data-node 127.0.0.1:37431
2011-08-09 19:42:36,209 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37431, storageID=DS-125828409-10.0.62.238-37431-1312911756188, infoPort=58689, ipcPort=57461)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:36,210 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:36,216 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:36,222 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37431 0 blocks shortCircuit first report.
2011-08-09 19:42:36,222 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 6 msecs
2011-08-09 19:42:36,239 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:36,257 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:36,258 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:36,278 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:36,279 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57461
2011-08-09 19:42:36,279 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57461: exiting
2011-08-09 19:42:36,281 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37431, storageID=DS-125828409-10.0.62.238-37431-1312911756188, infoPort=58689, ipcPort=57461):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:36,280 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:36,280 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57461
2011-08-09 19:42:36,280 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:36,282 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57461: exiting
2011-08-09 19:42:36,282 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57461: exiting
2011-08-09 19:42:36,283 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:36,283 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37431, storageID=DS-125828409-10.0.62.238-37431-1312911756188, infoPort=58689, ipcPort=57461):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:36,283 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57461
2011-08-09 19:42:36,284 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:36,284 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:36,284 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:36,285 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:36,311 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:36,412 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54003
2011-08-09 19:42:36,412 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54003: exiting
2011-08-09 19:42:36,413 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54003: exiting
2011-08-09 19:42:36,413 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54003: exiting
2011-08-09 19:42:36,413 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54003
2011-08-09 19:42:36,414 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54075, storageID=DS-1776216684-10.0.62.238-54075-1312911755664, infoPort=35667, ipcPort=54003):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:36,415 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:36,415 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:36,698 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:37,415 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:37,416 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54075, storageID=DS-1776216684-10.0.62.238-54075-1312911755664, infoPort=35667, ipcPort=54003):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:37,416 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54003
2011-08-09 19:42:37,416 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:37,416 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:37,417 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:37,417 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:37,422 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:37,523 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:37,525 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:37,526 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:42:37,533 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34199
2011-08-09 19:42:37,537 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34199: exiting
2011-08-09 19:42:37,537 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34199: exiting
2011-08-09 19:42:37,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34199: exiting
2011-08-09 19:42:37,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 34199: exiting
2011-08-09 19:42:37,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 34199: exiting
2011-08-09 19:42:37,538 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 34199: exiting
2011-08-09 19:42:37,539 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 34199: exiting
2011-08-09 19:42:37,540 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 34199: exiting
2011-08-09 19:42:37,540 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 34199: exiting
2011-08-09 19:42:37,540 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 34199: exiting
2011-08-09 19:42:37,541 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34199
2011-08-09 19:42:37,543 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:37,633 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:37,633 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:37,633 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:37,634 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:37,723 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:37,727 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:37,727 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:37,727 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:37,735 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:37,735 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:37,748 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:37,751 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:37,751 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:37,788 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:37,788 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:37,792 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:37,792 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:37,792 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:37,792 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:37,792 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:37,796 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:37,796 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:37,797 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:37,797 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:37,800 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:37,801 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:37,826 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:37,830 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:37,831 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:37,831 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:37,831 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:37,832 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:37,832 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:37,833 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:37,833 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:42:37,833 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:37,841 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:37,841 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:37,841 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:37,842 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:37,842 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:37,843 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:37,845 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=41285
2011-08-09 19:42:37,846 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:41285
2011-08-09 19:42:37,847 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:37,847 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41285: starting
2011-08-09 19:42:37,847 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41285: starting
2011-08-09 19:42:37,848 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41285: starting
2011-08-09 19:42:37,848 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41285: starting
2011-08-09 19:42:37,849 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 41285: starting
2011-08-09 19:42:37,849 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 41285: starting
2011-08-09 19:42:37,849 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 41285: starting
2011-08-09 19:42:37,849 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 41285: starting
2011-08-09 19:42:37,849 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 41285: starting
2011-08-09 19:42:37,850 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 41285: starting
2011-08-09 19:42:37,850 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 41285: starting
2011-08-09 19:42:37,866 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:37,867 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:37,867 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:37,868 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:37,868 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:37,870 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:37,876 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:37,876 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 60505 webServer.getConnectors()[0].getLocalPort() returned 60505
2011-08-09 19:42:37,876 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 60505
2011-08-09 19:42:37,876 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:38,034 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:60505
2011-08-09 19:42:38,034 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:60505
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:38,067 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:38,067 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:38,084 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:38,084 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:38,220 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:38,222 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 47630
2011-08-09 19:42:38,222 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:38,225 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:38,226 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:38,227 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 46999 webServer.getConnectors()[0].getLocalPort() returned 46999
2011-08-09 19:42:38,227 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 46999
2011-08-09 19:42:38,227 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:38,308 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:46999
2011-08-09 19:42:38,309 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:38,316 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:38,318 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=55428
2011-08-09 19:42:38,320 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:38,322 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 55428: starting
2011-08-09 19:42:38,323 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:47630, storageID=, infoPort=46999, ipcPort=55428)
2011-08-09 19:42:38,323 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 55428: starting
2011-08-09 19:42:38,323 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 55428: starting
2011-08-09 19:42:38,325 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 55428: starting
2011-08-09 19:42:38,330 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:47630 storage DS-940101504-10.0.62.238-47630-1312911758327
2011-08-09 19:42:38,330 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:47630
2011-08-09 19:42:38,336 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-940101504-10.0.62.238-47630-1312911758327 is assigned to data-node 127.0.0.1:47630
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:38,338 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:47630, storageID=DS-940101504-10.0.62.238-47630-1312911758327, infoPort=46999, ipcPort=55428)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:38,381 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:38,389 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:38,390 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:47630 0 blocks shortCircuit first report.
2011-08-09 19:42:38,391 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:42:38,391 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:38,392 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:38,411 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:38,416 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:38,437 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:38,438 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:38,619 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:38,621 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 49054
2011-08-09 19:42:38,621 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:38,624 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:38,625 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:38,626 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 55167 webServer.getConnectors()[0].getLocalPort() returned 55167
2011-08-09 19:42:38,626 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 55167
2011-08-09 19:42:38,626 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:38,789 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:55167
2011-08-09 19:42:38,792 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:38,797 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:38,799 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41086
2011-08-09 19:42:38,801 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:38,801 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41086: starting
2011-08-09 19:42:38,844 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41086: starting
2011-08-09 19:42:38,844 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41086: starting
2011-08-09 19:42:38,845 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41086: starting
2011-08-09 19:42:38,845 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:49054, storageID=, infoPort=55167, ipcPort=41086)
2011-08-09 19:42:38,851 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:49054 storage DS-1512686650-10.0.62.238-49054-1312911758848
2011-08-09 19:42:38,852 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:49054
2011-08-09 19:42:38,859 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1512686650-10.0.62.238-49054-1312911758848 is assigned to data-node 127.0.0.1:49054
2011-08-09 19:42:38,860 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:49054, storageID=DS-1512686650-10.0.62.238-49054-1312911758848, infoPort=55167, ipcPort=41086)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:38,862 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:38,869 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:38,872 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:49054 0 blocks shortCircuit first report.
2011-08-09 19:42:38,873 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 5 msecs
2011-08-09 19:42:38,874 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:38,916 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:38,937 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:38,942 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:38,950 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:38,959 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:39,003 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:39,104 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41086
2011-08-09 19:42:39,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41086: exiting
2011-08-09 19:42:39,105 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41086
2011-08-09 19:42:39,107 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:39,105 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41086: exiting
2011-08-09 19:42:39,115 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:49054, storageID=DS-1512686650-10.0.62.238-49054-1312911758848, infoPort=55167, ipcPort=41086):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:39,115 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:39,106 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41086: exiting
2011-08-09 19:42:39,117 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:39,118 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:49054, storageID=DS-1512686650-10.0.62.238-49054-1312911758848, infoPort=55167, ipcPort=41086):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:39,119 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41086
2011-08-09 19:42:39,119 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:39,120 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:39,120 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:39,121 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:39,193 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:39,300 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 55428
2011-08-09 19:42:39,300 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 55428: exiting
2011-08-09 19:42:39,301 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 55428: exiting
2011-08-09 19:42:39,301 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 55428: exiting
2011-08-09 19:42:39,301 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 55428
2011-08-09 19:42:39,304 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:39,305 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:47630, storageID=DS-940101504-10.0.62.238-47630-1312911758327, infoPort=46999, ipcPort=55428):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:39,305 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:39,306 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:39,307 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:47630, storageID=DS-940101504-10.0.62.238-47630-1312911758327, infoPort=46999, ipcPort=55428):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:39,307 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 55428
2011-08-09 19:42:39,308 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:39,308 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:39,309 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:39,317 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:39,369 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:39,470 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:39,471 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:39,472 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:42:39,475 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41285
2011-08-09 19:42:39,475 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41285: exiting
2011-08-09 19:42:39,475 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 41285: exiting
2011-08-09 19:42:39,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 41285: exiting
2011-08-09 19:42:39,477 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 41285: exiting
2011-08-09 19:42:39,477 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 41285: exiting
2011-08-09 19:42:39,477 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41285
2011-08-09 19:42:39,481 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:39,567 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:39,567 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:39,567 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:39,567 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:39,575 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:39,576 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:39,576 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:39,576 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:39,614 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:39,614 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:39,626 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:39,629 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:39,629 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:39,778 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:39,779 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:39,783 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:39,783 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:39,783 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:39,783 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:39,783 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:39,788 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:39,788 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:39,789 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:39,789 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:39,792 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:39,793 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:39,819 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:39,823 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:39,824 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:39,824 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:39,824 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:39,824 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:39,825 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:39,826 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:39,826 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 38 msecs
2011-08-09 19:42:39,826 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:39,829 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:39,829 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:39,830 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:39,830 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:39,830 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:39,832 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:39,835 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=34304
2011-08-09 19:42:39,835 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:34304
2011-08-09 19:42:39,836 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:39,836 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34304: starting
2011-08-09 19:42:39,877 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34304: starting
2011-08-09 19:42:39,877 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34304: starting
2011-08-09 19:42:39,878 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34304: starting
2011-08-09 19:42:39,878 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 34304: starting
2011-08-09 19:42:39,879 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 34304: starting
2011-08-09 19:42:39,879 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 34304: starting
2011-08-09 19:42:39,879 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 34304: starting
2011-08-09 19:42:39,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 34304: starting
2011-08-09 19:42:39,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 34304: starting
2011-08-09 19:42:39,882 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 34304: starting
2011-08-09 19:42:39,894 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:39,894 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:39,894 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:39,895 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:39,895 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:39,897 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:39,898 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:39,898 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35204 webServer.getConnectors()[0].getLocalPort() returned 35204
2011-08-09 19:42:39,899 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35204
2011-08-09 19:42:39,899 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:39,959 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35204
2011-08-09 19:42:39,960 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:35204
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:39,975 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:39,975 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:39,992 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:39,993 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:40,156 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:40,157 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40507
2011-08-09 19:42:40,158 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:40,160 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:40,161 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:40,162 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59387 webServer.getConnectors()[0].getLocalPort() returned 59387
2011-08-09 19:42:40,162 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59387
2011-08-09 19:42:40,162 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:40,250 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59387
2011-08-09 19:42:40,251 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:40,256 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:40,258 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34330
2011-08-09 19:42:40,259 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:40,283 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34330: starting
2011-08-09 19:42:40,283 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34330: starting
2011-08-09 19:42:40,283 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40507, storageID=, infoPort=59387, ipcPort=34330)
2011-08-09 19:42:40,284 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34330: starting
2011-08-09 19:42:40,303 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34330: starting
2011-08-09 19:42:40,309 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40507 storage DS-1441024663-10.0.62.238-40507-1312911760305
2011-08-09 19:42:40,311 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40507
2011-08-09 19:42:40,321 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1441024663-10.0.62.238-40507-1312911760305 is assigned to data-node 127.0.0.1:40507
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:40,323 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40507, storageID=DS-1441024663-10.0.62.238-40507-1312911760305, infoPort=59387, ipcPort=34330)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:40,324 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:40,382 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:40,383 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:40,384 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:40,386 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40507 0 blocks shortCircuit first report.
2011-08-09 19:42:40,387 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:42:40,387 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:40,388 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:40,401 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:40,401 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:40,577 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:40,578 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 36791
2011-08-09 19:42:40,579 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:40,581 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:40,582 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:40,583 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 33119 webServer.getConnectors()[0].getLocalPort() returned 33119
2011-08-09 19:42:40,583 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 33119
2011-08-09 19:42:40,583 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:40,672 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:33119
2011-08-09 19:42:40,672 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:40,677 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:40,680 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=44376
2011-08-09 19:42:40,681 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:40,681 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44376: starting
2011-08-09 19:42:40,724 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44376: starting
2011-08-09 19:42:40,725 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44376: starting
2011-08-09 19:42:40,725 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44376: starting
2011-08-09 19:42:40,725 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:36791, storageID=, infoPort=33119, ipcPort=44376)
2011-08-09 19:42:40,731 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:36791 storage DS-664115655-10.0.62.238-36791-1312911760728
2011-08-09 19:42:40,731 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:36791
2011-08-09 19:42:40,738 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-664115655-10.0.62.238-36791-1312911760728 is assigned to data-node 127.0.0.1:36791
2011-08-09 19:42:40,739 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:36791, storageID=DS-664115655-10.0.62.238-36791-1312911760728, infoPort=33119, ipcPort=44376)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:40,740 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:40,745 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:40,746 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:36791 0 blocks shortCircuit first report.
2011-08-09 19:42:40,771 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 27 msecs
2011-08-09 19:42:40,772 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:40,773 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:40,788 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:40,804 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:42:40,814 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_3001843581026724155_1001
2011-08-09 19:42:40,862 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_3001843581026724155_1001 src: /127.0.0.1:44149 dest: /127.0.0.1:36791
2011-08-09 19:42:40,886 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_3001843581026724155_1001 src: /127.0.0.1:53221 dest: /127.0.0.1:40507
2011-08-09 19:42:40,894 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:53221, dest: /127.0.0.1:40507, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_2110176229, offset: 0, srvID: DS-1441024663-10.0.62.238-40507-1312911760305, blockid: blk_3001843581026724155_1001, duration: 2208819
2011-08-09 19:42:40,898 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_3001843581026724155_1001 terminating
2011-08-09 19:42:40,912 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:40507 is added to blk_3001843581026724155_1001 size 2048
2011-08-09 19:42:40,914 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:44149, dest: /127.0.0.1:36791, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_2110176229, offset: 0, srvID: DS-664115655-10.0.62.238-36791-1312911760728, blockid: blk_3001843581026724155_1001, duration: 7019094
2011-08-09 19:42:40,916 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_3001843581026724155_1001 terminating
2011-08-09 19:42:40,917 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:36791 is added to blk_3001843581026724155_1001 size 2048
2011-08-09 19:42:40,949 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_2110176229
2011-08-09 19:42:40,953 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 34304, call mkdirs(/test/hadoop/file/subdir, rwxr-xr-x) from 127.0.0.1:48951: error: java.io.FileNotFoundException: Parent path is not a directory: /test/hadoop/file
java.io.FileNotFoundException: Parent path is not a directory: /test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.mkdirs(FSDirectory.java:1322)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:2372)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:2329)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs(NameNode.java:699)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:42:40,956 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 5 on 34304, call mkdirs(/test/hadoop/file/deep/sub/dir, rwxr-xr-x) from 127.0.0.1:48951: error: java.io.FileNotFoundException: Parent path is not a directory: /test/hadoop/file
java.io.FileNotFoundException: Parent path is not a directory: /test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.mkdirs(FSDirectory.java:1322)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:2372)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:2329)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.mkdirs(NameNode.java:699)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:42:40,958 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:40,963 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_3001843581026724155 is added to invalidSet of 127.0.0.1:40507
2011-08-09 19:42:40,963 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_3001843581026724155 is added to invalidSet of 127.0.0.1:36791
2011-08-09 19:42:40,965 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:41,031 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:41,132 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44376
2011-08-09 19:42:41,132 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44376: exiting
2011-08-09 19:42:41,132 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44376: exiting
2011-08-09 19:42:41,133 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44376: exiting
2011-08-09 19:42:41,133 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44376
2011-08-09 19:42:41,134 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:41,135 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:36791, storageID=DS-664115655-10.0.62.238-36791-1312911760728, infoPort=33119, ipcPort=44376):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:41,135 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:41,136 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:41,137 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:36791, storageID=DS-664115655-10.0.62.238-36791-1312911760728, infoPort=33119, ipcPort=44376):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:41,137 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44376
2011-08-09 19:42:41,137 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:41,138 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:41,138 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:41,139 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:41,172 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:41,273 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34330
2011-08-09 19:42:41,273 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34330: exiting
2011-08-09 19:42:41,274 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34330
2011-08-09 19:42:41,274 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34330: exiting
2011-08-09 19:42:41,274 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34330: exiting
2011-08-09 19:42:41,276 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:41,276 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:41,277 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40507, storageID=DS-1441024663-10.0.62.238-40507-1312911760305, infoPort=59387, ipcPort=34330):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:41,389 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:42,277 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:42,278 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40507, storageID=DS-1441024663-10.0.62.238-40507-1312911760305, infoPort=59387, ipcPort=34330):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:42,279 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34330
2011-08-09 19:42:42,279 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:42,279 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:42,280 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:42,281 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:42,344 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:42,445 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:42,445 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:42:42,446 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:42,447 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34304
2011-08-09 19:42:42,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34304: exiting
2011-08-09 19:42:42,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34304: exiting
2011-08-09 19:42:42,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34304: exiting
2011-08-09 19:42:42,448 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 34304: exiting
2011-08-09 19:42:42,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 34304: exiting
2011-08-09 19:42:42,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 34304: exiting
2011-08-09 19:42:42,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 34304: exiting
2011-08-09 19:42:42,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 34304: exiting
2011-08-09 19:42:42,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 34304: exiting
2011-08-09 19:42:42,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 34304: exiting
2011-08-09 19:42:42,451 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34304
2011-08-09 19:42:42,451 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:42,535 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:42,535 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:42,536 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:42,536 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:42,549 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:42,549 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:42,549 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:42,549 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:42,578 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:42,578 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:42,592 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:42,595 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:42,595 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:42,789 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:42,790 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:42,794 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:42,794 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:42,794 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:42,794 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:42,794 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:42,800 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:42,800 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:42,800 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:42,800 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:42,804 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:42,804 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:42,860 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:42,864 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:42,864 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:42,865 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:42,865 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:42,865 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:42,866 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:42,866 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:42,866 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 66 msecs
2011-08-09 19:42:42,866 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:42,870 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:42,870 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:42,870 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:42,870 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:42,871 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:42,874 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=40940
2011-08-09 19:42:42,875 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:40940
2011-08-09 19:42:42,875 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:42,894 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40940: starting
2011-08-09 19:42:42,894 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40940: starting
2011-08-09 19:42:42,894 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40940: starting
2011-08-09 19:42:42,894 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40940: starting
2011-08-09 19:42:42,895 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 40940: starting
2011-08-09 19:42:42,895 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 40940: starting
2011-08-09 19:42:42,895 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 40940: starting
2011-08-09 19:42:42,895 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 40940: starting
2011-08-09 19:42:42,896 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 40940: starting
2011-08-09 19:42:42,896 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 40940: starting
2011-08-09 19:42:42,897 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 40940: starting
2011-08-09 19:42:42,914 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:42,919 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:42,919 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:42,919 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:42,920 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:42,961 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:42,962 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:42,963 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:42,964 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59404 webServer.getConnectors()[0].getLocalPort() returned 59404
2011-08-09 19:42:42,964 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59404
2011-08-09 19:42:42,964 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:43,065 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59404
2011-08-09 19:42:43,065 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:59404
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:43,073 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:43,073 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:43,091 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:43,091 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:43,333 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:43,336 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53943
2011-08-09 19:42:43,337 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:43,343 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:43,344 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:43,345 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35311 webServer.getConnectors()[0].getLocalPort() returned 35311
2011-08-09 19:42:43,346 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35311
2011-08-09 19:42:43,346 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:43,600 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35311
2011-08-09 19:42:43,601 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:43,622 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:43,624 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=53736
2011-08-09 19:42:43,625 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:43,666 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53736: starting
2011-08-09 19:42:43,667 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53736: starting
2011-08-09 19:42:43,667 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53736: starting
2011-08-09 19:42:43,688 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53943, storageID=, infoPort=35311, ipcPort=53736)
2011-08-09 19:42:43,689 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53736: starting
2011-08-09 19:42:43,695 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53943 storage DS-1149193115-10.0.62.238-53943-1312911763692
2011-08-09 19:42:43,696 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53943
2011-08-09 19:42:43,702 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1149193115-10.0.62.238-53943-1312911763692 is assigned to data-node 127.0.0.1:53943
2011-08-09 19:42:43,703 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53943, storageID=DS-1149193115-10.0.62.238-53943-1312911763692, infoPort=35311, ipcPort=53736)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:43,704 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:43,711 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:43,713 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53943 0 blocks shortCircuit first report.
2011-08-09 19:42:43,714 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:43,715 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:43,721 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 10 msecs
2011-08-09 19:42:43,721 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:43,722 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:43,732 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:43,732 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:43,921 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:43,922 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 42401
2011-08-09 19:42:43,922 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:43,925 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:43,926 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:43,926 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42960 webServer.getConnectors()[0].getLocalPort() returned 42960
2011-08-09 19:42:43,926 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42960
2011-08-09 19:42:43,927 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:44,034 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42960
2011-08-09 19:42:44,035 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:44,040 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:44,042 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=40671
2011-08-09 19:42:44,044 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:44,044 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40671: starting
2011-08-09 19:42:44,045 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40671: starting
2011-08-09 19:42:44,050 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40671: starting
2011-08-09 19:42:44,051 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40671: starting
2011-08-09 19:42:44,051 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:42401, storageID=, infoPort=42960, ipcPort=40671)
2011-08-09 19:42:44,056 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:42401 storage DS-2138796229-10.0.62.238-42401-1312911764054
2011-08-09 19:42:44,057 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:42401
2011-08-09 19:42:44,064 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2138796229-10.0.62.238-42401-1312911764054 is assigned to data-node 127.0.0.1:42401
2011-08-09 19:42:44,065 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:42401, storageID=DS-2138796229-10.0.62.238-42401-1312911764054, infoPort=42960, ipcPort=40671)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:44,065 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:44,093 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:44,118 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:42401 0 blocks shortCircuit first report.
2011-08-09 19:42:44,120 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 28 msecs
2011-08-09 19:42:44,120 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:44,122 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:44,127 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:44,167 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:44,267 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40671
2011-08-09 19:42:44,268 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40671: exiting
2011-08-09 19:42:44,268 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40671: exiting
2011-08-09 19:42:44,268 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40671: exiting
2011-08-09 19:42:44,269 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40671
2011-08-09 19:42:44,271 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:44,271 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:42401, storageID=DS-2138796229-10.0.62.238-42401-1312911764054, infoPort=42960, ipcPort=40671):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:44,272 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:44,272 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:44,273 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:42401, storageID=DS-2138796229-10.0.62.238-42401-1312911764054, infoPort=42960, ipcPort=40671):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:44,274 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40671
2011-08-09 19:42:44,274 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:44,275 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:44,275 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:44,277 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:44,337 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:44,438 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53736
2011-08-09 19:42:44,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53736: exiting
2011-08-09 19:42:44,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53736: exiting
2011-08-09 19:42:44,439 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53736: exiting
2011-08-09 19:42:44,440 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53736
2011-08-09 19:42:44,442 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:44,442 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:44,443 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53943, storageID=DS-1149193115-10.0.62.238-53943-1312911763692, infoPort=35311, ipcPort=53736):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:44,723 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:45,443 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:45,444 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53943, storageID=DS-1149193115-10.0.62.238-53943-1312911763692, infoPort=35311, ipcPort=53736):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:45,445 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53736
2011-08-09 19:42:45,445 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:45,446 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:45,446 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:45,448 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:45,480 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:45,582 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:45,646 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:45,647 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:42:45,654 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40940
2011-08-09 19:42:45,660 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40940: exiting
2011-08-09 19:42:45,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40940: exiting
2011-08-09 19:42:45,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40940: exiting
2011-08-09 19:42:45,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 40940: exiting
2011-08-09 19:42:45,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 40940: exiting
2011-08-09 19:42:45,662 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 40940: exiting
2011-08-09 19:42:45,662 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 40940: exiting
2011-08-09 19:42:45,663 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40940
2011-08-09 19:42:45,663 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 40940: exiting
2011-08-09 19:42:45,663 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 40940: exiting
2011-08-09 19:42:45,663 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 40940: exiting
2011-08-09 19:42:45,666 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:45,712 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:45,712 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:45,713 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:45,713 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:45,718 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:45,718 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:45,718 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:45,719 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:45,726 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:45,726 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:45,738 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:45,741 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:45,741 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:45,896 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:45,897 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:45,901 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:45,901 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:45,901 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:45,901 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:45,901 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:45,906 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:45,907 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:45,907 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:45,907 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:45,911 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:45,911 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:45,936 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:45,952 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:45,952 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:45,952 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:45,952 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:45,952 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:45,953 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:45,954 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:45,954 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 48 msecs
2011-08-09 19:42:45,954 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:45,957 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:45,957 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:45,957 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:45,958 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:45,958 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:45,959 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:45,961 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=54594
2011-08-09 19:42:45,962 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:54594
2011-08-09 19:42:45,962 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:45,963 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54594: starting
2011-08-09 19:42:45,986 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54594: starting
2011-08-09 19:42:45,987 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54594: starting
2011-08-09 19:42:45,987 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54594: starting
2011-08-09 19:42:45,987 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 54594: starting
2011-08-09 19:42:45,987 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 54594: starting
2011-08-09 19:42:45,987 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 54594: starting
2011-08-09 19:42:45,988 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 54594: starting
2011-08-09 19:42:45,988 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 54594: starting
2011-08-09 19:42:45,988 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 54594: starting
2011-08-09 19:42:45,989 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 54594: starting
2011-08-09 19:42:45,998 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:45,998 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:45,999 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:45,999 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:46,000 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:46,003 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:46,016 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:46,016 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 53366 webServer.getConnectors()[0].getLocalPort() returned 53366
2011-08-09 19:42:46,017 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 53366
2011-08-09 19:42:46,017 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:46,093 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:53366
2011-08-09 19:42:46,094 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:53366
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:46,102 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:46,102 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:46,119 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:46,119 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:46,352 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:46,353 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40900
2011-08-09 19:42:46,354 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:46,356 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:46,357 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:46,357 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45598 webServer.getConnectors()[0].getLocalPort() returned 45598
2011-08-09 19:42:46,358 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45598
2011-08-09 19:42:46,358 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:46,424 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45598
2011-08-09 19:42:46,425 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:46,430 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:46,432 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=46179
2011-08-09 19:42:46,433 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:46,435 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 46179: starting
2011-08-09 19:42:46,435 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 46179: starting
2011-08-09 19:42:46,435 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40900, storageID=, infoPort=45598, ipcPort=46179)
2011-08-09 19:42:46,436 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 46179: starting
2011-08-09 19:42:46,436 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 46179: starting
2011-08-09 19:42:46,441 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40900 storage DS-1517396355-10.0.62.238-40900-1312911766438
2011-08-09 19:42:46,442 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40900
2011-08-09 19:42:46,448 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1517396355-10.0.62.238-40900-1312911766438 is assigned to data-node 127.0.0.1:40900
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:46,449 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40900, storageID=DS-1517396355-10.0.62.238-40900-1312911766438, infoPort=45598, ipcPort=46179)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:46,464 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:46,471 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:46,472 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40900 0 blocks shortCircuit first report.
2011-08-09 19:42:46,473 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:42:46,474 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:46,475 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:46,475 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:46,476 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:46,491 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:46,499 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:46,743 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:46,744 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 45927
2011-08-09 19:42:46,745 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:46,747 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:46,748 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:46,748 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 46274 webServer.getConnectors()[0].getLocalPort() returned 46274
2011-08-09 19:42:46,749 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 46274
2011-08-09 19:42:46,749 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:46,894 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:46274
2011-08-09 19:42:46,895 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:46,900 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:46,902 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41698
2011-08-09 19:42:46,903 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:46,904 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41698: starting
2011-08-09 19:42:46,905 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41698: starting
2011-08-09 19:42:46,910 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41698: starting
2011-08-09 19:42:46,911 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41698: starting
2011-08-09 19:42:46,911 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:45927, storageID=, infoPort=46274, ipcPort=41698)
2011-08-09 19:42:46,917 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:45927 storage DS-1360507418-10.0.62.238-45927-1312911766914
2011-08-09 19:42:46,918 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:45927
2011-08-09 19:42:46,925 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1360507418-10.0.62.238-45927-1312911766914 is assigned to data-node 127.0.0.1:45927
2011-08-09 19:42:46,926 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:45927, storageID=DS-1360507418-10.0.62.238-45927-1312911766914, infoPort=46274, ipcPort=41698)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:46,928 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:46,933 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:46,935 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:45927 0 blocks shortCircuit first report.
2011-08-09 19:42:46,937 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:42:46,937 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:46,939 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:46,943 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=listStatus	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:42:46,945 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:47,004 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:47,106 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41698
2011-08-09 19:42:47,106 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41698: exiting
2011-08-09 19:42:47,106 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41698: exiting
2011-08-09 19:42:47,106 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41698: exiting
2011-08-09 19:42:47,108 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41698
2011-08-09 19:42:47,109 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:47,109 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:47,110 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:45927, storageID=DS-1360507418-10.0.62.238-45927-1312911766914, infoPort=46274, ipcPort=41698):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:47,940 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:48,110 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:48,111 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:45927, storageID=DS-1360507418-10.0.62.238-45927-1312911766914, infoPort=46274, ipcPort=41698):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:48,111 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41698
2011-08-09 19:42:48,112 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:48,112 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:48,113 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:48,114 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:48,245 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:48,346 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46179
2011-08-09 19:42:48,347 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 46179: exiting
2011-08-09 19:42:48,347 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 46179: exiting
2011-08-09 19:42:48,347 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 46179: exiting
2011-08-09 19:42:48,348 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 46179
2011-08-09 19:42:48,349 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:48,350 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40900, storageID=DS-1517396355-10.0.62.238-40900-1312911766438, infoPort=45598, ipcPort=46179):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:48,350 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:48,478 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:49,350 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:49,351 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40900, storageID=DS-1517396355-10.0.62.238-40900-1312911766438, infoPort=45598, ipcPort=46179):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:49,352 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46179
2011-08-09 19:42:49,352 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:49,353 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:49,353 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:49,354 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:49,470 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:49,571 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:49,572 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:49,573 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:42:49,579 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54594
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54594: exiting
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54594: exiting
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54594: exiting
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 54594: exiting
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 54594: exiting
2011-08-09 19:42:49,580 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 54594: exiting
2011-08-09 19:42:49,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 54594: exiting
2011-08-09 19:42:49,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 54594: exiting
2011-08-09 19:42:49,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 54594: exiting
2011-08-09 19:42:49,581 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 54594: exiting
2011-08-09 19:42:49,583 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54594
2011-08-09 19:42:49,585 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:49,631 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:49,631 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:49,631 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:49,631 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:49,637 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:49,637 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:49,637 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:49,638 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:49,645 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:49,645 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:49,657 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:49,660 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:49,660 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:49,810 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:49,811 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:49,814 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:49,814 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:49,815 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:49,815 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:49,815 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:49,820 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:49,820 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:49,820 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:49,820 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:49,824 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:49,824 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:49,849 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:49,853 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:49,853 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:49,853 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:49,854 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:49,854 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:49,854 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:49,855 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:49,855 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 35 msecs
2011-08-09 19:42:49,855 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:49,858 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:49,859 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:49,859 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:49,859 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:49,859 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:49,860 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:49,863 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=53877
2011-08-09 19:42:49,863 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:53877
2011-08-09 19:42:49,864 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:49,864 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53877: starting
2011-08-09 19:42:49,883 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53877: starting
2011-08-09 19:42:49,884 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53877: starting
2011-08-09 19:42:49,884 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53877: starting
2011-08-09 19:42:49,884 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 53877: starting
2011-08-09 19:42:49,884 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 53877: starting
2011-08-09 19:42:49,885 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 53877: starting
2011-08-09 19:42:49,885 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 53877: starting
2011-08-09 19:42:49,885 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 53877: starting
2011-08-09 19:42:49,885 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 53877: starting
2011-08-09 19:42:49,886 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 53877: starting
2011-08-09 19:42:49,935 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:49,936 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:49,936 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:49,936 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:49,938 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:49,939 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:49,940 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:49,940 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 45667 webServer.getConnectors()[0].getLocalPort() returned 45667
2011-08-09 19:42:49,940 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 45667
2011-08-09 19:42:49,940 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:50,040 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:45667
2011-08-09 19:42:50,041 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:45667
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:50,047 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:50,047 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:50,064 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:50,065 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:50,307 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:50,309 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 45345
2011-08-09 19:42:50,309 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:50,312 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:50,312 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:50,313 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40884 webServer.getConnectors()[0].getLocalPort() returned 40884
2011-08-09 19:42:50,313 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40884
2011-08-09 19:42:50,313 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:50,379 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40884
2011-08-09 19:42:50,380 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:50,386 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:50,388 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=37838
2011-08-09 19:42:50,389 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:50,391 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 37838: starting
2011-08-09 19:42:50,392 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 37838: starting
2011-08-09 19:42:50,392 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:45345, storageID=, infoPort=40884, ipcPort=37838)
2011-08-09 19:42:50,393 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 37838: starting
2011-08-09 19:42:50,393 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 37838: starting
2011-08-09 19:42:50,398 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:45345 storage DS-1469422361-10.0.62.238-45345-1312911770395
2011-08-09 19:42:50,398 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:45345
2011-08-09 19:42:50,404 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1469422361-10.0.62.238-45345-1312911770395 is assigned to data-node 127.0.0.1:45345
2011-08-09 19:42:50,405 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:45345, storageID=DS-1469422361-10.0.62.238-45345-1312911770395, infoPort=40884, ipcPort=37838)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:50,407 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:50,414 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:50,415 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:45345 0 blocks shortCircuit first report.
2011-08-09 19:42:50,416 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:42:50,416 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:50,418 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:50,418 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:50,418 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:50,435 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:50,443 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:50,650 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:50,651 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38023
2011-08-09 19:42:50,651 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:50,654 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:50,655 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:50,655 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44325 webServer.getConnectors()[0].getLocalPort() returned 44325
2011-08-09 19:42:50,655 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44325
2011-08-09 19:42:50,656 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:50,727 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44325
2011-08-09 19:42:50,727 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:50,733 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:50,736 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=33134
2011-08-09 19:42:50,738 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:50,739 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 33134: starting
2011-08-09 19:42:50,762 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 33134: starting
2011-08-09 19:42:50,762 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38023, storageID=, infoPort=44325, ipcPort=33134)
2011-08-09 19:42:50,762 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 33134: starting
2011-08-09 19:42:50,763 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 33134: starting
2011-08-09 19:42:50,769 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38023 storage DS-731225650-10.0.62.238-38023-1312911770766
2011-08-09 19:42:50,769 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38023
2011-08-09 19:42:50,776 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-731225650-10.0.62.238-38023-1312911770766 is assigned to data-node 127.0.0.1:38023
2011-08-09 19:42:50,777 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38023, storageID=DS-731225650-10.0.62.238-38023-1312911770766, infoPort=44325, ipcPort=33134)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:50,778 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:50,783 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:50,787 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38023 0 blocks shortCircuit first report.
2011-08-09 19:42:50,788 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:42:50,788 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:50,809 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:50,820 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/a	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:50,824 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/b	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:50,829 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/c/1	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:50,830 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null
2011-08-09 19:42:50,832 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=listStatus	src=/test/hadoop	dst=null	perm=null
2011-08-09 19:42:50,835 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=listStatus	src=/test/hadoop/a	dst=null	perm=null
2011-08-09 19:42:50,835 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:50,841 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:50,890 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:50,890 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33134
2011-08-09 19:42:50,891 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 33134: exiting
2011-08-09 19:42:50,891 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 33134: exiting
2011-08-09 19:42:50,891 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 33134
2011-08-09 19:42:50,892 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 33134: exiting
2011-08-09 19:42:50,893 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:50,893 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:50,894 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38023, storageID=DS-731225650-10.0.62.238-38023-1312911770766, infoPort=44325, ipcPort=33134):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:51,812 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:51,894 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:51,895 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38023, storageID=DS-731225650-10.0.62.238-38023-1312911770766, infoPort=44325, ipcPort=33134):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:51,895 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33134
2011-08-09 19:42:51,896 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:51,897 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:51,897 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:51,898 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:51,940 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:51,941 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37838
2011-08-09 19:42:51,942 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 37838: exiting
2011-08-09 19:42:51,942 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 37838: exiting
2011-08-09 19:42:51,943 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 37838: exiting
2011-08-09 19:42:51,949 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 37838
2011-08-09 19:42:51,968 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:51,969 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:51,969 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:45345, storageID=DS-1469422361-10.0.62.238-45345-1312911770395, infoPort=40884, ipcPort=37838):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:52,423 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:52,969 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:52,971 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:45345, storageID=DS-1469422361-10.0.62.238-45345-1312911770395, infoPort=40884, ipcPort=37838):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:52,971 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37838
2011-08-09 19:42:52,972 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:52,972 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:52,972 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:52,973 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:52,977 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:53,078 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:53,078 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:53,079 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:3 
2011-08-09 19:42:53,081 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53877
2011-08-09 19:42:53,081 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 53877: exiting
2011-08-09 19:42:53,081 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 53877: exiting
2011-08-09 19:42:53,081 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 53877: exiting
2011-08-09 19:42:53,084 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53877
2011-08-09 19:42:53,084 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 53877: exiting
2011-08-09 19:42:53,082 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53877: exiting
2011-08-09 19:42:53,085 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:53,109 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:53,110 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:53,110 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:53,110 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:53,116 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:53,116 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:53,116 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:53,116 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:53,126 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:53,126 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:53,138 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:53,141 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:53,141 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:53,298 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:53,299 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:53,302 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:53,302 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:53,303 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:53,303 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:53,303 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:53,307 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:53,308 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:53,308 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:53,308 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:53,312 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:53,312 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:53,338 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:53,342 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:53,342 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:53,342 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:53,343 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:53,343 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:53,343 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:53,344 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:53,344 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:42:53,344 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:53,347 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:53,348 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:53,348 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:53,348 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:53,348 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:53,349 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:53,352 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=47586
2011-08-09 19:42:53,352 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:47586
2011-08-09 19:42:53,353 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:53,353 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47586: starting
2011-08-09 19:42:53,354 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47586: starting
2011-08-09 19:42:53,354 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47586: starting
2011-08-09 19:42:53,354 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47586: starting
2011-08-09 19:42:53,354 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 47586: starting
2011-08-09 19:42:53,355 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 47586: starting
2011-08-09 19:42:53,355 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 47586: starting
2011-08-09 19:42:53,355 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 47586: starting
2011-08-09 19:42:53,355 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 47586: starting
2011-08-09 19:42:53,355 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 47586: starting
2011-08-09 19:42:53,356 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 47586: starting
2011-08-09 19:42:53,368 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:53,368 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:53,368 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:53,369 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:53,369 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:53,371 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:53,414 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:53,414 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44070 webServer.getConnectors()[0].getLocalPort() returned 44070
2011-08-09 19:42:53,414 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44070
2011-08-09 19:42:53,414 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:53,469 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44070
2011-08-09 19:42:53,469 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:44070
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:53,476 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:53,476 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:53,492 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:53,492 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:53,736 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:53,737 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44416
2011-08-09 19:42:53,737 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:53,741 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:53,742 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:53,742 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39081 webServer.getConnectors()[0].getLocalPort() returned 39081
2011-08-09 19:42:53,743 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39081
2011-08-09 19:42:53,743 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:53,808 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39081
2011-08-09 19:42:53,809 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:53,814 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:53,816 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=38377
2011-08-09 19:42:53,817 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:53,818 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 38377: starting
2011-08-09 19:42:53,818 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 38377: starting
2011-08-09 19:42:53,819 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44416, storageID=, infoPort=39081, ipcPort=38377)
2011-08-09 19:42:53,819 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 38377: starting
2011-08-09 19:42:53,820 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 38377: starting
2011-08-09 19:42:53,826 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44416 storage DS-811437826-10.0.62.238-44416-1312911773823
2011-08-09 19:42:53,827 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44416
2011-08-09 19:42:53,833 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-811437826-10.0.62.238-44416-1312911773823 is assigned to data-node 127.0.0.1:44416
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:53,834 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44416, storageID=DS-811437826-10.0.62.238-44416-1312911773823, infoPort=39081, ipcPort=38377)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:53,836 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:53,842 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:53,844 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:44416 0 blocks shortCircuit first report.
2011-08-09 19:42:53,846 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:42:53,846 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:53,847 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:53,847 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:53,847 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:53,864 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:53,864 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:54,069 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:54,071 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 44974
2011-08-09 19:42:54,071 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:54,074 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:54,075 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:54,075 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44859 webServer.getConnectors()[0].getLocalPort() returned 44859
2011-08-09 19:42:54,075 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44859
2011-08-09 19:42:54,076 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:54,141 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44859
2011-08-09 19:42:54,143 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:54,147 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:54,150 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34897
2011-08-09 19:42:54,151 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:54,151 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34897: starting
2011-08-09 19:42:54,194 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34897: starting
2011-08-09 19:42:54,194 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34897: starting
2011-08-09 19:42:54,195 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34897: starting
2011-08-09 19:42:54,195 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:44974, storageID=, infoPort=44859, ipcPort=34897)
2011-08-09 19:42:54,201 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:44974 storage DS-86736049-10.0.62.238-44974-1312911774199
2011-08-09 19:42:54,202 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:44974
2011-08-09 19:42:54,209 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-86736049-10.0.62.238-44974-1312911774199 is assigned to data-node 127.0.0.1:44974
2011-08-09 19:42:54,210 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:44974, storageID=DS-86736049-10.0.62.238-44974-1312911774199, infoPort=44859, ipcPort=34897)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:54,211 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:54,216 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:54,217 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:44974 0 blocks shortCircuit first report.
2011-08-09 19:42:54,219 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:42:54,219 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:54,220 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:54,239 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:54,245 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:42:54,252 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-308733913
2011-08-09 19:42:54,260 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:42:54,261 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:54,267 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
Deleted /test/hadoop/file
2011-08-09 19:42:54,269 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:54,273 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:54,330 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:54,331 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34897
2011-08-09 19:42:54,331 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34897: exiting
2011-08-09 19:42:54,332 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34897: exiting
2011-08-09 19:42:54,332 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34897
2011-08-09 19:42:54,331 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34897: exiting
2011-08-09 19:42:54,333 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:54,334 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44974, storageID=DS-86736049-10.0.62.238-44974-1312911774199, infoPort=44859, ipcPort=34897):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:54,334 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:54,335 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:54,335 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44974, storageID=DS-86736049-10.0.62.238-44974-1312911774199, infoPort=44859, ipcPort=34897):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:54,336 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34897
2011-08-09 19:42:54,336 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:54,337 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:54,337 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:54,338 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:54,371 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:54,472 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38377
2011-08-09 19:42:54,473 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 38377
2011-08-09 19:42:54,474 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 38377: exiting
2011-08-09 19:42:54,474 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 38377: exiting
2011-08-09 19:42:54,474 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 38377: exiting
2011-08-09 19:42:54,475 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:54,476 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:44416, storageID=DS-811437826-10.0.62.238-44416-1312911773823, infoPort=39081, ipcPort=38377):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:54,476 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:54,482 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:54,484 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:44416, storageID=DS-811437826-10.0.62.238-44416-1312911773823, infoPort=39081, ipcPort=38377):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:54,485 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38377
2011-08-09 19:42:54,485 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:54,486 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:54,486 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:54,487 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:54,506 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:54,507 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:54,507 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:54,508 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:7 
2011-08-09 19:42:54,510 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47586
2011-08-09 19:42:54,510 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47586: exiting
2011-08-09 19:42:54,510 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47586: exiting
2011-08-09 19:42:54,511 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 47586: exiting
2011-08-09 19:42:54,511 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47586: exiting
2011-08-09 19:42:54,511 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 47586: exiting
2011-08-09 19:42:54,511 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 47586: exiting
2011-08-09 19:42:54,512 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 47586: exiting
2011-08-09 19:42:54,512 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 47586: exiting
2011-08-09 19:42:54,512 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 47586: exiting
2011-08-09 19:42:54,512 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 47586: exiting
2011-08-09 19:42:54,513 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47586
2011-08-09 19:42:54,515 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:54,532 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:54,532 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:54,532 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:54,533 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:54,539 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:54,539 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:54,539 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:54,540 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:54,560 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:54,561 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:54,572 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:54,575 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:54,575 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:54,735 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:54,736 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:54,739 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:54,739 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:54,739 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:54,739 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:54,740 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:54,745 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:54,745 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:54,745 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:54,745 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:54,749 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:54,750 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:54,775 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:54,779 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:54,780 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:54,780 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:54,780 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:54,780 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:54,781 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:54,782 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:54,782 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 38 msecs
2011-08-09 19:42:54,782 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:54,785 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:54,786 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:54,786 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:54,786 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:54,786 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:54,788 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:54,790 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=36812
2011-08-09 19:42:54,791 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:36812
2011-08-09 19:42:54,791 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:54,791 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36812: starting
2011-08-09 19:42:54,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36812: starting
2011-08-09 19:42:54,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36812: starting
2011-08-09 19:42:54,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36812: starting
2011-08-09 19:42:54,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 36812: starting
2011-08-09 19:42:54,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 36812: starting
2011-08-09 19:42:54,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 36812: starting
2011-08-09 19:42:54,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 36812: starting
2011-08-09 19:42:54,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 36812: starting
2011-08-09 19:42:54,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 36812: starting
2011-08-09 19:42:54,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 36812: starting
2011-08-09 19:42:54,803 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:54,803 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:54,804 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:54,804 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:54,846 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:54,848 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:54,849 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:54,849 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59821 webServer.getConnectors()[0].getLocalPort() returned 59821
2011-08-09 19:42:54,849 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59821
2011-08-09 19:42:54,850 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:54,902 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59821
2011-08-09 19:42:54,903 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:59821
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:54,912 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:54,912 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:54,929 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:54,929 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:55,170 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:55,171 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53100
2011-08-09 19:42:55,172 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:55,176 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:55,176 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:55,177 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39434 webServer.getConnectors()[0].getLocalPort() returned 39434
2011-08-09 19:42:55,177 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39434
2011-08-09 19:42:55,177 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:55,255 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39434
2011-08-09 19:42:55,255 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:55,260 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:55,262 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=51837
2011-08-09 19:42:55,264 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:55,264 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51837: starting
2011-08-09 19:42:55,265 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51837: starting
2011-08-09 19:42:55,308 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53100, storageID=, infoPort=39434, ipcPort=51837)
2011-08-09 19:42:55,309 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51837: starting
2011-08-09 19:42:55,310 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51837: starting
2011-08-09 19:42:55,314 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53100 storage DS-64996467-10.0.62.238-53100-1312911775312
2011-08-09 19:42:55,315 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53100
2011-08-09 19:42:55,331 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-64996467-10.0.62.238-53100-1312911775312 is assigned to data-node 127.0.0.1:53100
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:55,332 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53100, storageID=DS-64996467-10.0.62.238-53100-1312911775312, infoPort=39434, ipcPort=51837)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:55,334 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:55,342 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:55,343 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:55,346 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:55,347 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53100 0 blocks shortCircuit first report.
2011-08-09 19:42:55,347 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:42:55,348 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:55,349 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:55,361 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:55,362 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:55,616 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:55,617 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38242
2011-08-09 19:42:55,618 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:55,621 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:55,621 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:55,622 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35961 webServer.getConnectors()[0].getLocalPort() returned 35961
2011-08-09 19:42:55,622 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35961
2011-08-09 19:42:55,622 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:55,759 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35961
2011-08-09 19:42:55,815 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:55,841 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:55,844 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=56460
2011-08-09 19:42:55,847 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:55,847 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 56460: starting
2011-08-09 19:42:55,863 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 56460: starting
2011-08-09 19:42:55,863 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 56460: starting
2011-08-09 19:42:55,864 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 56460: starting
2011-08-09 19:42:55,864 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38242, storageID=, infoPort=35961, ipcPort=56460)
2011-08-09 19:42:55,872 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38242 storage DS-183439329-10.0.62.238-38242-1312911775868
2011-08-09 19:42:55,872 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38242
2011-08-09 19:42:55,879 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-183439329-10.0.62.238-38242-1312911775868 is assigned to data-node 127.0.0.1:38242
2011-08-09 19:42:55,880 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38242, storageID=DS-183439329-10.0.62.238-38242-1312911775868, infoPort=35961, ipcPort=56460)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:55,881 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:55,886 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:55,914 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38242 0 blocks shortCircuit first report.
2011-08-09 19:42:55,915 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 29 msecs
2011-08-09 19:42:55,915 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:55,917 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:55,932 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:55,937 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:42:55,941 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_5135149291522900822_1001
2011-08-09 19:42:55,944 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5135149291522900822_1001 src: /127.0.0.1:35632 dest: /127.0.0.1:53100
2011-08-09 19:42:55,948 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:35632, dest: /127.0.0.1:53100, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_323184214, offset: 0, srvID: DS-64996467-10.0.62.238-53100-1312911775312, blockid: blk_5135149291522900822_1001, duration: 1564392
2011-08-09 19:42:55,949 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5135149291522900822_1001 terminating
2011-08-09 19:42:55,952 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53100 is added to blk_5135149291522900822_1001 size 512
2011-08-09 19:42:55,955 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_323184214
2011-08-09 19:42:55,960 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:42:55,972 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:53100, dest: /127.0.0.1:35633, bytes: 516, op: HDFS_READ, cliID: DFSClient_323184214, offset: 0, srvID: DS-64996467-10.0.62.238-53100-1312911775312, blockid: blk_5135149291522900822_1001, duration: 1379113
2011-08-09 19:42:55,974 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:55,985 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5135149291522900822 is added to invalidSet of 127.0.0.1:53100
2011-08-09 19:42:55,987 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
Deleted /test/hadoop/file
2011-08-09 19:42:55,988 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:55,993 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:56,022 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:56,030 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56460
2011-08-09 19:42:56,031 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 56460: exiting
2011-08-09 19:42:56,031 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 56460: exiting
2011-08-09 19:42:56,031 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 56460
2011-08-09 19:42:56,032 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 56460: exiting
2011-08-09 19:42:56,033 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:56,033 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:56,034 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38242, storageID=DS-183439329-10.0.62.238-38242-1312911775868, infoPort=35961, ipcPort=56460):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:56,919 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:57,034 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:57,035 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38242, storageID=DS-183439329-10.0.62.238-38242-1312911775868, infoPort=35961, ipcPort=56460):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:57,035 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 56460
2011-08-09 19:42:57,036 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:57,036 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:57,037 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:57,037 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:57,040 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:57,041 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51837
2011-08-09 19:42:57,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51837: exiting
2011-08-09 19:42:57,042 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51837: exiting
2011-08-09 19:42:57,043 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51837: exiting
2011-08-09 19:42:57,043 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:57,044 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:57,044 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53100, storageID=DS-64996467-10.0.62.238-53100-1312911775312, infoPort=39434, ipcPort=51837):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:57,044 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51837
2011-08-09 19:42:57,350 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:57,848 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:53100 to delete  blk_5135149291522900822_1001
2011-08-09 19:42:58,044 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:58,044 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53100, storageID=DS-64996467-10.0.62.238-53100-1312911775312, infoPort=39434, ipcPort=51837):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:58,045 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51837
2011-08-09 19:42:58,045 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:58,046 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:58,046 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:58,046 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:42:58,048 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:58,150 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:42:58,150 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:8  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:42:58,151 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:42:58,153 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36812
2011-08-09 19:42:58,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36812: exiting
2011-08-09 19:42:58,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36812: exiting
2011-08-09 19:42:58,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 36812: exiting
2011-08-09 19:42:58,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36812: exiting
2011-08-09 19:42:58,154 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 36812: exiting
2011-08-09 19:42:58,154 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 36812: exiting
2011-08-09 19:42:58,155 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 36812: exiting
2011-08-09 19:42:58,155 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 36812: exiting
2011-08-09 19:42:58,155 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 36812: exiting
2011-08-09 19:42:58,155 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 36812: exiting
2011-08-09 19:42:58,156 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36812
2011-08-09 19:42:58,157 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:58,176 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:58,176 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:58,177 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:58,177 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:58,183 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:58,183 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:58,184 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:58,184 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:58,194 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:58,194 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:58,206 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:42:58,209 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:42:58,209 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:58,363 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:42:58,364 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:42:58,368 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:58,368 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:42:58,368 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:42:58,368 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:42:58,368 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:42:58,375 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:42:58,375 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:42:58,375 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:42:58,375 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:42:58,379 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:42:58,379 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:42:58,405 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:42:58,410 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:42:58,410 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:42:58,410 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:42:58,410 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:42:58,411 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:58,411 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:42:58,412 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:42:58,412 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:42:58,412 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:42:58,415 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:42:58,416 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:42:58,416 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:42:58,416 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:42:58,416 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:42:58,417 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:58,426 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=53516
2011-08-09 19:42:58,427 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:53516
2011-08-09 19:42:58,427 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:58,427 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53516: starting
2011-08-09 19:42:58,468 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53516: starting
2011-08-09 19:42:58,469 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53516: starting
2011-08-09 19:42:58,469 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 53516: starting
2011-08-09 19:42:58,469 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 53516: starting
2011-08-09 19:42:58,469 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 53516: starting
2011-08-09 19:42:58,469 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 53516: starting
2011-08-09 19:42:58,470 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 53516: starting
2011-08-09 19:42:58,470 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 53516: starting
2011-08-09 19:42:58,470 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 53516: starting
2011-08-09 19:42:58,471 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53516: starting
2011-08-09 19:42:58,489 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:42:58,489 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:42:58,490 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:42:58,490 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:42:58,491 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:42:58,493 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:58,493 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:58,494 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 51131 webServer.getConnectors()[0].getLocalPort() returned 51131
2011-08-09 19:42:58,494 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 51131
2011-08-09 19:42:58,494 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:58,590 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:51131
2011-08-09 19:42:58,590 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:51131
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:42:58,602 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:42:58,603 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:58,619 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:42:58,619 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:58,860 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:58,861 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54105
2011-08-09 19:42:58,861 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:58,864 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:58,865 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:58,865 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49421 webServer.getConnectors()[0].getLocalPort() returned 49421
2011-08-09 19:42:58,865 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49421
2011-08-09 19:42:58,865 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:58,931 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49421
2011-08-09 19:42:58,931 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:58,936 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:58,941 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=50544
2011-08-09 19:42:58,942 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:58,942 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50544: starting
2011-08-09 19:42:58,944 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50544: starting
2011-08-09 19:42:58,944 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54105, storageID=, infoPort=49421, ipcPort=50544)
2011-08-09 19:42:58,944 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50544: starting
2011-08-09 19:42:58,945 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50544: starting
2011-08-09 19:42:58,951 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54105 storage DS-1177782421-10.0.62.238-54105-1312911778948
2011-08-09 19:42:58,952 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54105
2011-08-09 19:42:58,960 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1177782421-10.0.62.238-54105-1312911778948 is assigned to data-node 127.0.0.1:54105
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:42:58,961 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54105, storageID=DS-1177782421-10.0.62.238-54105-1312911778948, infoPort=49421, ipcPort=50544)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:42:58,963 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:58,968 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:58,969 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54105 0 blocks shortCircuit first report.
2011-08-09 19:42:58,970 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:42:58,970 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:58,971 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:58,973 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:42:58,973 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:58,989 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:42:58,990 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:42:59,191 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:42:59,193 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 57402
2011-08-09 19:42:59,193 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:42:59,196 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:42:59,197 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:42:59,197 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43609 webServer.getConnectors()[0].getLocalPort() returned 43609
2011-08-09 19:42:59,197 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43609
2011-08-09 19:42:59,197 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:42:59,272 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43609
2011-08-09 19:42:59,272 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:42:59,277 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:42:59,279 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=43964
2011-08-09 19:42:59,280 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:42:59,280 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 43964: starting
2011-08-09 19:42:59,315 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 43964: starting
2011-08-09 19:42:59,316 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 43964: starting
2011-08-09 19:42:59,316 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:57402, storageID=, infoPort=43609, ipcPort=43964)
2011-08-09 19:42:59,317 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 43964: starting
2011-08-09 19:42:59,321 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:57402 storage DS-161273302-10.0.62.238-57402-1312911779319
2011-08-09 19:42:59,322 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:57402
2011-08-09 19:42:59,328 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-161273302-10.0.62.238-57402-1312911779319 is assigned to data-node 127.0.0.1:57402
2011-08-09 19:42:59,329 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:57402, storageID=DS-161273302-10.0.62.238-57402-1312911779319, infoPort=43609, ipcPort=43964)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:59,330 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:42:59,335 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:59,337 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:57402 0 blocks shortCircuit first report.
2011-08-09 19:42:59,340 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 6 msecs
2011-08-09 19:42:59,340 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:42:59,342 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:42:59,356 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:42:59,361 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:42:59,367 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-1983779585495300849_1001
2011-08-09 19:42:59,369 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1983779585495300849_1001 src: /127.0.0.1:50611 dest: /127.0.0.1:54105
2011-08-09 19:42:59,374 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:50611, dest: /127.0.0.1:54105, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_1108035367, offset: 0, srvID: DS-1177782421-10.0.62.238-54105-1312911778948, blockid: blk_-1983779585495300849_1001, duration: 1456522
2011-08-09 19:42:59,374 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1983779585495300849_1001 terminating
2011-08-09 19:42:59,375 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:54105 is added to blk_-1983779585495300849_1001 size 1024
2011-08-09 19:42:59,418 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_1108035367
2011-08-09 19:42:59,423 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:42:59,426 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:54105, dest: /127.0.0.1:50612, bytes: 1032, op: HDFS_READ, cliID: DFSClient_1108035367, offset: 0, srvID: DS-1177782421-10.0.62.238-54105-1312911778948, blockid: blk_-1983779585495300849_1001, duration: 335626
2011-08-09 19:42:59,428 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:59,433 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1983779585495300849 is added to invalidSet of 127.0.0.1:54105
2011-08-09 19:42:59,435 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
Deleted /test/hadoop/file
2011-08-09 19:42:59,441 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:42:59,446 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:42:59,516 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:59,617 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 43964
2011-08-09 19:42:59,618 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 43964: exiting
2011-08-09 19:42:59,618 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 43964: exiting
2011-08-09 19:42:59,618 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 43964: exiting
2011-08-09 19:42:59,619 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 43964
2011-08-09 19:42:59,619 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:59,620 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:57402, storageID=DS-161273302-10.0.62.238-57402-1312911779319, infoPort=43609, ipcPort=43964):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:59,627 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:59,628 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:42:59,628 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:57402, storageID=DS-161273302-10.0.62.238-57402-1312911779319, infoPort=43609, ipcPort=43964):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:42:59,629 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 43964
2011-08-09 19:42:59,629 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:42:59,630 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:42:59,630 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:42:59,631 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:42:59,633 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:42:59,634 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50544
2011-08-09 19:42:59,635 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50544: exiting
2011-08-09 19:42:59,635 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50544: exiting
2011-08-09 19:42:59,635 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50544: exiting
2011-08-09 19:42:59,635 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50544
2011-08-09 19:42:59,636 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:42:59,636 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:42:59,637 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54105, storageID=DS-1177782421-10.0.62.238-54105-1312911778948, infoPort=49421, ipcPort=50544):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:42:59,974 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:00,637 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:00,638 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54105, storageID=DS-1177782421-10.0.62.238-54105-1312911778948, infoPort=49421, ipcPort=50544):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:00,638 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50544
2011-08-09 19:43:00,638 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:00,639 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:00,639 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:00,640 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:00,682 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:00,784 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:00,784 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:00,785 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:11  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:00,787 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53516
2011-08-09 19:43:00,787 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53516: exiting
2011-08-09 19:43:00,788 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53516: exiting
2011-08-09 19:43:00,788 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53516: exiting
2011-08-09 19:43:00,788 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 53516: exiting
2011-08-09 19:43:00,788 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 53516: exiting
2011-08-09 19:43:00,789 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 53516: exiting
2011-08-09 19:43:00,789 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 53516: exiting
2011-08-09 19:43:00,789 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 53516: exiting
2011-08-09 19:43:00,789 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 53516: exiting
2011-08-09 19:43:00,790 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 53516: exiting
2011-08-09 19:43:00,790 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53516
2011-08-09 19:43:00,792 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:00,844 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:00,844 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:00,844 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:00,844 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:00,853 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:00,853 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:00,853 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:00,853 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:00,861 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:00,862 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:00,873 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:00,876 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:00,876 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:01,029 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:01,030 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:01,033 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:01,034 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:01,034 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:01,034 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:01,034 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:01,041 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:01,041 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:01,041 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:01,041 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:01,049 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:01,049 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:01,075 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:01,079 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:01,080 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:01,080 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:01,080 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:01,080 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:01,081 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:01,081 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:01,081 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 40 msecs
2011-08-09 19:43:01,082 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:01,085 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:01,085 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:01,085 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:01,085 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:01,085 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:01,087 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:01,089 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=34878
2011-08-09 19:43:01,090 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:34878
2011-08-09 19:43:01,090 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:01,090 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 34878: starting
2011-08-09 19:43:01,091 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 34878: starting
2011-08-09 19:43:01,092 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 34878: starting
2011-08-09 19:43:01,092 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 34878: starting
2011-08-09 19:43:01,092 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 34878: starting
2011-08-09 19:43:01,092 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 34878: starting
2011-08-09 19:43:01,100 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:01,100 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:01,100 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:01,101 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:01,102 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:01,103 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:01,104 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:01,104 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 52561 webServer.getConnectors()[0].getLocalPort() returned 52561
2011-08-09 19:43:01,104 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 52561
2011-08-09 19:43:01,104 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:01,165 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:52561
2011-08-09 19:43:01,166 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:52561
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:01,173 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:01,173 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:01,189 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:01,190 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:01,441 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:01,442 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 58844
2011-08-09 19:43:01,442 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:01,445 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:01,446 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:01,446 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 51456 webServer.getConnectors()[0].getLocalPort() returned 51456
2011-08-09 19:43:01,446 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 51456
2011-08-09 19:43:01,446 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:01,519 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:51456
2011-08-09 19:43:01,520 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:01,524 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:01,527 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36037
2011-08-09 19:43:01,528 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:01,528 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36037: starting
2011-08-09 19:43:01,547 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36037: starting
2011-08-09 19:43:01,548 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:58844, storageID=, infoPort=51456, ipcPort=36037)
2011-08-09 19:43:01,548 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36037: starting
2011-08-09 19:43:01,548 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36037: starting
2011-08-09 19:43:01,555 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:58844 storage DS-82603683-10.0.62.238-58844-1312911781552
2011-08-09 19:43:01,556 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:58844
2011-08-09 19:43:01,562 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-82603683-10.0.62.238-58844-1312911781552 is assigned to data-node 127.0.0.1:58844
2011-08-09 19:43:01,563 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-82603683-10.0.62.238-58844-1312911781552, infoPort=51456, ipcPort=36037)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:01,564 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:01,570 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:01,617 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:01,618 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:01,618 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:58844 0 blocks shortCircuit first report.
2011-08-09 19:43:01,619 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 49 msecs
2011-08-09 19:43:01,620 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:01,624 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:01,637 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:01,637 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:01,912 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:01,913 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48249
2011-08-09 19:43:01,914 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:01,916 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:01,917 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:01,917 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43798 webServer.getConnectors()[0].getLocalPort() returned 43798
2011-08-09 19:43:01,918 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43798
2011-08-09 19:43:01,918 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:02,025 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43798
2011-08-09 19:43:02,025 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:02,030 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:02,041 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36586
2011-08-09 19:43:02,042 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:02,042 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36586: starting
2011-08-09 19:43:02,044 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36586: starting
2011-08-09 19:43:02,044 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48249, storageID=, infoPort=43798, ipcPort=36586)
2011-08-09 19:43:02,045 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36586: starting
2011-08-09 19:43:02,045 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36586: starting
2011-08-09 19:43:02,050 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48249 storage DS-349727142-10.0.62.238-48249-1312911782047
2011-08-09 19:43:02,050 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48249
2011-08-09 19:43:02,057 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-349727142-10.0.62.238-48249-1312911782047 is assigned to data-node 127.0.0.1:48249
2011-08-09 19:43:02,058 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48249, storageID=DS-349727142-10.0.62.238-48249-1312911782047, infoPort=43798, ipcPort=36586)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:02,059 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:02,065 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:02,066 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48249 0 blocks shortCircuit first report.
2011-08-09 19:43:02,067 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:02,067 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:02,068 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:02,084 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:02,089 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:02,095 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_8826144765432526859_1001
2011-08-09 19:43:02,097 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8826144765432526859_1001 src: /127.0.0.1:46888 dest: /127.0.0.1:48249
2011-08-09 19:43:02,102 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:46888, dest: /127.0.0.1:48249, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_-1736966964, offset: 0, srvID: DS-349727142-10.0.62.238-48249-1312911782047, blockid: blk_8826144765432526859_1001, duration: 1359272
2011-08-09 19:43:02,103 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48249 is added to blk_8826144765432526859_1001 size 1024
2011-08-09 19:43:02,103 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_8826144765432526859_1001 terminating
2011-08-09 19:43:02,149 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-7091949485082483624_1001
2011-08-09 19:43:02,150 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7091949485082483624_1001 src: /127.0.0.1:46889 dest: /127.0.0.1:48249
2011-08-09 19:43:02,154 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:46889, dest: /127.0.0.1:48249, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_-1736966964, offset: 0, srvID: DS-349727142-10.0.62.238-48249-1312911782047, blockid: blk_-7091949485082483624_1001, duration: 1698251
2011-08-09 19:43:02,155 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:48249 is added to blk_-7091949485082483624_1001 size 512
2011-08-09 19:43:02,155 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7091949485082483624_1001 terminating
2011-08-09 19:43:02,159 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-1736966964
2011-08-09 19:43:02,164 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:43:02,167 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:48249, dest: /127.0.0.1:46890, bytes: 1032, op: HDFS_READ, cliID: DFSClient_-1736966964, offset: 0, srvID: DS-349727142-10.0.62.238-48249-1312911782047, blockid: blk_8826144765432526859_1001, duration: 375867
2011-08-09 19:43:02,171 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:02,173 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:48249, dest: /127.0.0.1:46891, bytes: 516, op: HDFS_READ, cliID: DFSClient_-1736966964, offset: 0, srvID: DS-349727142-10.0.62.238-48249-1312911782047, blockid: blk_-7091949485082483624_1001, duration: 3856765
2011-08-09 19:43:02,177 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_8826144765432526859 is added to invalidSet of 127.0.0.1:48249
2011-08-09 19:43:02,177 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7091949485082483624 is added to invalidSet of 127.0.0.1:48249
2011-08-09 19:43:02,189 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
Deleted /test/hadoop/file
2011-08-09 19:43:02,191 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:02,195 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:02,224 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:02,325 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36586
2011-08-09 19:43:02,325 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36586: exiting
2011-08-09 19:43:02,326 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36586: exiting
2011-08-09 19:43:02,326 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36586: exiting
2011-08-09 19:43:02,326 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36586
2011-08-09 19:43:02,327 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:02,328 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:02,328 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48249, storageID=DS-349727142-10.0.62.238-48249-1312911782047, infoPort=43798, ipcPort=36586):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:03,069 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:03,328 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:03,329 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48249, storageID=DS-349727142-10.0.62.238-48249-1312911782047, infoPort=43798, ipcPort=36586):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:03,329 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36586
2011-08-09 19:43:03,330 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:03,330 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:03,330 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:03,331 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:03,348 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:03,449 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36037
2011-08-09 19:43:03,449 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36037: exiting
2011-08-09 19:43:03,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36037: exiting
2011-08-09 19:43:03,450 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36037: exiting
2011-08-09 19:43:03,451 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36037
2011-08-09 19:43:03,452 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:03,452 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-82603683-10.0.62.238-58844-1312911781552, infoPort=51456, ipcPort=36037):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:03,452 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:03,452 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:03,453 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:58844, storageID=DS-82603683-10.0.62.238-58844-1312911781552, infoPort=51456, ipcPort=36037):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:03,454 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36037
2011-08-09 19:43:03,454 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:03,455 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:03,455 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:03,456 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:03,522 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:03,623 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:03,624 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:03,624 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:13  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:03,626 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34878
2011-08-09 19:43:03,627 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34878: exiting
2011-08-09 19:43:03,627 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 34878: exiting
2011-08-09 19:43:03,627 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 34878: exiting
2011-08-09 19:43:03,627 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 34878: exiting
2011-08-09 19:43:03,627 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34878: exiting
2011-08-09 19:43:03,628 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 34878: exiting
2011-08-09 19:43:03,628 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34878: exiting
2011-08-09 19:43:03,628 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 34878: exiting
2011-08-09 19:43:03,629 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34878
2011-08-09 19:43:03,629 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 34878: exiting
2011-08-09 19:43:03,629 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 34878: exiting
2011-08-09 19:43:03,630 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:03,647 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:03,647 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:03,647 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:03,647 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:03,653 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:03,653 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:03,653 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:03,653 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:03,661 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:03,662 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:03,674 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:03,676 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:03,676 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:03,834 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:03,835 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:03,839 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:03,839 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:03,839 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:03,839 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:03,839 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:03,845 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:03,845 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:03,845 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:03,845 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:03,849 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:03,850 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:03,875 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:03,879 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:03,879 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:03,879 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:03,879 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:03,879 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:03,880 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:03,881 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:03,881 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:03,881 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:03,884 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:03,884 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:03,884 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:03,885 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:03,885 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:03,886 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:03,889 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=58514
2011-08-09 19:43:03,889 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:58514
2011-08-09 19:43:03,890 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:03,891 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 58514: starting
2011-08-09 19:43:03,891 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 58514: starting
2011-08-09 19:43:03,891 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 58514: starting
2011-08-09 19:43:03,892 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 58514: starting
2011-08-09 19:43:03,892 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 58514: starting
2011-08-09 19:43:03,892 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 58514: starting
2011-08-09 19:43:03,892 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 58514: starting
2011-08-09 19:43:03,892 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 58514: starting
2011-08-09 19:43:03,893 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 58514: starting
2011-08-09 19:43:03,893 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 58514: starting
2011-08-09 19:43:03,893 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 58514: starting
2011-08-09 19:43:03,923 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:03,924 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:03,924 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:03,924 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:03,925 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:03,927 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:03,927 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:03,928 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44859 webServer.getConnectors()[0].getLocalPort() returned 44859
2011-08-09 19:43:03,928 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44859
2011-08-09 19:43:03,928 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:03,981 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44859
2011-08-09 19:43:03,982 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:44859
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:03,989 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:03,989 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:04,006 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:04,007 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:04,224 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:04,226 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 59212
2011-08-09 19:43:04,226 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:04,229 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:04,230 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:04,230 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44981 webServer.getConnectors()[0].getLocalPort() returned 44981
2011-08-09 19:43:04,230 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44981
2011-08-09 19:43:04,231 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:04,406 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44981
2011-08-09 19:43:04,407 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:04,414 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:04,450 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=48487
2011-08-09 19:43:04,451 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:04,453 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48487: starting
2011-08-09 19:43:04,454 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48487: starting
2011-08-09 19:43:04,454 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48487: starting
2011-08-09 19:43:04,474 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:59212, storageID=, infoPort=44981, ipcPort=48487)
2011-08-09 19:43:04,477 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48487: starting
2011-08-09 19:43:04,482 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:59212 storage DS-1213824304-10.0.62.238-59212-1312911784478
2011-08-09 19:43:04,483 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:59212
2011-08-09 19:43:04,492 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1213824304-10.0.62.238-59212-1312911784478 is assigned to data-node 127.0.0.1:59212
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:04,495 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:59212, storageID=DS-1213824304-10.0.62.238-59212-1312911784478, infoPort=44981, ipcPort=48487)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:04,496 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:04,523 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:04,525 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:04,526 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:59212 0 blocks shortCircuit first report.
2011-08-09 19:43:04,526 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:04,526 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 5 msecs
2011-08-09 19:43:04,527 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:04,535 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:04,547 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:04,548 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:04,852 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:04,854 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40761
2011-08-09 19:43:04,854 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:04,857 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:04,857 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:04,858 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 55590 webServer.getConnectors()[0].getLocalPort() returned 55590
2011-08-09 19:43:04,858 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 55590
2011-08-09 19:43:04,858 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:04,959 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:55590
2011-08-09 19:43:04,960 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:04,973 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:04,976 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=53173
2011-08-09 19:43:04,977 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:04,978 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53173: starting
2011-08-09 19:43:04,981 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53173: starting
2011-08-09 19:43:04,981 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40761, storageID=, infoPort=55590, ipcPort=53173)
2011-08-09 19:43:04,982 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53173: starting
2011-08-09 19:43:04,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53173: starting
2011-08-09 19:43:04,988 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40761 storage DS-642060906-10.0.62.238-40761-1312911784986
2011-08-09 19:43:04,989 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40761
2011-08-09 19:43:04,995 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-642060906-10.0.62.238-40761-1312911784986 is assigned to data-node 127.0.0.1:40761
2011-08-09 19:43:04,996 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40761, storageID=DS-642060906-10.0.62.238-40761-1312911784986, infoPort=55590, ipcPort=53173)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:04,997 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:05,002 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:05,004 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40761 0 blocks shortCircuit first report.
2011-08-09 19:43:05,005 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:05,005 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:05,051 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:05,068 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:05,073 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:05,077 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-7335890723629491861_1001
2011-08-09 19:43:05,080 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7335890723629491861_1001 src: /127.0.0.1:42888 dest: /127.0.0.1:59212
2011-08-09 19:43:05,084 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:42888, dest: /127.0.0.1:59212, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_605281335, offset: 0, srvID: DS-1213824304-10.0.62.238-59212-1312911784478, blockid: blk_-7335890723629491861_1001, duration: 1527504
2011-08-09 19:43:05,084 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7335890723629491861_1001 terminating
2011-08-09 19:43:05,087 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:59212 is added to blk_-7335890723629491861_1001 size 1024
2011-08-09 19:43:05,088 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_286366660850642013_1001
2011-08-09 19:43:05,090 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_286366660850642013_1001 src: /127.0.0.1:42889 dest: /127.0.0.1:59212
2011-08-09 19:43:05,094 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:42889, dest: /127.0.0.1:59212, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_605281335, offset: 0, srvID: DS-1213824304-10.0.62.238-59212-1312911784478, blockid: blk_286366660850642013_1001, duration: 1482231
2011-08-09 19:43:05,094 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_286366660850642013_1001 terminating
2011-08-09 19:43:05,095 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:59212 is added to blk_286366660850642013_1001 size 1024
2011-08-09 19:43:05,140 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_605281335
2011-08-09 19:43:05,145 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:43:05,148 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:59212, dest: /127.0.0.1:42890, bytes: 1032, op: HDFS_READ, cliID: DFSClient_605281335, offset: 0, srvID: DS-1213824304-10.0.62.238-59212-1312911784478, blockid: blk_-7335890723629491861_1001, duration: 409123
2011-08-09 19:43:05,153 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:05,156 INFO  DataNode.clienttrace (BlockSender.java:sendBlock(441)) - src: /127.0.0.1:59212, dest: /127.0.0.1:42891, bytes: 1032, op: HDFS_READ, cliID: DFSClient_605281335, offset: 0, srvID: DS-1213824304-10.0.62.238-59212-1312911784478, blockid: blk_286366660850642013_1001, duration: 4530811
2011-08-09 19:43:05,158 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7335890723629491861 is added to invalidSet of 127.0.0.1:59212
2011-08-09 19:43:05,165 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_286366660850642013 is added to invalidSet of 127.0.0.1:59212
2011-08-09 19:43:05,167 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
Deleted /test/hadoop/file
2011-08-09 19:43:05,169 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:05,173 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:05,282 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:05,382 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53173
2011-08-09 19:43:05,383 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53173: exiting
2011-08-09 19:43:05,383 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53173: exiting
2011-08-09 19:43:05,383 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53173: exiting
2011-08-09 19:43:05,383 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53173
2011-08-09 19:43:05,385 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:05,385 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40761, storageID=DS-642060906-10.0.62.238-40761-1312911784986, infoPort=55590, ipcPort=53173):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:05,385 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:05,386 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:05,386 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40761, storageID=DS-642060906-10.0.62.238-40761-1312911784986, infoPort=55590, ipcPort=53173):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:05,387 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53173
2011-08-09 19:43:05,387 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:05,388 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:05,388 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:05,388 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:05,522 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:05,523 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48487
2011-08-09 19:43:05,524 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48487: exiting
2011-08-09 19:43:05,524 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 48487
2011-08-09 19:43:05,524 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48487: exiting
2011-08-09 19:43:05,524 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48487: exiting
2011-08-09 19:43:05,525 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:05,525 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:05,525 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:59212, storageID=DS-1213824304-10.0.62.238-59212-1312911784478, infoPort=44981, ipcPort=48487):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:05,536 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:06,525 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:06,527 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:59212, storageID=DS-1213824304-10.0.62.238-59212-1312911784478, infoPort=44981, ipcPort=48487):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:06,527 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48487
2011-08-09 19:43:06,528 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:06,528 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:06,529 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:06,530 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:06,616 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:06,617 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:06,618 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:06,618 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 7 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:11  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:06,620 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58514
2011-08-09 19:43:06,620 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 58514: exiting
2011-08-09 19:43:06,620 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 58514: exiting
2011-08-09 19:43:06,621 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 58514: exiting
2011-08-09 19:43:06,620 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 58514: exiting
2011-08-09 19:43:06,622 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 58514: exiting
2011-08-09 19:43:06,624 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:06,624 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 58514
2011-08-09 19:43:06,640 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:06,640 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:06,640 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:06,640 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:06,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:06,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:06,646 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:06,646 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:06,661 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:06,662 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:06,679 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:06,682 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:06,682 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:06,840 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:06,841 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:06,845 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:06,845 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:06,845 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:06,845 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:06,845 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:06,850 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:06,851 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:06,851 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:06,851 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:06,854 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:06,855 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:06,881 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:06,885 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:06,886 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:06,886 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:06,886 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:06,886 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:06,887 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:06,887 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:06,888 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 38 msecs
2011-08-09 19:43:06,888 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:06,891 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:06,891 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:06,891 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:06,891 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:06,892 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:06,893 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:06,895 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=54422
2011-08-09 19:43:06,896 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:54422
2011-08-09 19:43:06,896 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:06,897 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54422: starting
2011-08-09 19:43:06,897 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54422: starting
2011-08-09 19:43:06,898 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54422: starting
2011-08-09 19:43:06,898 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54422: starting
2011-08-09 19:43:06,898 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 54422: starting
2011-08-09 19:43:06,898 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 54422: starting
2011-08-09 19:43:06,898 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 54422: starting
2011-08-09 19:43:06,899 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 54422: starting
2011-08-09 19:43:06,899 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 54422: starting
2011-08-09 19:43:06,899 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 54422: starting
2011-08-09 19:43:06,900 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 54422: starting
2011-08-09 19:43:06,911 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:06,912 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:06,912 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:06,912 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:06,954 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:06,956 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:06,956 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:06,956 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43001 webServer.getConnectors()[0].getLocalPort() returned 43001
2011-08-09 19:43:06,957 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43001
2011-08-09 19:43:06,957 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:07,052 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43001
2011-08-09 19:43:07,052 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:43001
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:07,059 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:07,060 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:07,076 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:07,076 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:07,278 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:07,279 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 43242
2011-08-09 19:43:07,280 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:07,282 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:07,283 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:07,283 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 37239 webServer.getConnectors()[0].getLocalPort() returned 37239
2011-08-09 19:43:07,284 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 37239
2011-08-09 19:43:07,284 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:07,385 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:37239
2011-08-09 19:43:07,385 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:07,391 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:07,443 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34097
2011-08-09 19:43:07,443 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:07,485 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34097: starting
2011-08-09 19:43:07,485 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34097: starting
2011-08-09 19:43:07,486 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:43242, storageID=, infoPort=37239, ipcPort=34097)
2011-08-09 19:43:07,487 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34097: starting
2011-08-09 19:43:07,487 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34097: starting
2011-08-09 19:43:07,494 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:43242 storage DS-1737071747-10.0.62.238-43242-1312911787491
2011-08-09 19:43:07,495 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:43242
2011-08-09 19:43:07,500 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1737071747-10.0.62.238-43242-1312911787491 is assigned to data-node 127.0.0.1:43242
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:07,502 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:43242, storageID=DS-1737071747-10.0.62.238-43242-1312911787491, infoPort=37239, ipcPort=34097)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:07,503 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:07,508 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:07,509 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:43242 0 blocks shortCircuit first report.
2011-08-09 19:43:07,510 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:07,510 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:07,512 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:07,513 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:07,513 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:07,529 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:07,530 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:07,754 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:07,755 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 57767
2011-08-09 19:43:07,756 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:07,758 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:07,759 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:07,759 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59287 webServer.getConnectors()[0].getLocalPort() returned 59287
2011-08-09 19:43:07,761 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59287
2011-08-09 19:43:07,761 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:07,871 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59287
2011-08-09 19:43:07,871 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:07,876 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:07,879 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60458
2011-08-09 19:43:07,880 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:07,881 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60458: starting
2011-08-09 19:43:07,903 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60458: starting
2011-08-09 19:43:07,903 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:57767, storageID=, infoPort=59287, ipcPort=60458)
2011-08-09 19:43:07,904 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60458: starting
2011-08-09 19:43:07,904 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60458: starting
2011-08-09 19:43:07,909 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:57767 storage DS-469254060-10.0.62.238-57767-1312911787907
2011-08-09 19:43:07,910 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:57767
2011-08-09 19:43:07,916 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-469254060-10.0.62.238-57767-1312911787907 is assigned to data-node 127.0.0.1:57767
2011-08-09 19:43:07,917 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:57767, storageID=DS-469254060-10.0.62.238-57767-1312911787907, infoPort=59287, ipcPort=60458)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:07,918 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:07,923 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:07,924 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:57767 0 blocks shortCircuit first report.
2011-08-09 19:43:07,924 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:07,924 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:07,926 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:07,942 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:07,947 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:07,953 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_8231079263206015358_1001
2011-08-09 19:43:07,956 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8231079263206015358_1001 src: /127.0.0.1:43978 dest: /127.0.0.1:43242
2011-08-09 19:43:07,958 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_8231079263206015358_1001 src: /127.0.0.1:39936 dest: /127.0.0.1:57767
2011-08-09 19:43:07,964 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:57767 is added to blk_8231079263206015358_1001 size 2048
2011-08-09 19:43:07,965 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:39936, dest: /127.0.0.1:57767, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1461006855, offset: 0, srvID: DS-469254060-10.0.62.238-57767-1312911787907, blockid: blk_8231079263206015358_1001, duration: 595799
2011-08-09 19:43:07,967 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:43978, dest: /127.0.0.1:43242, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1461006855, offset: 0, srvID: DS-1737071747-10.0.62.238-43242-1312911787491, blockid: blk_8231079263206015358_1001, duration: 4559874
2011-08-09 19:43:07,967 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:43242 is added to blk_8231079263206015358_1001 size 2048
2011-08-09 19:43:07,968 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_8231079263206015358_1001 terminating
2011-08-09 19:43:07,983 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_8231079263206015358_1001 terminating
2011-08-09 19:43:07,987 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-1461006855
2011-08-09 19:43:07,992 WARN  hdfs.StateChange (FSNamesystem.java:startFileInternal(1590)) - DIR* NameSystem.startFile: failed to create file /test/hadoop/file on client 127.0.0.1 either because the filename is invalid or the file exists
2011-08-09 19:43:07,993 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 3 on 54422, call create(/test/hadoop/file, rwxr-xr-x, DFSClient_-1461006855, false, 2, 67108864) from 127.0.0.1:55705: error: java.io.IOException: failed to create file /test/hadoop/file on client 127.0.0.1 either because the filename is invalid or the file exists
java.io.IOException: failed to create file /test/hadoop/file on client 127.0.0.1 either because the filename is invalid or the file exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1541)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:509)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:43:07,996 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_8231079263206015358 is added to invalidSet of 127.0.0.1:57767
2011-08-09 19:43:07,996 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_8231079263206015358 is added to invalidSet of 127.0.0.1:43242
2011-08-09 19:43:07,998 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:43:08,000 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:08,012 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_6902628424414001778_1002
2011-08-09 19:43:08,028 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6902628424414001778_1002 src: /127.0.0.1:43980 dest: /127.0.0.1:43242
2011-08-09 19:43:08,029 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_6902628424414001778_1002 src: /127.0.0.1:39938 dest: /127.0.0.1:57767
2011-08-09 19:43:08,033 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:39938, dest: /127.0.0.1:57767, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1461006855, offset: 0, srvID: DS-469254060-10.0.62.238-57767-1312911787907, blockid: blk_6902628424414001778_1002, duration: 1745478
2011-08-09 19:43:08,033 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_6902628424414001778_1002 terminating
2011-08-09 19:43:08,034 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:57767 is added to blk_6902628424414001778_1002 size 2048
2011-08-09 19:43:08,035 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:43980, dest: /127.0.0.1:43242, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1461006855, offset: 0, srvID: DS-1737071747-10.0.62.238-43242-1312911787491, blockid: blk_6902628424414001778_1002, duration: 3137725
2011-08-09 19:43:08,051 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_6902628424414001778_1002 terminating
2011-08-09 19:43:08,051 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:43242 is added to blk_6902628424414001778_1002 size 2048
2011-08-09 19:43:08,083 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-1461006855
2011-08-09 19:43:08,087 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:08,089 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_6902628424414001778 is added to invalidSet of 127.0.0.1:57767
2011-08-09 19:43:08,089 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_6902628424414001778 is added to invalidSet of 127.0.0.1:43242
2011-08-09 19:43:08,091 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:08,141 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:08,142 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60458
2011-08-09 19:43:08,142 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60458: exiting
2011-08-09 19:43:08,142 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60458: exiting
2011-08-09 19:43:08,142 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60458: exiting
2011-08-09 19:43:08,143 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60458
2011-08-09 19:43:08,143 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:08,144 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:08,144 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:57767, storageID=DS-469254060-10.0.62.238-57767-1312911787907, infoPort=59287, ipcPort=60458):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:08,929 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:09,144 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:09,145 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:57767, storageID=DS-469254060-10.0.62.238-57767-1312911787907, infoPort=59287, ipcPort=60458):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:09,146 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60458
2011-08-09 19:43:09,146 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:09,146 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:09,147 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:09,147 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:09,152 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:09,153 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34097
2011-08-09 19:43:09,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34097: exiting
2011-08-09 19:43:09,153 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34097: exiting
2011-08-09 19:43:09,155 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34097
2011-08-09 19:43:09,155 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34097: exiting
2011-08-09 19:43:09,156 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:43242, storageID=DS-1737071747-10.0.62.238-43242-1312911787491, infoPort=37239, ipcPort=34097):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:09,156 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:09,156 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:09,157 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:09,157 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:43242, storageID=DS-1737071747-10.0.62.238-43242-1312911787491, infoPort=37239, ipcPort=34097):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:09,157 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34097
2011-08-09 19:43:09,157 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:09,158 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:09,158 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:09,159 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:09,172 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:09,273 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:09,273 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:09,274 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 10 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:43:09,276 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54422
2011-08-09 19:43:09,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54422: exiting
2011-08-09 19:43:09,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54422: exiting
2011-08-09 19:43:09,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54422: exiting
2011-08-09 19:43:09,276 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 54422: exiting
2011-08-09 19:43:09,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 54422: exiting
2011-08-09 19:43:09,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 54422: exiting
2011-08-09 19:43:09,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 54422: exiting
2011-08-09 19:43:09,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 54422: exiting
2011-08-09 19:43:09,277 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 54422: exiting
2011-08-09 19:43:09,278 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54422
2011-08-09 19:43:09,279 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 54422: exiting
2011-08-09 19:43:09,280 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:09,296 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:09,296 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:09,296 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:09,296 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:09,358 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:09,360 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:09,360 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:09,362 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:09,391 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:09,392 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:09,403 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:09,406 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:09,406 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:09,569 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:09,570 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:09,575 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:09,575 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:09,575 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:09,575 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:09,575 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:09,580 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:09,580 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:09,581 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:09,581 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:09,588 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:09,589 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:09,614 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:09,621 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:09,621 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:09,621 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:09,621 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:09,622 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:09,622 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:09,623 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:09,623 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 43 msecs
2011-08-09 19:43:09,623 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:09,626 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:09,626 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:09,627 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:09,627 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:09,627 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:09,628 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:09,631 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=38879
2011-08-09 19:43:09,631 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:38879
2011-08-09 19:43:09,632 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:09,632 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 38879: starting
2011-08-09 19:43:09,674 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 38879: starting
2011-08-09 19:43:09,674 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 38879: starting
2011-08-09 19:43:09,674 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 38879: starting
2011-08-09 19:43:09,675 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 38879: starting
2011-08-09 19:43:09,676 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 38879: starting
2011-08-09 19:43:09,726 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:09,726 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:09,726 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:09,727 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:09,727 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:09,729 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:09,730 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:09,730 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 55913 webServer.getConnectors()[0].getLocalPort() returned 55913
2011-08-09 19:43:09,730 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 55913
2011-08-09 19:43:09,730 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:09,856 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:55913
2011-08-09 19:43:09,886 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:55913
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:09,894 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:09,895 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:09,911 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:09,911 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:10,114 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:10,115 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 42318
2011-08-09 19:43:10,116 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:10,118 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:10,119 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:10,119 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43498 webServer.getConnectors()[0].getLocalPort() returned 43498
2011-08-09 19:43:10,120 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43498
2011-08-09 19:43:10,120 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:10,181 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43498
2011-08-09 19:43:10,181 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:10,189 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:10,191 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=55583
2011-08-09 19:43:10,193 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:10,193 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 55583: starting
2011-08-09 19:43:10,194 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 55583: starting
2011-08-09 19:43:10,216 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:42318, storageID=, infoPort=43498, ipcPort=55583)
2011-08-09 19:43:10,216 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 55583: starting
2011-08-09 19:43:10,216 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 55583: starting
2011-08-09 19:43:10,222 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:42318 storage DS-1199876856-10.0.62.238-42318-1312911790219
2011-08-09 19:43:10,222 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:42318
2011-08-09 19:43:10,228 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1199876856-10.0.62.238-42318-1312911790219 is assigned to data-node 127.0.0.1:42318
2011-08-09 19:43:10,229 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:42318, storageID=DS-1199876856-10.0.62.238-42318-1312911790219, infoPort=43498, ipcPort=55583)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:10,231 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:10,236 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:10,238 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:42318 0 blocks shortCircuit first report.
2011-08-09 19:43:10,239 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:10,239 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:10,242 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:10,242 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:10,242 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:10,259 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:10,260 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:10,464 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:10,465 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37877
2011-08-09 19:43:10,465 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:10,468 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:10,469 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:10,469 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39832 webServer.getConnectors()[0].getLocalPort() returned 39832
2011-08-09 19:43:10,470 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39832
2011-08-09 19:43:10,470 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:10,534 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39832
2011-08-09 19:43:10,536 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:10,541 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:10,544 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=40947
2011-08-09 19:43:10,545 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:10,568 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40947: starting
2011-08-09 19:43:10,568 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40947: starting
2011-08-09 19:43:10,568 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37877, storageID=, infoPort=39832, ipcPort=40947)
2011-08-09 19:43:10,569 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40947: starting
2011-08-09 19:43:10,570 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40947: starting
2011-08-09 19:43:10,576 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37877 storage DS-1047970119-10.0.62.238-37877-1312911790573
2011-08-09 19:43:10,576 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37877
2011-08-09 19:43:10,583 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1047970119-10.0.62.238-37877-1312911790573 is assigned to data-node 127.0.0.1:37877
2011-08-09 19:43:10,584 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37877, storageID=DS-1047970119-10.0.62.238-37877-1312911790573, infoPort=39832, ipcPort=40947)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:10,585 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:10,588 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:10,589 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37877 0 blocks shortCircuit first report.
2011-08-09 19:43:10,590 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:10,590 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:10,591 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:10,620 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:10,625 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-1645037372820801681_1001
2011-08-09 19:43:10,627 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1645037372820801681_1001 src: /127.0.0.1:37672 dest: /127.0.0.1:42318
2011-08-09 19:43:10,631 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1645037372820801681_1001 src: /127.0.0.1:48388 dest: /127.0.0.1:37877
2011-08-09 19:43:10,637 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:37877 is added to blk_-1645037372820801681_1001 size 2048
2011-08-09 19:43:10,638 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:48388, dest: /127.0.0.1:37877, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-706601086, offset: 0, srvID: DS-1047970119-10.0.62.238-37877-1312911790573, blockid: blk_-1645037372820801681_1001, duration: 708978
2011-08-09 19:43:10,639 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1645037372820801681_1001 terminating
2011-08-09 19:43:10,640 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:37672, dest: /127.0.0.1:42318, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-706601086, offset: 0, srvID: DS-1199876856-10.0.62.238-42318-1312911790219, blockid: blk_-1645037372820801681_1001, duration: 5882535
2011-08-09 19:43:10,641 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-1645037372820801681_1001 terminating
2011-08-09 19:43:10,683 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:42318 is added to blk_-1645037372820801681_1001 size 2048
2011-08-09 19:43:10,685 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-706601086
2011-08-09 19:43:10,689 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:10,692 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1645037372820801681 is added to invalidSet of 127.0.0.1:37877
2011-08-09 19:43:10,692 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1645037372820801681 is added to invalidSet of 127.0.0.1:42318
2011-08-09 19:43:10,694 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:10,805 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:10,806 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40947
2011-08-09 19:43:10,806 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40947: exiting
2011-08-09 19:43:10,806 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40947: exiting
2011-08-09 19:43:10,806 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40947: exiting
2011-08-09 19:43:10,807 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40947
2011-08-09 19:43:10,808 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:10,808 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:10,808 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37877, storageID=DS-1047970119-10.0.62.238-37877-1312911790573, infoPort=39832, ipcPort=40947):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:11,592 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:11,808 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:11,810 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37877, storageID=DS-1047970119-10.0.62.238-37877-1312911790573, infoPort=39832, ipcPort=40947):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:11,810 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40947
2011-08-09 19:43:11,810 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:11,811 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:11,811 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:11,812 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:11,824 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:11,832 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 55583
2011-08-09 19:43:11,833 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 55583: exiting
2011-08-09 19:43:11,833 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 55583: exiting
2011-08-09 19:43:11,834 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 55583: exiting
2011-08-09 19:43:11,834 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 55583
2011-08-09 19:43:11,835 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:42318, storageID=DS-1199876856-10.0.62.238-42318-1312911790219, infoPort=43498, ipcPort=55583):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:11,835 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:11,835 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:11,836 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:11,836 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:42318, storageID=DS-1199876856-10.0.62.238-42318-1312911790219, infoPort=43498, ipcPort=55583):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:11,836 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 55583
2011-08-09 19:43:11,836 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:11,837 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:11,837 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:11,838 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:11,879 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:11,981 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:11,981 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:11,981 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:11,984 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 38879
2011-08-09 19:43:11,985 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 38879: exiting
2011-08-09 19:43:11,985 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 38879: exiting
2011-08-09 19:43:11,985 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 38879: exiting
2011-08-09 19:43:11,986 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 38879: exiting
2011-08-09 19:43:11,986 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 38879: exiting
2011-08-09 19:43:11,986 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 38879: exiting
2011-08-09 19:43:11,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 38879: exiting
2011-08-09 19:43:11,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 38879: exiting
2011-08-09 19:43:11,987 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 38879: exiting
2011-08-09 19:43:11,988 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 38879: exiting
2011-08-09 19:43:11,988 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 38879
2011-08-09 19:43:11,989 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:12,002 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:12,003 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:12,003 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:12,003 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:12,008 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:12,009 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:12,009 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:12,009 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:12,018 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:12,018 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:12,030 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:12,032 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:12,033 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:12,192 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:12,193 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:12,196 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:12,197 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:12,197 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:12,197 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:12,197 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:12,203 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:12,203 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:12,203 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:12,203 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:12,207 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:12,208 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:12,233 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:12,237 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:12,237 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:12,237 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:12,237 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:12,237 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:12,238 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:12,239 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:12,239 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 36 msecs
2011-08-09 19:43:12,239 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:12,242 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:12,242 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:12,243 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:12,243 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:12,243 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:12,244 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:12,247 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=42324
2011-08-09 19:43:12,247 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:42324
2011-08-09 19:43:12,247 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:12,248 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 42324: starting
2011-08-09 19:43:12,248 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 42324: starting
2011-08-09 19:43:12,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 42324: starting
2011-08-09 19:43:12,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 42324: starting
2011-08-09 19:43:12,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 42324: starting
2011-08-09 19:43:12,249 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 42324: starting
2011-08-09 19:43:12,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 42324: starting
2011-08-09 19:43:12,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 42324: starting
2011-08-09 19:43:12,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 42324: starting
2011-08-09 19:43:12,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 42324: starting
2011-08-09 19:43:12,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 42324: starting
2011-08-09 19:43:12,259 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:12,259 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:12,259 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:12,259 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:12,260 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:12,302 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:12,303 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:12,303 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40655 webServer.getConnectors()[0].getLocalPort() returned 40655
2011-08-09 19:43:12,303 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40655
2011-08-09 19:43:12,303 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:12,352 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40655
2011-08-09 19:43:12,353 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:40655
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:12,396 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:12,396 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:12,414 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:12,414 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:12,617 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:12,618 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34393
2011-08-09 19:43:12,618 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:12,621 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:12,622 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:12,622 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48265 webServer.getConnectors()[0].getLocalPort() returned 48265
2011-08-09 19:43:12,622 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48265
2011-08-09 19:43:12,622 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:12,683 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48265
2011-08-09 19:43:12,683 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:12,688 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:12,691 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49377
2011-08-09 19:43:12,692 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:12,714 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49377: starting
2011-08-09 19:43:12,715 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49377: starting
2011-08-09 19:43:12,715 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34393, storageID=, infoPort=48265, ipcPort=49377)
2011-08-09 19:43:12,716 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49377: starting
2011-08-09 19:43:12,716 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49377: starting
2011-08-09 19:43:12,723 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34393 storage DS-356032688-10.0.62.238-34393-1312911792719
2011-08-09 19:43:12,723 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34393
2011-08-09 19:43:12,729 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-356032688-10.0.62.238-34393-1312911792719 is assigned to data-node 127.0.0.1:34393
2011-08-09 19:43:12,730 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34393, storageID=DS-356032688-10.0.62.238-34393-1312911792719, infoPort=48265, ipcPort=49377)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:12,731 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:12,736 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:12,739 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:34393 0 blocks shortCircuit first report.
2011-08-09 19:43:12,739 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:12,740 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:12,741 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:12,742 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:12,742 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:12,757 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:12,757 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:12,960 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:12,961 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38704
2011-08-09 19:43:12,962 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:13,014 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:13,015 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:13,016 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48558 webServer.getConnectors()[0].getLocalPort() returned 48558
2011-08-09 19:43:13,016 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48558
2011-08-09 19:43:13,016 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:13,114 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48558
2011-08-09 19:43:13,160 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:13,165 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:13,168 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49829
2011-08-09 19:43:13,169 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:13,169 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49829: starting
2011-08-09 19:43:13,170 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49829: starting
2011-08-09 19:43:13,171 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49829: starting
2011-08-09 19:43:13,171 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38704, storageID=, infoPort=48558, ipcPort=49829)
2011-08-09 19:43:13,172 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49829: starting
2011-08-09 19:43:13,176 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38704 storage DS-129263281-10.0.62.238-38704-1312911793174
2011-08-09 19:43:13,177 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38704
2011-08-09 19:43:13,184 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-129263281-10.0.62.238-38704-1312911793174 is assigned to data-node 127.0.0.1:38704
2011-08-09 19:43:13,185 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38704, storageID=DS-129263281-10.0.62.238-38704-1312911793174, infoPort=48558, ipcPort=49829)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:13,187 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:13,191 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:13,193 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38704 0 blocks shortCircuit first report.
2011-08-09 19:43:13,194 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:13,194 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:13,195 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:13,200 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test/hadoop/file is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:13,202 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:13,281 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:13,382 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49829
2011-08-09 19:43:13,382 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49829: exiting
2011-08-09 19:43:13,382 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49829: exiting
2011-08-09 19:43:13,383 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49829: exiting
2011-08-09 19:43:13,383 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49829
2011-08-09 19:43:13,384 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:13,384 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:13,385 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38704, storageID=DS-129263281-10.0.62.238-38704-1312911793174, infoPort=48558, ipcPort=49829):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:14,197 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:14,385 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:14,386 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38704, storageID=DS-129263281-10.0.62.238-38704-1312911793174, infoPort=48558, ipcPort=49829):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:14,387 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49829
2011-08-09 19:43:14,387 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:14,388 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:14,388 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:14,389 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:14,434 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:14,536 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49377
2011-08-09 19:43:14,536 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49377: exiting
2011-08-09 19:43:14,536 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49377: exiting
2011-08-09 19:43:14,537 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:14,538 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34393, storageID=DS-356032688-10.0.62.238-34393-1312911792719, infoPort=48265, ipcPort=49377):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:14,538 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49377
2011-08-09 19:43:14,537 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:14,539 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49377: exiting
2011-08-09 19:43:14,744 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:15,538 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:15,538 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34393, storageID=DS-356032688-10.0.62.238-34393-1312911792719, infoPort=48265, ipcPort=49377):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:15,539 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49377
2011-08-09 19:43:15,540 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:15,540 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:15,541 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:15,542 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:15,544 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:15,651 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:15,651 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:15,652 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:0  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:0 
2011-08-09 19:43:15,659 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 42324
2011-08-09 19:43:15,660 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 42324: exiting
2011-08-09 19:43:15,660 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 42324: exiting
2011-08-09 19:43:15,660 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 42324: exiting
2011-08-09 19:43:15,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 42324: exiting
2011-08-09 19:43:15,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 42324: exiting
2011-08-09 19:43:15,661 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 42324: exiting
2011-08-09 19:43:15,662 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 42324: exiting
2011-08-09 19:43:15,662 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 42324: exiting
2011-08-09 19:43:15,662 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 42324: exiting
2011-08-09 19:43:15,663 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 42324: exiting
2011-08-09 19:43:15,663 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 42324
2011-08-09 19:43:15,665 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:15,679 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:15,679 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:15,679 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:15,679 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:15,685 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:15,686 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:15,686 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:15,686 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:15,694 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:15,694 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:15,706 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:15,708 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:15,708 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:15,868 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:15,869 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:15,872 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:15,872 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:15,872 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:15,873 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:15,873 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:15,878 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:15,878 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:15,878 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:15,878 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:15,882 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:15,882 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:15,908 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:15,911 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:15,912 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:15,912 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:15,912 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:15,913 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:15,913 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:15,914 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:15,914 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 36 msecs
2011-08-09 19:43:15,914 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:15,917 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:15,918 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:15,918 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:15,918 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:15,918 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:15,919 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:15,922 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=57668
2011-08-09 19:43:15,923 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:57668
2011-08-09 19:43:15,923 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:15,923 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57668: starting
2011-08-09 19:43:15,924 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57668: starting
2011-08-09 19:43:15,924 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57668: starting
2011-08-09 19:43:15,924 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57668: starting
2011-08-09 19:43:15,924 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 57668: starting
2011-08-09 19:43:15,925 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 57668: starting
2011-08-09 19:43:15,925 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 57668: starting
2011-08-09 19:43:15,925 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 57668: starting
2011-08-09 19:43:15,925 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 57668: starting
2011-08-09 19:43:15,926 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 57668: starting
2011-08-09 19:43:15,926 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 57668: starting
2011-08-09 19:43:15,975 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:15,976 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:15,976 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:15,976 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:15,977 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:15,979 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:15,980 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:15,980 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 54495 webServer.getConnectors()[0].getLocalPort() returned 54495
2011-08-09 19:43:15,980 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 54495
2011-08-09 19:43:15,980 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:16,028 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:54495
2011-08-09 19:43:16,029 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:54495
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:16,036 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:16,036 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:16,053 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:16,053 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:16,243 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:16,244 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34848
2011-08-09 19:43:16,245 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:16,247 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:16,248 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:16,248 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 59817 webServer.getConnectors()[0].getLocalPort() returned 59817
2011-08-09 19:43:16,248 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 59817
2011-08-09 19:43:16,249 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:16,366 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:59817
2011-08-09 19:43:16,367 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:16,373 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:16,375 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=41270
2011-08-09 19:43:16,376 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:16,377 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 41270: starting
2011-08-09 19:43:16,377 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 41270: starting
2011-08-09 19:43:16,378 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 41270: starting
2011-08-09 19:43:16,378 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 41270: starting
2011-08-09 19:43:16,378 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34848, storageID=, infoPort=59817, ipcPort=41270)
2011-08-09 19:43:16,386 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34848 storage DS-1310491272-10.0.62.238-34848-1312911796381
2011-08-09 19:43:16,386 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34848
2011-08-09 19:43:16,392 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1310491272-10.0.62.238-34848-1312911796381 is assigned to data-node 127.0.0.1:34848
2011-08-09 19:43:16,393 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34848, storageID=DS-1310491272-10.0.62.238-34848-1312911796381, infoPort=59817, ipcPort=41270)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:16,394 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:16,400 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:16,402 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:34848 0 blocks shortCircuit first report.
2011-08-09 19:43:16,403 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:16,403 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:16,404 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:16,404 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:16,405 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:16,421 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:16,422 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:16,628 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:16,630 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53816
2011-08-09 19:43:16,630 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:16,633 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:16,634 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:16,634 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57771 webServer.getConnectors()[0].getLocalPort() returned 57771
2011-08-09 19:43:16,634 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57771
2011-08-09 19:43:16,634 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:16,694 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57771
2011-08-09 19:43:16,694 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:16,699 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:16,701 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=58705
2011-08-09 19:43:16,703 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:16,704 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 58705: starting
2011-08-09 19:43:16,705 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 58705: starting
2011-08-09 19:43:16,705 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 58705: starting
2011-08-09 19:43:16,706 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53816, storageID=, infoPort=57771, ipcPort=58705)
2011-08-09 19:43:16,708 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 58705: starting
2011-08-09 19:43:16,733 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53816 storage DS-1234264342-10.0.62.238-53816-1312911796729
2011-08-09 19:43:16,734 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53816
2011-08-09 19:43:16,743 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1234264342-10.0.62.238-53816-1312911796729 is assigned to data-node 127.0.0.1:53816
2011-08-09 19:43:16,744 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53816, storageID=DS-1234264342-10.0.62.238-53816-1312911796729, infoPort=57771, ipcPort=58705)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:16,745 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:16,751 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:16,752 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53816 0 blocks shortCircuit first report.
2011-08-09 19:43:16,754 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:43:16,754 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:16,756 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:16,772 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/tmp/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:16,778 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /tmp/test/hadoop/file. blk_-7622735754197200536_1001
2011-08-09 19:43:16,793 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7622735754197200536_1001 src: /127.0.0.1:37750 dest: /127.0.0.1:34848
2011-08-09 19:43:16,795 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7622735754197200536_1001 src: /127.0.0.1:37658 dest: /127.0.0.1:53816
2011-08-09 19:43:16,801 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:37658, dest: /127.0.0.1:53816, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_164525345, offset: 0, srvID: DS-1234264342-10.0.62.238-53816-1312911796729, blockid: blk_-7622735754197200536_1001, duration: 2796789
2011-08-09 19:43:16,801 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7622735754197200536_1001 terminating
2011-08-09 19:43:16,804 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:37750, dest: /127.0.0.1:34848, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_164525345, offset: 0, srvID: DS-1310491272-10.0.62.238-34848-1312911796381, blockid: blk_-7622735754197200536_1001, duration: 2133082
2011-08-09 19:43:16,806 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-7622735754197200536_1001 terminating
2011-08-09 19:43:16,804 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53816 is added to blk_-7622735754197200536_1001 size 2048
2011-08-09 19:43:16,808 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34848 is added to blk_-7622735754197200536_1001 size 2048
2011-08-09 19:43:16,811 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /tmp/test/hadoop/file is closed by DFSClient_164525345
2011-08-09 19:43:16,816 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test/hadoop/subdir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:16,821 INFO  ipc.Server (Server.java:run(1079)) - IPC Server handler 4 on 57668, call delete(/tmp/test/hadoop, false) from 127.0.0.1:38689: error: java.io.IOException: /tmp/test/hadoop is non empty
java.io.IOException: /tmp/test/hadoop is non empty
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2202)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.delete(NameNode.java:674)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:631)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1070)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1066)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1064)
2011-08-09 19:43:16,825 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7622735754197200536 is added to invalidSet of 127.0.0.1:53816
2011-08-09 19:43:16,826 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7622735754197200536 is added to invalidSet of 127.0.0.1:34848
2011-08-09 19:43:16,827 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/tmp/test/hadoop	dst=null	perm=null
2011-08-09 19:43:16,830 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:16,848 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:16,949 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58705
2011-08-09 19:43:16,950 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 58705: exiting
2011-08-09 19:43:16,950 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 58705: exiting
2011-08-09 19:43:16,950 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 58705: exiting
2011-08-09 19:43:16,958 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 58705
2011-08-09 19:43:16,959 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:16,960 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:16,960 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53816, storageID=DS-1234264342-10.0.62.238-53816-1312911796729, infoPort=57771, ipcPort=58705):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:17,759 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:17,960 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:17,961 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53816, storageID=DS-1234264342-10.0.62.238-53816-1312911796729, infoPort=57771, ipcPort=58705):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:17,961 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58705
2011-08-09 19:43:17,962 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:17,962 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:17,962 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:17,963 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:17,980 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:17,980 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41270
2011-08-09 19:43:17,981 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 41270: exiting
2011-08-09 19:43:17,981 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 41270: exiting
2011-08-09 19:43:17,981 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 41270: exiting
2011-08-09 19:43:17,982 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 41270
2011-08-09 19:43:17,982 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:17,983 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:17,983 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34848, storageID=DS-1310491272-10.0.62.238-34848-1312911796381, infoPort=59817, ipcPort=41270):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:18,409 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:18,983 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:53816 to delete  blk_-7622735754197200536_1001
2011-08-09 19:43:18,983 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:18,984 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34848, storageID=DS-1310491272-10.0.62.238-34848-1312911796381, infoPort=59817, ipcPort=41270):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:18,984 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 41270
2011-08-09 19:43:18,984 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:18,985 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:18,985 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:18,986 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:18,999 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:19,100 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:19,100 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 8 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:5  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:19,101 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:19,103 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57668
2011-08-09 19:43:19,103 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57668: exiting
2011-08-09 19:43:19,103 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 57668: exiting
2011-08-09 19:43:19,103 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57668: exiting
2011-08-09 19:43:19,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57668: exiting
2011-08-09 19:43:19,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 57668: exiting
2011-08-09 19:43:19,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 57668: exiting
2011-08-09 19:43:19,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 57668: exiting
2011-08-09 19:43:19,105 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 57668: exiting
2011-08-09 19:43:19,105 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 57668: exiting
2011-08-09 19:43:19,105 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 57668: exiting
2011-08-09 19:43:19,106 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57668
2011-08-09 19:43:19,107 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:19,118 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:19,119 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:19,119 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:19,119 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:19,124 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:19,125 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:19,125 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:19,125 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:19,133 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:19,134 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:19,145 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:19,148 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:19,148 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:19,314 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:19,315 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:19,318 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:19,318 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:19,318 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:19,319 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:19,319 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:19,323 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:19,324 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:19,324 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:19,324 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:19,327 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:19,328 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:19,354 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:19,358 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:19,358 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:19,359 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:19,359 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:19,359 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:19,360 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:19,360 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:19,360 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:19,360 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:19,363 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:19,364 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:19,364 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:19,364 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:19,364 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:19,365 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:19,368 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=32852
2011-08-09 19:43:19,369 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:32852
2011-08-09 19:43:19,369 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:19,369 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 32852: starting
2011-08-09 19:43:19,370 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 32852: starting
2011-08-09 19:43:19,370 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 32852: starting
2011-08-09 19:43:19,370 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 32852: starting
2011-08-09 19:43:19,370 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 32852: starting
2011-08-09 19:43:19,370 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 32852: starting
2011-08-09 19:43:19,371 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 32852: starting
2011-08-09 19:43:19,371 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 32852: starting
2011-08-09 19:43:19,371 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 32852: starting
2011-08-09 19:43:19,371 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 32852: starting
2011-08-09 19:43:19,371 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 32852: starting
2011-08-09 19:43:19,381 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:19,381 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:19,381 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:19,381 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:19,382 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:19,386 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:19,386 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:19,386 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 58286 webServer.getConnectors()[0].getLocalPort() returned 58286
2011-08-09 19:43:19,387 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 58286
2011-08-09 19:43:19,387 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:19,435 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:58286
2011-08-09 19:43:19,435 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:58286
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:19,482 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:19,483 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:19,500 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:19,500 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:19,697 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:19,699 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 47367
2011-08-09 19:43:19,699 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:19,702 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:19,702 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:19,703 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 35698 webServer.getConnectors()[0].getLocalPort() returned 35698
2011-08-09 19:43:19,703 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 35698
2011-08-09 19:43:19,703 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:19,760 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:35698
2011-08-09 19:43:19,761 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:19,787 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:19,789 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=50808
2011-08-09 19:43:19,791 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:19,791 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 50808: starting
2011-08-09 19:43:19,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 50808: starting
2011-08-09 19:43:19,792 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 50808: starting
2011-08-09 19:43:19,793 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 50808: starting
2011-08-09 19:43:19,792 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:47367, storageID=, infoPort=35698, ipcPort=50808)
2011-08-09 19:43:19,800 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:47367 storage DS-231880065-10.0.62.238-47367-1312911799796
2011-08-09 19:43:19,801 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:47367
2011-08-09 19:43:19,807 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-231880065-10.0.62.238-47367-1312911799796 is assigned to data-node 127.0.0.1:47367
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:19,808 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:47367, storageID=DS-231880065-10.0.62.238-47367-1312911799796, infoPort=35698, ipcPort=50808)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:19,810 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:19,816 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:19,817 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:19,819 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:19,820 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:47367 0 blocks shortCircuit first report.
2011-08-09 19:43:19,821 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:19,821 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:19,822 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:19,834 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:19,834 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:20,049 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:20,050 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 36031
2011-08-09 19:43:20,050 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:20,053 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:20,053 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:20,054 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34387 webServer.getConnectors()[0].getLocalPort() returned 34387
2011-08-09 19:43:20,054 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34387
2011-08-09 19:43:20,054 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:20,119 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34387
2011-08-09 19:43:20,120 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:20,124 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:20,127 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=46809
2011-08-09 19:43:20,128 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:20,128 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 46809: starting
2011-08-09 19:43:20,129 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 46809: starting
2011-08-09 19:43:20,130 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 46809: starting
2011-08-09 19:43:20,130 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 46809: starting
2011-08-09 19:43:20,130 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:36031, storageID=, infoPort=34387, ipcPort=46809)
2011-08-09 19:43:20,136 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:36031 storage DS-889299677-10.0.62.238-36031-1312911800133
2011-08-09 19:43:20,136 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:36031
2011-08-09 19:43:20,143 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-889299677-10.0.62.238-36031-1312911800133 is assigned to data-node 127.0.0.1:36031
2011-08-09 19:43:20,144 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:36031, storageID=DS-889299677-10.0.62.238-36031-1312911800133, infoPort=34387, ipcPort=46809)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:20,147 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:20,154 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:20,155 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:36031 0 blocks shortCircuit first report.
2011-08-09 19:43:20,156 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:20,156 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:20,157 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:20,192 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/test/hadoop	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:20,197 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/tmp/test/hadoop	dst=null	perm=null
2011-08-09 19:43:20,199 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:20,253 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:20,354 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46809
2011-08-09 19:43:20,354 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 46809
2011-08-09 19:43:20,355 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 46809: exiting
2011-08-09 19:43:20,355 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 46809: exiting
2011-08-09 19:43:20,355 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 46809: exiting
2011-08-09 19:43:20,356 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:20,356 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:36031, storageID=DS-889299677-10.0.62.238-36031-1312911800133, infoPort=34387, ipcPort=46809):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:20,357 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:20,357 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:20,359 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:36031, storageID=DS-889299677-10.0.62.238-36031-1312911800133, infoPort=34387, ipcPort=46809):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:20,359 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 46809
2011-08-09 19:43:20,359 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:20,360 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:20,360 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:20,361 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:20,363 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:20,364 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50808
2011-08-09 19:43:20,365 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 50808: exiting
2011-08-09 19:43:20,365 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 50808: exiting
2011-08-09 19:43:20,365 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 50808: exiting
2011-08-09 19:43:20,365 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 50808
2011-08-09 19:43:20,366 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:20,367 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:20,367 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:47367, storageID=DS-231880065-10.0.62.238-47367-1312911799796, infoPort=35698, ipcPort=50808):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:20,823 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:21,367 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:21,369 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:47367, storageID=DS-231880065-10.0.62.238-47367-1312911799796, infoPort=35698, ipcPort=50808):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:21,369 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 50808
2011-08-09 19:43:21,370 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:21,371 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:21,371 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:21,372 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:21,373 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:21,380 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:21,380 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:21,380 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 4 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:6  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:21,383 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 32852
2011-08-09 19:43:21,384 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 32852: exiting
2011-08-09 19:43:21,384 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 32852: exiting
2011-08-09 19:43:21,384 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 32852: exiting
2011-08-09 19:43:21,384 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 32852: exiting
2011-08-09 19:43:21,384 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 32852: exiting
2011-08-09 19:43:21,385 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 32852: exiting
2011-08-09 19:43:21,385 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 32852: exiting
2011-08-09 19:43:21,385 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 32852: exiting
2011-08-09 19:43:21,385 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 32852: exiting
2011-08-09 19:43:21,385 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 32852: exiting
2011-08-09 19:43:21,386 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 32852
2011-08-09 19:43:21,387 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:21,400 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:21,400 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:21,400 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:21,400 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:21,405 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:21,406 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:21,406 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:21,406 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:21,418 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:21,418 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:21,430 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:21,433 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:21,433 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:21,594 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:21,595 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:21,598 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:21,598 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:21,598 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:21,599 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:21,599 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:21,603 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:21,604 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:21,604 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:21,604 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:21,607 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:21,608 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:21,633 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:21,637 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:21,637 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:21,637 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:21,637 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:21,638 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:21,638 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:21,639 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:21,639 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 36 msecs
2011-08-09 19:43:21,639 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:21,642 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:21,642 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:21,643 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:21,643 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:21,643 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:21,644 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:21,646 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=57245
2011-08-09 19:43:21,647 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:57245
2011-08-09 19:43:21,647 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:21,647 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57245: starting
2011-08-09 19:43:21,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57245: starting
2011-08-09 19:43:21,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57245: starting
2011-08-09 19:43:21,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57245: starting
2011-08-09 19:43:21,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 57245: starting
2011-08-09 19:43:21,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 57245: starting
2011-08-09 19:43:21,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 57245: starting
2011-08-09 19:43:21,649 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 57245: starting
2011-08-09 19:43:21,649 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 57245: starting
2011-08-09 19:43:21,649 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 57245: starting
2011-08-09 19:43:21,650 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 57245: starting
2011-08-09 19:43:21,657 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:21,658 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:21,658 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:21,658 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:21,659 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:21,704 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:21,705 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:21,705 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 60343 webServer.getConnectors()[0].getLocalPort() returned 60343
2011-08-09 19:43:21,705 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 60343
2011-08-09 19:43:21,705 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:21,819 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:60343
2011-08-09 19:43:21,819 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:60343
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:21,826 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:21,826 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:21,843 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:21,843 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:22,086 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:22,087 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 40316
2011-08-09 19:43:22,088 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:22,090 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:22,091 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:22,091 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43780 webServer.getConnectors()[0].getLocalPort() returned 43780
2011-08-09 19:43:22,091 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43780
2011-08-09 19:43:22,092 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:22,148 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43780
2011-08-09 19:43:22,149 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:22,153 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:22,156 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=48254
2011-08-09 19:43:22,157 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:22,157 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 48254: starting
2011-08-09 19:43:22,157 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 48254: starting
2011-08-09 19:43:22,158 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 48254: starting
2011-08-09 19:43:22,158 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:40316, storageID=, infoPort=43780, ipcPort=48254)
2011-08-09 19:43:22,159 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 48254: starting
2011-08-09 19:43:22,165 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:40316 storage DS-482585991-10.0.62.238-40316-1312911802161
2011-08-09 19:43:22,166 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:40316
2011-08-09 19:43:22,172 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-482585991-10.0.62.238-40316-1312911802161 is assigned to data-node 127.0.0.1:40316
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:22,173 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:40316, storageID=DS-482585991-10.0.62.238-40316-1312911802161, infoPort=43780, ipcPort=48254)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:22,174 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:22,179 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:22,180 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:22,182 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:22,183 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:40316 0 blocks shortCircuit first report.
2011-08-09 19:43:22,184 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:22,184 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:22,185 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:22,197 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:22,197 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:22,415 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:22,416 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38602
2011-08-09 19:43:22,417 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:22,419 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:22,420 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:22,420 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 36936 webServer.getConnectors()[0].getLocalPort() returned 36936
2011-08-09 19:43:22,420 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 36936
2011-08-09 19:43:22,421 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:22,479 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:36936
2011-08-09 19:43:22,480 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:22,484 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:22,487 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=52784
2011-08-09 19:43:22,488 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:22,489 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 52784: starting
2011-08-09 19:43:22,489 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 52784: starting
2011-08-09 19:43:22,490 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 52784: starting
2011-08-09 19:43:22,490 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38602, storageID=, infoPort=36936, ipcPort=52784)
2011-08-09 19:43:22,491 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 52784: starting
2011-08-09 19:43:22,496 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38602 storage DS-1267193639-10.0.62.238-38602-1312911802493
2011-08-09 19:43:22,496 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38602
2011-08-09 19:43:22,503 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1267193639-10.0.62.238-38602-1312911802493 is assigned to data-node 127.0.0.1:38602
2011-08-09 19:43:22,504 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38602, storageID=DS-1267193639-10.0.62.238-38602-1312911802493, infoPort=36936, ipcPort=52784)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:22,505 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:22,510 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:22,513 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38602 0 blocks shortCircuit first report.
2011-08-09 19:43:22,515 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 6 msecs
2011-08-09 19:43:22,515 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:22,516 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:22,519 WARN  hdfs.StateChange (FSDirectory.java:unprotectedRenameTo(462)) - DIR* FSDirectory.unprotectedRenameTo: failed to rename /test/hadoop/path to /test/new/newpath because source does not exist
2011-08-09 19:43:22,530 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:22,565 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:22,665 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52784
2011-08-09 19:43:22,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 52784: exiting
2011-08-09 19:43:22,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 52784: exiting
2011-08-09 19:43:22,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 52784: exiting
2011-08-09 19:43:22,666 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 52784
2011-08-09 19:43:22,667 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:22,667 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:22,668 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38602, storageID=DS-1267193639-10.0.62.238-38602-1312911802493, infoPort=36936, ipcPort=52784):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:23,518 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:23,668 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:23,669 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38602, storageID=DS-1267193639-10.0.62.238-38602-1312911802493, infoPort=36936, ipcPort=52784):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:23,670 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 52784
2011-08-09 19:43:23,670 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:23,671 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:23,671 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:23,672 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:23,704 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:23,805 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48254
2011-08-09 19:43:23,805 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 48254: exiting
2011-08-09 19:43:23,805 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 48254: exiting
2011-08-09 19:43:23,806 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 48254: exiting
2011-08-09 19:43:23,806 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 48254
2011-08-09 19:43:23,807 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:23,808 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:40316, storageID=DS-482585991-10.0.62.238-40316-1312911802161, infoPort=43780, ipcPort=48254):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:23,808 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:23,809 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:23,809 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:40316, storageID=DS-482585991-10.0.62.238-40316-1312911802161, infoPort=43780, ipcPort=48254):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:23,810 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 48254
2011-08-09 19:43:23,811 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:23,812 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:23,812 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:23,813 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:23,848 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:23,949 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:23,950 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:23,955 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 0 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:5  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:2 
2011-08-09 19:43:23,957 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57245
2011-08-09 19:43:23,957 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57245: exiting
2011-08-09 19:43:23,958 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57245: exiting
2011-08-09 19:43:23,958 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 57245: exiting
2011-08-09 19:43:23,958 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57245: exiting
2011-08-09 19:43:23,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 57245: exiting
2011-08-09 19:43:23,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 57245: exiting
2011-08-09 19:43:23,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 57245: exiting
2011-08-09 19:43:23,959 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 57245: exiting
2011-08-09 19:43:23,960 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 57245: exiting
2011-08-09 19:43:23,960 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 57245: exiting
2011-08-09 19:43:23,960 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57245
2011-08-09 19:43:23,961 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:23,974 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:23,974 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:23,974 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:23,974 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:23,979 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:23,980 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:23,980 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:23,980 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:23,990 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:23,990 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:24,002 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:24,004 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:24,004 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:24,167 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:24,168 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:24,172 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:24,172 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:24,172 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:24,172 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:24,172 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:24,177 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:24,178 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:24,178 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:24,178 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:24,181 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:24,182 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:24,208 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:24,212 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:24,212 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:24,212 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:24,212 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:24,212 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:24,213 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:24,214 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:24,214 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:24,214 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:24,217 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:24,217 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:24,218 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:24,218 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:24,218 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:24,219 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:24,221 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=43557
2011-08-09 19:43:24,222 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:43557
2011-08-09 19:43:24,222 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:24,223 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 43557: starting
2011-08-09 19:43:24,223 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 43557: starting
2011-08-09 19:43:24,223 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 43557: starting
2011-08-09 19:43:24,223 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 43557: starting
2011-08-09 19:43:24,223 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 43557: starting
2011-08-09 19:43:24,224 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 43557: starting
2011-08-09 19:43:24,224 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 43557: starting
2011-08-09 19:43:24,224 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 43557: starting
2011-08-09 19:43:24,224 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 43557: starting
2011-08-09 19:43:24,224 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 43557: starting
2011-08-09 19:43:24,225 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 43557: starting
2011-08-09 19:43:24,233 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:24,233 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:24,233 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:24,234 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:24,234 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:24,237 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:24,238 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:24,238 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57552 webServer.getConnectors()[0].getLocalPort() returned 57552
2011-08-09 19:43:24,238 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57552
2011-08-09 19:43:24,238 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:24,285 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57552
2011-08-09 19:43:24,286 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:57552
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:24,292 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:24,292 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:24,309 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:24,309 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:24,526 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:24,527 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53911
2011-08-09 19:43:24,528 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:24,531 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:24,533 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:24,533 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 38602 webServer.getConnectors()[0].getLocalPort() returned 38602
2011-08-09 19:43:24,534 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 38602
2011-08-09 19:43:24,534 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:24,591 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:38602
2011-08-09 19:43:24,592 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:24,597 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:24,599 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49881
2011-08-09 19:43:24,601 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:24,601 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49881: starting
2011-08-09 19:43:24,602 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49881: starting
2011-08-09 19:43:24,602 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49881: starting
2011-08-09 19:43:24,602 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53911, storageID=, infoPort=38602, ipcPort=49881)
2011-08-09 19:43:24,603 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49881: starting
2011-08-09 19:43:24,609 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53911 storage DS-487923848-10.0.62.238-53911-1312911804605
2011-08-09 19:43:24,610 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53911
2011-08-09 19:43:24,616 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-487923848-10.0.62.238-53911-1312911804605 is assigned to data-node 127.0.0.1:53911
2011-08-09 19:43:24,617 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53911, storageID=DS-487923848-10.0.62.238-53911-1312911804605, infoPort=38602, ipcPort=49881)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:24,618 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:24,623 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:24,625 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53911 0 blocks shortCircuit first report.
2011-08-09 19:43:24,626 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:24,627 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:24,627 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:24,628 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:24,628 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:24,645 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:24,645 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:24,856 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:24,857 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 51381
2011-08-09 19:43:24,858 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:24,860 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:24,861 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:24,861 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 37019 webServer.getConnectors()[0].getLocalPort() returned 37019
2011-08-09 19:43:24,861 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 37019
2011-08-09 19:43:24,862 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:24,921 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:37019
2011-08-09 19:43:24,922 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:24,927 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:24,930 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=58015
2011-08-09 19:43:24,931 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:24,932 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 58015: starting
2011-08-09 19:43:24,932 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 58015: starting
2011-08-09 19:43:24,933 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 58015: starting
2011-08-09 19:43:24,933 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:51381, storageID=, infoPort=37019, ipcPort=58015)
2011-08-09 19:43:24,934 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 58015: starting
2011-08-09 19:43:24,939 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:51381 storage DS-772556968-10.0.62.238-51381-1312911804936
2011-08-09 19:43:24,940 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:51381
2011-08-09 19:43:24,947 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-772556968-10.0.62.238-51381-1312911804936 is assigned to data-node 127.0.0.1:51381
2011-08-09 19:43:24,948 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:51381, storageID=DS-772556968-10.0.62.238-51381-1312911804936, infoPort=37019, ipcPort=58015)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:24,950 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:24,955 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:24,956 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:51381 0 blocks shortCircuit first report.
2011-08-09 19:43:24,958 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:24,958 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:24,959 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:24,980 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:24,984 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_5041316689376549910_1001
2011-08-09 19:43:24,987 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5041316689376549910_1001 src: /127.0.0.1:46839 dest: /127.0.0.1:53911
2011-08-09 19:43:24,989 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5041316689376549910_1001 src: /127.0.0.1:42992 dest: /127.0.0.1:51381
2011-08-09 19:43:24,993 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:42992, dest: /127.0.0.1:51381, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1449668565, offset: 0, srvID: DS-772556968-10.0.62.238-51381-1312911804936, blockid: blk_5041316689376549910_1001, duration: 2384870
2011-08-09 19:43:24,994 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5041316689376549910_1001 terminating
2011-08-09 19:43:24,995 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:46839, dest: /127.0.0.1:53911, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-1449668565, offset: 0, srvID: DS-487923848-10.0.62.238-53911-1312911804605, blockid: blk_5041316689376549910_1001, duration: 2146495
2011-08-09 19:43:24,996 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5041316689376549910_1001 terminating
2011-08-09 19:43:24,997 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:51381 is added to blk_5041316689376549910_1001 size 2048
2011-08-09 19:43:25,037 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-1449668565
2011-08-09 19:43:25,038 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53911 is added to blk_5041316689376549910_1001 size 2048
2011-08-09 19:43:25,041 WARN  hdfs.StateChange (FSDirectory.java:unprotectedRenameTo(499)) - DIR* FSDirectory.unprotectedRenameTo: failed to rename /test/hadoop/file to /test/new/newfile because destination's parent does not exist
2011-08-09 19:43:25,045 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:25,048 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5041316689376549910 is added to invalidSet of 127.0.0.1:51381
2011-08-09 19:43:25,048 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5041316689376549910 is added to invalidSet of 127.0.0.1:53911
2011-08-09 19:43:25,050 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:25,051 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:25,052 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58015
2011-08-09 19:43:25,052 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 58015: exiting
2011-08-09 19:43:25,052 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 58015: exiting
2011-08-09 19:43:25,053 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 58015: exiting
2011-08-09 19:43:25,053 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 58015
2011-08-09 19:43:25,054 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:25,054 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:25,055 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:51381, storageID=DS-772556968-10.0.62.238-51381-1312911804936, infoPort=37019, ipcPort=58015):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:25,961 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:26,055 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:26,057 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:51381, storageID=DS-772556968-10.0.62.238-51381-1312911804936, infoPort=37019, ipcPort=58015):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:26,064 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58015
2011-08-09 19:43:26,064 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:26,065 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:26,065 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:26,066 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:26,067 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:26,068 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49881
2011-08-09 19:43:26,069 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49881: exiting
2011-08-09 19:43:26,069 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49881: exiting
2011-08-09 19:43:26,069 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49881: exiting
2011-08-09 19:43:26,070 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49881
2011-08-09 19:43:26,070 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53911, storageID=DS-487923848-10.0.62.238-53911-1312911804605, infoPort=38602, ipcPort=49881):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:26,070 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:26,071 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:26,071 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:26,072 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53911, storageID=DS-487923848-10.0.62.238-53911-1312911804605, infoPort=38602, ipcPort=49881):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:26,072 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49881
2011-08-09 19:43:26,072 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:26,073 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:26,073 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:26,074 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:26,075 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:26,176 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:26,176 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:26,177 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:13  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:26,179 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 43557
2011-08-09 19:43:26,179 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 43557: exiting
2011-08-09 19:43:26,179 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 43557: exiting
2011-08-09 19:43:26,179 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 43557: exiting
2011-08-09 19:43:26,180 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 43557: exiting
2011-08-09 19:43:26,181 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 43557: exiting
2011-08-09 19:43:26,181 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 43557
2011-08-09 19:43:26,183 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:26,196 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:26,196 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:26,196 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:26,196 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:26,202 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:26,203 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:26,203 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:26,203 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:26,214 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:26,214 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:26,226 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:26,229 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:26,229 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:26,392 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:26,393 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:26,396 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:26,396 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:26,396 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:26,396 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:26,397 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:26,401 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:26,402 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:26,402 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:26,402 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:26,405 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:26,406 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:26,431 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:26,435 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:26,436 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:26,436 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:26,436 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:26,436 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:26,437 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:26,437 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:26,438 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:26,438 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:26,441 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:26,441 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:26,441 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:26,442 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:26,442 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:26,443 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:26,446 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=39777
2011-08-09 19:43:26,446 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:39777
2011-08-09 19:43:26,447 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:26,447 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 39777: starting
2011-08-09 19:43:26,447 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 39777: starting
2011-08-09 19:43:26,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 39777: starting
2011-08-09 19:43:26,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 39777: starting
2011-08-09 19:43:26,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 39777: starting
2011-08-09 19:43:26,448 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 39777: starting
2011-08-09 19:43:26,449 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 39777: starting
2011-08-09 19:43:26,449 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 39777: starting
2011-08-09 19:43:26,449 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 39777: starting
2011-08-09 19:43:26,449 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 39777: starting
2011-08-09 19:43:26,450 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 39777: starting
2011-08-09 19:43:26,495 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:26,496 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:26,496 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:26,496 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:26,497 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:26,499 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:26,499 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:26,499 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 56467 webServer.getConnectors()[0].getLocalPort() returned 56467
2011-08-09 19:43:26,499 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 56467
2011-08-09 19:43:26,499 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:26,548 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:56467
2011-08-09 19:43:26,548 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:56467
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:26,566 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:26,566 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:26,582 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:26,582 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:26,784 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:26,786 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 60006
2011-08-09 19:43:26,786 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:26,789 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:26,789 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:26,789 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 47204 webServer.getConnectors()[0].getLocalPort() returned 47204
2011-08-09 19:43:26,790 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 47204
2011-08-09 19:43:26,790 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:26,863 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:47204
2011-08-09 19:43:26,864 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:26,869 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:26,871 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=49205
2011-08-09 19:43:26,873 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:26,873 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 49205: starting
2011-08-09 19:43:26,874 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 49205: starting
2011-08-09 19:43:26,874 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:60006, storageID=, infoPort=47204, ipcPort=49205)
2011-08-09 19:43:26,880 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 49205: starting
2011-08-09 19:43:26,874 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 49205: starting
2011-08-09 19:43:26,887 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:60006 storage DS-300793937-10.0.62.238-60006-1312911806883
2011-08-09 19:43:26,887 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:60006
2011-08-09 19:43:26,893 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-300793937-10.0.62.238-60006-1312911806883 is assigned to data-node 127.0.0.1:60006
2011-08-09 19:43:26,895 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:60006, storageID=DS-300793937-10.0.62.238-60006-1312911806883, infoPort=47204, ipcPort=49205)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:26,911 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:26,916 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:26,918 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:60006 0 blocks shortCircuit first report.
2011-08-09 19:43:26,919 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:26,919 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:26,921 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:26,921 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:26,921 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:26,939 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:26,940 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:27,162 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:27,164 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 55918
2011-08-09 19:43:27,164 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:27,167 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:27,167 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:27,167 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49869 webServer.getConnectors()[0].getLocalPort() returned 49869
2011-08-09 19:43:27,168 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49869
2011-08-09 19:43:27,168 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:27,225 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49869
2011-08-09 19:43:27,226 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:27,231 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:27,233 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=44019
2011-08-09 19:43:27,235 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:27,235 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44019: starting
2011-08-09 19:43:27,236 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44019: starting
2011-08-09 19:43:27,236 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44019: starting
2011-08-09 19:43:27,236 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:55918, storageID=, infoPort=49869, ipcPort=44019)
2011-08-09 19:43:27,237 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44019: starting
2011-08-09 19:43:27,242 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:55918 storage DS-597083539-10.0.62.238-55918-1312911807240
2011-08-09 19:43:27,243 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:55918
2011-08-09 19:43:27,250 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-597083539-10.0.62.238-55918-1312911807240 is assigned to data-node 127.0.0.1:55918
2011-08-09 19:43:27,251 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:55918, storageID=DS-597083539-10.0.62.238-55918-1312911807240, infoPort=49869, ipcPort=44019)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:27,252 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:27,257 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:27,259 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:55918 0 blocks shortCircuit first report.
2011-08-09 19:43:27,260 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:27,260 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:27,303 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:27,320 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:27,325 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_4838035097516337734_1001
2011-08-09 19:43:27,346 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_4838035097516337734_1001 src: /127.0.0.1:54892 dest: /127.0.0.1:60006
2011-08-09 19:43:27,348 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_4838035097516337734_1001 src: /127.0.0.1:44770 dest: /127.0.0.1:55918
2011-08-09 19:43:27,354 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:44770, dest: /127.0.0.1:55918, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1094445287, offset: 0, srvID: DS-597083539-10.0.62.238-55918-1312911807240, blockid: blk_4838035097516337734_1001, duration: 2089206
2011-08-09 19:43:27,355 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_4838035097516337734_1001 terminating
2011-08-09 19:43:27,356 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:54892, dest: /127.0.0.1:60006, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1094445287, offset: 0, srvID: DS-300793937-10.0.62.238-60006-1312911806883, blockid: blk_4838035097516337734_1001, duration: 2585239
2011-08-09 19:43:27,356 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_4838035097516337734_1001 terminating
2011-08-09 19:43:27,360 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:55918 is added to blk_4838035097516337734_1001 size 2048
2011-08-09 19:43:27,362 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_1094445287
2011-08-09 19:43:27,362 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:60006 is added to blk_4838035097516337734_1001 size 2048
2011-08-09 19:43:27,367 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/new	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:27,370 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=rename	src=/test/hadoop/file	dst=/test/new/newfile	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:27,373 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:27,376 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_4838035097516337734 is added to invalidSet of 127.0.0.1:55918
2011-08-09 19:43:27,376 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_4838035097516337734 is added to invalidSet of 127.0.0.1:60006
2011-08-09 19:43:27,379 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:27,380 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:27,481 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44019
2011-08-09 19:43:27,481 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44019: exiting
2011-08-09 19:43:27,482 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44019: exiting
2011-08-09 19:43:27,482 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44019
2011-08-09 19:43:27,481 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44019: exiting
2011-08-09 19:43:27,482 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:27,483 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:27,484 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:55918, storageID=DS-597083539-10.0.62.238-55918-1312911807240, infoPort=49869, ipcPort=44019):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:28,304 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:28,484 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:28,485 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:55918, storageID=DS-597083539-10.0.62.238-55918-1312911807240, infoPort=49869, ipcPort=44019):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:28,485 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44019
2011-08-09 19:43:28,486 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:28,494 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:28,494 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:28,495 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:28,556 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:28,657 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49205
2011-08-09 19:43:28,657 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 49205: exiting
2011-08-09 19:43:28,657 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 49205: exiting
2011-08-09 19:43:28,658 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 49205: exiting
2011-08-09 19:43:28,658 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 49205
2011-08-09 19:43:28,659 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:28,659 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:28,659 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:60006, storageID=DS-300793937-10.0.62.238-60006-1312911806883, infoPort=47204, ipcPort=49205):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:28,923 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:29,515 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:60006 to delete  blk_4838035097516337734_1001
2011-08-09 19:43:29,659 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:29,659 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:60006, storageID=DS-300793937-10.0.62.238-60006-1312911806883, infoPort=47204, ipcPort=49205):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:29,660 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 49205
2011-08-09 19:43:29,660 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:29,660 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:29,660 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:29,661 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:29,662 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:29,663 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:29,664 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 8 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:29,664 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:29,666 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 39777
2011-08-09 19:43:29,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 39777: exiting
2011-08-09 19:43:29,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 39777: exiting
2011-08-09 19:43:29,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 39777: exiting
2011-08-09 19:43:29,666 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 39777: exiting
2011-08-09 19:43:29,667 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 39777: exiting
2011-08-09 19:43:29,667 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 39777: exiting
2011-08-09 19:43:29,667 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 39777: exiting
2011-08-09 19:43:29,667 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 39777: exiting
2011-08-09 19:43:29,667 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 39777: exiting
2011-08-09 19:43:29,668 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 39777: exiting
2011-08-09 19:43:29,668 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 39777
2011-08-09 19:43:29,669 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:29,713 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:29,713 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:29,713 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:29,713 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:29,721 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:29,721 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:29,721 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:29,721 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:29,742 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:29,743 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:29,754 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:29,757 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:29,757 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:29,924 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:29,925 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:29,928 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:29,928 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:29,928 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:29,929 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:29,929 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:29,938 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:29,938 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:29,938 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:29,938 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:29,942 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:29,943 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:29,967 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:29,971 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:29,972 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:29,972 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:29,972 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:29,972 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:29,973 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:29,973 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:29,973 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 35 msecs
2011-08-09 19:43:29,974 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:29,977 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:29,977 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:29,977 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:29,977 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:29,977 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:29,979 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:29,981 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=45493
2011-08-09 19:43:29,982 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:45493
2011-08-09 19:43:29,982 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:29,982 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45493: starting
2011-08-09 19:43:29,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45493: starting
2011-08-09 19:43:29,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45493: starting
2011-08-09 19:43:29,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45493: starting
2011-08-09 19:43:29,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 45493: starting
2011-08-09 19:43:29,983 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 45493: starting
2011-08-09 19:43:29,984 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 45493: starting
2011-08-09 19:43:29,984 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 45493: starting
2011-08-09 19:43:29,984 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 45493: starting
2011-08-09 19:43:29,984 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 45493: starting
2011-08-09 19:43:29,985 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 45493: starting
2011-08-09 19:43:29,993 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:29,993 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:29,993 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:29,994 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:29,994 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:30,017 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:30,023 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:30,023 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 47527 webServer.getConnectors()[0].getLocalPort() returned 47527
2011-08-09 19:43:30,023 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 47527
2011-08-09 19:43:30,024 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:30,067 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:47527
2011-08-09 19:43:30,068 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:47527
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:30,074 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:30,075 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:30,091 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:30,091 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:30,287 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:30,288 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 46866
2011-08-09 19:43:30,289 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:30,291 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:30,292 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:30,292 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42505 webServer.getConnectors()[0].getLocalPort() returned 42505
2011-08-09 19:43:30,292 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42505
2011-08-09 19:43:30,292 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:30,368 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42505
2011-08-09 19:43:30,368 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:30,374 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:30,377 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=59464
2011-08-09 19:43:30,378 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:30,378 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 59464: starting
2011-08-09 19:43:30,380 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 59464: starting
2011-08-09 19:43:30,381 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 59464: starting
2011-08-09 19:43:30,381 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:46866, storageID=, infoPort=42505, ipcPort=59464)
2011-08-09 19:43:30,381 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 59464: starting
2011-08-09 19:43:30,388 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:46866 storage DS-156993566-10.0.62.238-46866-1312911810385
2011-08-09 19:43:30,389 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:46866
2011-08-09 19:43:30,395 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-156993566-10.0.62.238-46866-1312911810385 is assigned to data-node 127.0.0.1:46866
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:30,397 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:46866, storageID=DS-156993566-10.0.62.238-46866-1312911810385, infoPort=42505, ipcPort=59464)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:30,398 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:30,406 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:30,406 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:30,407 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:30,408 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:46866 0 blocks shortCircuit first report.
2011-08-09 19:43:30,409 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:30,409 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:30,410 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:30,424 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:30,424 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:30,626 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:30,627 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 53884
2011-08-09 19:43:30,627 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:30,630 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:30,631 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:30,631 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40834 webServer.getConnectors()[0].getLocalPort() returned 40834
2011-08-09 19:43:30,631 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40834
2011-08-09 19:43:30,631 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:30,687 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40834
2011-08-09 19:43:30,687 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:30,692 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:30,695 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=51655
2011-08-09 19:43:30,696 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:30,697 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51655: starting
2011-08-09 19:43:30,698 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51655: starting
2011-08-09 19:43:30,698 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51655: starting
2011-08-09 19:43:30,698 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:53884, storageID=, infoPort=40834, ipcPort=51655)
2011-08-09 19:43:30,699 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51655: starting
2011-08-09 19:43:30,705 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:53884 storage DS-1376494208-10.0.62.238-53884-1312911810702
2011-08-09 19:43:30,705 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:53884
2011-08-09 19:43:30,713 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1376494208-10.0.62.238-53884-1312911810702 is assigned to data-node 127.0.0.1:53884
2011-08-09 19:43:30,714 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:53884, storageID=DS-1376494208-10.0.62.238-53884-1312911810702, infoPort=40834, ipcPort=51655)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:30,715 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:30,720 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:30,721 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:53884 0 blocks shortCircuit first report.
2011-08-09 19:43:30,722 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:30,722 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:30,723 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:30,744 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:30,748 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-7372220070207403053_1001
2011-08-09 19:43:30,751 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7372220070207403053_1001 src: /127.0.0.1:48024 dest: /127.0.0.1:46866
2011-08-09 19:43:30,753 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-7372220070207403053_1001 src: /127.0.0.1:40715 dest: /127.0.0.1:53884
2011-08-09 19:43:30,771 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40715, dest: /127.0.0.1:53884, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-696108213, offset: 0, srvID: DS-1376494208-10.0.62.238-53884-1312911810702, blockid: blk_-7372220070207403053_1001, duration: 3072887
2011-08-09 19:43:30,772 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-7372220070207403053_1001 terminating
2011-08-09 19:43:30,772 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53884 is added to blk_-7372220070207403053_1001 size 2048
2011-08-09 19:43:30,774 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:48024, dest: /127.0.0.1:46866, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-696108213, offset: 0, srvID: DS-156993566-10.0.62.238-46866-1312911810385, blockid: blk_-7372220070207403053_1001, duration: 17337669
2011-08-09 19:43:30,774 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:46866 is added to blk_-7372220070207403053_1001 size 2048
2011-08-09 19:43:30,776 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-7372220070207403053_1001 terminating
2011-08-09 19:43:30,785 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-696108213
2011-08-09 19:43:30,791 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/new/newfile	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:30,793 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/new/newfile. blk_-1702943362455937992_1002
2011-08-09 19:43:30,795 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1702943362455937992_1002 src: /127.0.0.1:48026 dest: /127.0.0.1:46866
2011-08-09 19:43:30,797 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1702943362455937992_1002 src: /127.0.0.1:40717 dest: /127.0.0.1:53884
2011-08-09 19:43:30,802 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40717, dest: /127.0.0.1:53884, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-696108213, offset: 0, srvID: DS-1376494208-10.0.62.238-53884-1312911810702, blockid: blk_-1702943362455937992_1002, duration: 2341274
2011-08-09 19:43:30,802 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1702943362455937992_1002 terminating
2011-08-09 19:43:30,805 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:48026, dest: /127.0.0.1:46866, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-696108213, offset: 0, srvID: DS-156993566-10.0.62.238-46866-1312911810385, blockid: blk_-1702943362455937992_1002, duration: 4693447
2011-08-09 19:43:30,805 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-1702943362455937992_1002 terminating
2011-08-09 19:43:30,806 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:53884 is added to blk_-1702943362455937992_1002 size 2048
2011-08-09 19:43:30,808 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:46866 is added to blk_-1702943362455937992_1002 size 2048
2011-08-09 19:43:30,809 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/new/newfile is closed by DFSClient_-696108213
2011-08-09 19:43:30,812 WARN  hdfs.StateChange (FSDirectory.java:unprotectedRenameTo(493)) - DIR* FSDirectory.unprotectedRenameTo: failed to rename /test/hadoop/file to /test/new/newfile because destination exists
2011-08-09 19:43:30,816 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:30,830 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7372220070207403053 is added to invalidSet of 127.0.0.1:53884
2011-08-09 19:43:30,831 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-7372220070207403053 is added to invalidSet of 127.0.0.1:46866
2011-08-09 19:43:30,831 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1702943362455937992 is added to invalidSet of 127.0.0.1:53884
2011-08-09 19:43:30,831 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1702943362455937992 is added to invalidSet of 127.0.0.1:46866
2011-08-09 19:43:30,832 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:30,834 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:30,834 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51655
2011-08-09 19:43:30,835 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51655: exiting
2011-08-09 19:43:30,835 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51655: exiting
2011-08-09 19:43:30,835 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51655: exiting
2011-08-09 19:43:30,835 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51655
2011-08-09 19:43:30,836 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:30,836 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:30,836 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:53884, storageID=DS-1376494208-10.0.62.238-53884-1312911810702, infoPort=40834, ipcPort=51655):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:31,724 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:31,836 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:31,838 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:53884, storageID=DS-1376494208-10.0.62.238-53884-1312911810702, infoPort=40834, ipcPort=51655):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:31,838 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51655
2011-08-09 19:43:31,838 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:31,839 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:31,839 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:31,840 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:31,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:31,852 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59464
2011-08-09 19:43:31,852 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 59464: exiting
2011-08-09 19:43:31,853 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 59464: exiting
2011-08-09 19:43:31,853 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 59464: exiting
2011-08-09 19:43:31,853 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 59464
2011-08-09 19:43:31,854 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:31,854 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:46866, storageID=DS-156993566-10.0.62.238-46866-1312911810385, infoPort=42505, ipcPort=59464):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:31,854 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:32,411 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:32,854 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:32,855 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:46866, storageID=DS-156993566-10.0.62.238-46866-1312911810385, infoPort=42505, ipcPort=59464):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:32,855 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59464
2011-08-09 19:43:32,855 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:32,856 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:32,856 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:32,857 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:32,871 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:32,972 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:32,972 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:32,973 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 10 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:14  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:5 
2011-08-09 19:43:32,975 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45493
2011-08-09 19:43:32,975 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45493: exiting
2011-08-09 19:43:32,976 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 45493: exiting
2011-08-09 19:43:32,976 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45493: exiting
2011-08-09 19:43:32,976 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 45493: exiting
2011-08-09 19:43:32,976 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45493: exiting
2011-08-09 19:43:32,976 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 45493: exiting
2011-08-09 19:43:32,977 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 45493: exiting
2011-08-09 19:43:32,977 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 45493: exiting
2011-08-09 19:43:32,977 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 45493: exiting
2011-08-09 19:43:32,978 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45493
2011-08-09 19:43:32,978 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:32,977 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 45493: exiting
2011-08-09 19:43:32,991 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:32,991 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:32,991 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:32,992 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:32,998 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:32,998 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:32,998 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:32,999 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:33,010 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:33,010 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:33,022 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:33,024 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:33,024 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:33,185 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:33,186 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:33,189 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:33,189 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:33,190 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:33,190 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:33,190 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:33,197 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:33,198 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:33,198 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:33,198 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:33,202 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:33,202 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:33,228 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:33,232 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:33,232 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:33,232 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:33,232 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:33,233 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:33,233 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:33,234 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:33,234 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:33,234 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:33,238 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:33,238 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:33,238 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:33,239 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:33,239 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:33,240 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:33,249 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=40448
2011-08-09 19:43:33,249 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:40448
2011-08-09 19:43:33,250 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:33,250 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 40448: starting
2011-08-09 19:43:33,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 40448: starting
2011-08-09 19:43:33,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 40448: starting
2011-08-09 19:43:33,250 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 40448: starting
2011-08-09 19:43:33,251 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 40448: starting
2011-08-09 19:43:33,251 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 40448: starting
2011-08-09 19:43:33,251 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 40448: starting
2011-08-09 19:43:33,251 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 40448: starting
2011-08-09 19:43:33,252 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 40448: starting
2011-08-09 19:43:33,252 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 40448: starting
2011-08-09 19:43:33,252 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 40448: starting
2011-08-09 19:43:33,261 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:33,261 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:33,261 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:33,262 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:33,262 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:33,268 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:33,268 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:33,268 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 41249 webServer.getConnectors()[0].getLocalPort() returned 41249
2011-08-09 19:43:33,269 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 41249
2011-08-09 19:43:33,269 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:33,314 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:41249
2011-08-09 19:43:33,314 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:41249
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:33,321 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:33,321 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:33,339 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:33,339 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:33,561 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:33,562 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54270
2011-08-09 19:43:33,562 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:33,565 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:33,566 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:33,566 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42672 webServer.getConnectors()[0].getLocalPort() returned 42672
2011-08-09 19:43:33,566 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42672
2011-08-09 19:43:33,566 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:33,623 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42672
2011-08-09 19:43:33,624 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:33,629 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:33,631 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=57293
2011-08-09 19:43:33,632 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:33,633 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57293: starting
2011-08-09 19:43:33,633 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57293: starting
2011-08-09 19:43:33,634 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57293: starting
2011-08-09 19:43:33,635 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57293: starting
2011-08-09 19:43:33,634 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54270, storageID=, infoPort=42672, ipcPort=57293)
2011-08-09 19:43:33,643 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54270 storage DS-307633812-10.0.62.238-54270-1312911813638
2011-08-09 19:43:33,643 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54270
2011-08-09 19:43:33,649 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-307633812-10.0.62.238-54270-1312911813638 is assigned to data-node 127.0.0.1:54270
2011-08-09 19:43:33,651 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54270, storageID=DS-307633812-10.0.62.238-54270-1312911813638, infoPort=42672, ipcPort=57293)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:33,689 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:33,693 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:33,694 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54270 0 blocks shortCircuit first report.
2011-08-09 19:43:33,695 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:33,695 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:33,696 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:33,729 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:33,729 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:33,746 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:33,746 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:33,949 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:33,950 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 60987
2011-08-09 19:43:33,951 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:33,953 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:33,954 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:33,954 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34436 webServer.getConnectors()[0].getLocalPort() returned 34436
2011-08-09 19:43:33,955 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34436
2011-08-09 19:43:33,955 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:34,011 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34436
2011-08-09 19:43:34,012 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:34,016 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:34,019 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=44815
2011-08-09 19:43:34,020 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:34,021 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44815: starting
2011-08-09 19:43:34,021 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44815: starting
2011-08-09 19:43:34,022 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44815: starting
2011-08-09 19:43:34,022 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:60987, storageID=, infoPort=34436, ipcPort=44815)
2011-08-09 19:43:34,023 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44815: starting
2011-08-09 19:43:34,029 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:60987 storage DS-1191421434-10.0.62.238-60987-1312911814025
2011-08-09 19:43:34,029 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:60987
2011-08-09 19:43:34,035 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1191421434-10.0.62.238-60987-1312911814025 is assigned to data-node 127.0.0.1:60987
2011-08-09 19:43:34,036 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:60987, storageID=DS-1191421434-10.0.62.238-60987-1312911814025, infoPort=34436, ipcPort=44815)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:34,037 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:34,072 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:34,074 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:60987 0 blocks shortCircuit first report.
2011-08-09 19:43:34,075 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:43:34,075 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:34,078 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:34,092 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:34,096 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_2835260985388779933_1001
2011-08-09 19:43:34,098 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2835260985388779933_1001 src: /127.0.0.1:53600 dest: /127.0.0.1:60987
2011-08-09 19:43:34,100 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_2835260985388779933_1001 src: /127.0.0.1:49302 dest: /127.0.0.1:54270
2011-08-09 19:43:34,147 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:49302, dest: /127.0.0.1:54270, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_708360320, offset: 0, srvID: DS-307633812-10.0.62.238-54270-1312911813638, blockid: blk_2835260985388779933_1001, duration: 2123299
2011-08-09 19:43:34,148 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_2835260985388779933_1001 terminating
2011-08-09 19:43:34,150 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:53600, dest: /127.0.0.1:60987, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_708360320, offset: 0, srvID: DS-1191421434-10.0.62.238-60987-1312911814025, blockid: blk_2835260985388779933_1001, duration: 44171768
2011-08-09 19:43:34,151 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_2835260985388779933_1001 terminating
2011-08-09 19:43:34,152 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:54270 is added to blk_2835260985388779933_1001 size 2048
2011-08-09 19:43:34,153 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:60987 is added to blk_2835260985388779933_1001 size 2048
2011-08-09 19:43:34,156 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_708360320
2011-08-09 19:43:34,161 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/new/newdir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:34,164 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=rename	src=/test/hadoop/file	dst=/test/new/newdir	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:34,167 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:34,170 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_2835260985388779933 is added to invalidSet of 127.0.0.1:54270
2011-08-09 19:43:34,171 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_2835260985388779933 is added to invalidSet of 127.0.0.1:60987
2011-08-09 19:43:34,172 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:34,174 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:34,175 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44815
2011-08-09 19:43:34,175 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44815: exiting
2011-08-09 19:43:34,176 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44815
2011-08-09 19:43:34,176 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44815: exiting
2011-08-09 19:43:34,176 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:34,177 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:34,176 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44815: exiting
2011-08-09 19:43:34,177 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:60987, storageID=DS-1191421434-10.0.62.238-60987-1312911814025, infoPort=34436, ipcPort=44815):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:35,081 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:35,177 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:35,179 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:60987, storageID=DS-1191421434-10.0.62.238-60987-1312911814025, infoPort=34436, ipcPort=44815):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:35,179 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44815
2011-08-09 19:43:35,179 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:35,206 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:35,206 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:35,207 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:35,242 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:35,343 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57293
2011-08-09 19:43:35,343 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57293: exiting
2011-08-09 19:43:35,343 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57293: exiting
2011-08-09 19:43:35,343 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57293: exiting
2011-08-09 19:43:35,344 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57293
2011-08-09 19:43:35,345 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:35,345 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54270, storageID=DS-307633812-10.0.62.238-54270-1312911813638, infoPort=42672, ipcPort=57293):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:35,345 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:35,697 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:36,268 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:60987 to delete  blk_2835260985388779933_1001
2011-08-09 19:43:36,345 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:36,345 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54270, storageID=DS-307633812-10.0.62.238-54270-1312911813638, infoPort=42672, ipcPort=57293):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:36,346 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57293
2011-08-09 19:43:36,346 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:36,347 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:36,347 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:36,348 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:36,349 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:36,450 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:36,450 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 9 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:36,451 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 40448
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 40448: exiting
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 40448: exiting
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 40448: exiting
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 40448: exiting
2011-08-09 19:43:36,453 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 40448: exiting
2011-08-09 19:43:36,454 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 40448: exiting
2011-08-09 19:43:36,454 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 40448: exiting
2011-08-09 19:43:36,454 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 40448: exiting
2011-08-09 19:43:36,454 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 40448: exiting
2011-08-09 19:43:36,454 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 40448: exiting
2011-08-09 19:43:36,455 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 40448
2011-08-09 19:43:36,455 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:36,468 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:36,468 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:36,468 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:36,468 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:36,474 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:36,474 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:36,474 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:36,475 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:36,488 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:36,488 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:36,500 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:36,503 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:36,503 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:36,667 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:36,668 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:36,671 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:36,671 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:36,671 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:36,671 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:36,671 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:36,681 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:36,682 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:36,682 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:36,682 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:36,685 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:36,686 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:36,711 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:36,716 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:36,716 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:36,716 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:36,716 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:36,717 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:36,718 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:36,718 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:36,718 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:36,719 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:36,722 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:36,722 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:36,722 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:36,722 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:36,723 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:36,724 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:36,726 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=45566
2011-08-09 19:43:36,727 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:45566
2011-08-09 19:43:36,727 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:36,727 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45566: starting
2011-08-09 19:43:36,728 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45566: starting
2011-08-09 19:43:36,728 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45566: starting
2011-08-09 19:43:36,728 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45566: starting
2011-08-09 19:43:36,728 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 45566: starting
2011-08-09 19:43:36,728 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 45566: starting
2011-08-09 19:43:36,729 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 45566: starting
2011-08-09 19:43:36,729 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 45566: starting
2011-08-09 19:43:36,729 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 45566: starting
2011-08-09 19:43:36,729 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 45566: starting
2011-08-09 19:43:36,729 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 45566: starting
2011-08-09 19:43:36,763 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:36,764 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:36,764 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:36,764 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:36,765 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:36,766 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:36,766 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:36,767 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 52337 webServer.getConnectors()[0].getLocalPort() returned 52337
2011-08-09 19:43:36,767 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 52337
2011-08-09 19:43:36,767 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:36,856 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:52337
2011-08-09 19:43:36,857 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:52337
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:36,863 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:36,864 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:36,881 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:36,881 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:37,102 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:37,103 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37631
2011-08-09 19:43:37,104 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:37,106 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:37,107 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:37,115 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 51559 webServer.getConnectors()[0].getLocalPort() returned 51559
2011-08-09 19:43:37,115 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 51559
2011-08-09 19:43:37,115 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:37,171 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:51559
2011-08-09 19:43:37,172 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:37,177 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:37,179 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=51059
2011-08-09 19:43:37,180 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:37,180 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 51059: starting
2011-08-09 19:43:37,181 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 51059: starting
2011-08-09 19:43:37,182 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 51059: starting
2011-08-09 19:43:37,182 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 51059: starting
2011-08-09 19:43:37,182 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37631, storageID=, infoPort=51559, ipcPort=51059)
2011-08-09 19:43:37,190 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37631 storage DS-572798733-10.0.62.238-37631-1312911817185
2011-08-09 19:43:37,190 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37631
2011-08-09 19:43:37,196 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-572798733-10.0.62.238-37631-1312911817185 is assigned to data-node 127.0.0.1:37631
2011-08-09 19:43:37,197 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37631, storageID=DS-572798733-10.0.62.238-37631-1312911817185, infoPort=51559, ipcPort=51059)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:37,215 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:37,221 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:37,229 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37631 0 blocks shortCircuit first report.
2011-08-09 19:43:37,230 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 8 msecs
2011-08-09 19:43:37,230 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:37,233 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:37,234 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:37,235 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:37,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:37,251 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:37,478 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:37,479 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 48613
2011-08-09 19:43:37,479 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:37,482 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:37,482 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:37,490 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48858 webServer.getConnectors()[0].getLocalPort() returned 48858
2011-08-09 19:43:37,490 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48858
2011-08-09 19:43:37,490 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:37,550 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48858
2011-08-09 19:43:37,551 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:37,556 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:37,558 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=54761
2011-08-09 19:43:37,559 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:37,560 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 54761: starting
2011-08-09 19:43:37,560 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 54761: starting
2011-08-09 19:43:37,561 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 54761: starting
2011-08-09 19:43:37,561 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:48613, storageID=, infoPort=48858, ipcPort=54761)
2011-08-09 19:43:37,562 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 54761: starting
2011-08-09 19:43:37,567 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:48613 storage DS-1241447986-10.0.62.238-48613-1312911817564
2011-08-09 19:43:37,567 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:48613
2011-08-09 19:43:37,575 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1241447986-10.0.62.238-48613-1312911817564 is assigned to data-node 127.0.0.1:48613
2011-08-09 19:43:37,576 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:48613, storageID=DS-1241447986-10.0.62.238-48613-1312911817564, infoPort=48858, ipcPort=54761)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:37,577 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:37,582 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:37,583 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:48613 0 blocks shortCircuit first report.
2011-08-09 19:43:37,584 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:37,584 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:37,586 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:37,623 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:37,625 WARN  hdfs.StateChange (FSDirectory.java:unprotectedRenameTo(499)) - DIR* FSDirectory.unprotectedRenameTo: failed to rename /test/hadoop/dir to /test/new/newdir because destination's parent does not exist
2011-08-09 19:43:37,630 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:37,635 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:37,670 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:37,771 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54761
2011-08-09 19:43:37,771 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 54761: exiting
2011-08-09 19:43:37,771 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 54761
2011-08-09 19:43:37,772 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 54761: exiting
2011-08-09 19:43:37,772 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:37,772 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:37,773 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:48613, storageID=DS-1241447986-10.0.62.238-48613-1312911817564, infoPort=48858, ipcPort=54761):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:37,771 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 54761: exiting
2011-08-09 19:43:38,611 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:38,773 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:38,774 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:48613, storageID=DS-1241447986-10.0.62.238-48613-1312911817564, infoPort=48858, ipcPort=54761):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:38,774 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 54761
2011-08-09 19:43:38,775 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:38,775 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:38,775 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:38,776 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:38,833 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:38,934 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51059
2011-08-09 19:43:38,934 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 51059: exiting
2011-08-09 19:43:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 51059: exiting
2011-08-09 19:43:38,935 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 51059: exiting
2011-08-09 19:43:38,936 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 51059
2011-08-09 19:43:38,937 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:38,938 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37631, storageID=DS-572798733-10.0.62.238-37631-1312911817185, infoPort=51559, ipcPort=51059):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:38,937 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:39,235 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:39,937 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:39,938 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37631, storageID=DS-572798733-10.0.62.238-37631-1312911817185, infoPort=51559, ipcPort=51059):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:39,939 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 51059
2011-08-09 19:43:39,939 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:39,940 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:39,940 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:39,941 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:39,988 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:40,089 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:40,090 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:40,090 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 4 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:40,092 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45566
2011-08-09 19:43:40,092 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 45566: exiting
2011-08-09 19:43:40,093 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 45566: exiting
2011-08-09 19:43:40,094 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 45566: exiting
2011-08-09 19:43:40,094 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 45566: exiting
2011-08-09 19:43:40,094 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45566
2011-08-09 19:43:40,096 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:40,107 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:40,107 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:40,108 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:40,108 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:40,113 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:40,113 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:40,114 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:40,114 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:40,127 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:40,128 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:40,140 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:40,143 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:40,143 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:40,309 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:40,310 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:40,313 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:40,314 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:40,314 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:40,314 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:40,314 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:40,319 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:40,320 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:40,320 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:40,320 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:40,324 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:40,324 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:40,350 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:40,354 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:40,354 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:40,355 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:40,355 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:40,355 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:40,356 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:40,356 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:40,356 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 37 msecs
2011-08-09 19:43:40,357 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:40,360 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:40,360 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:40,360 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:40,360 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:40,360 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:40,361 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:40,364 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=58502
2011-08-09 19:43:40,365 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:58502
2011-08-09 19:43:40,365 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:40,365 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 58502: starting
2011-08-09 19:43:40,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 58502: starting
2011-08-09 19:43:40,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 58502: starting
2011-08-09 19:43:40,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 58502: starting
2011-08-09 19:43:40,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 58502: starting
2011-08-09 19:43:40,366 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 58502: starting
2011-08-09 19:43:40,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 58502: starting
2011-08-09 19:43:40,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 58502: starting
2011-08-09 19:43:40,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 58502: starting
2011-08-09 19:43:40,367 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 58502: starting
2011-08-09 19:43:40,368 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 58502: starting
2011-08-09 19:43:40,376 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:40,376 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:40,377 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:40,377 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:40,377 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:40,414 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:40,415 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:40,415 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 37780 webServer.getConnectors()[0].getLocalPort() returned 37780
2011-08-09 19:43:40,415 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 37780
2011-08-09 19:43:40,415 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:40,472 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:37780
2011-08-09 19:43:40,473 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:37780
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:40,479 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:40,480 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:40,495 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:40,496 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:40,694 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:40,695 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 54688
2011-08-09 19:43:40,696 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:40,698 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:40,699 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:40,699 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42741 webServer.getConnectors()[0].getLocalPort() returned 42741
2011-08-09 19:43:40,699 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42741
2011-08-09 19:43:40,699 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:40,756 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42741
2011-08-09 19:43:40,756 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:40,761 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:40,764 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=35528
2011-08-09 19:43:40,765 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:40,766 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 35528: starting
2011-08-09 19:43:40,766 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 35528: starting
2011-08-09 19:43:40,767 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:54688, storageID=, infoPort=42741, ipcPort=35528)
2011-08-09 19:43:40,767 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 35528: starting
2011-08-09 19:43:40,768 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 35528: starting
2011-08-09 19:43:40,775 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:54688 storage DS-1808584663-10.0.62.238-54688-1312911820771
2011-08-09 19:43:40,776 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:54688
2011-08-09 19:43:40,782 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1808584663-10.0.62.238-54688-1312911820771 is assigned to data-node 127.0.0.1:54688
2011-08-09 19:43:40,783 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:54688, storageID=DS-1808584663-10.0.62.238-54688-1312911820771, infoPort=42741, ipcPort=35528)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:40,820 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:40,857 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:40,858 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:40,859 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:40,860 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:54688 0 blocks shortCircuit first report.
2011-08-09 19:43:40,860 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:40,861 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:40,861 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:40,874 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:40,874 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:41,098 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:41,099 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 36270
2011-08-09 19:43:41,100 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:41,102 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:41,103 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:41,103 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 34536 webServer.getConnectors()[0].getLocalPort() returned 34536
2011-08-09 19:43:41,103 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 34536
2011-08-09 19:43:41,103 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:41,161 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:34536
2011-08-09 19:43:41,161 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:41,167 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:41,169 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=60911
2011-08-09 19:43:41,171 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:41,171 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 60911: starting
2011-08-09 19:43:41,172 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 60911: starting
2011-08-09 19:43:41,173 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 60911: starting
2011-08-09 19:43:41,173 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:36270, storageID=, infoPort=34536, ipcPort=60911)
2011-08-09 19:43:41,174 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 60911: starting
2011-08-09 19:43:41,179 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:36270 storage DS-674283241-10.0.62.238-36270-1312911821176
2011-08-09 19:43:41,179 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:36270
2011-08-09 19:43:41,187 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-674283241-10.0.62.238-36270-1312911821176 is assigned to data-node 127.0.0.1:36270
2011-08-09 19:43:41,188 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:36270, storageID=DS-674283241-10.0.62.238-36270-1312911821176, infoPort=34536, ipcPort=60911)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:41,189 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:41,194 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:41,195 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:36270 0 blocks shortCircuit first report.
2011-08-09 19:43:41,196 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:41,196 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:41,198 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:41,212 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:41,217 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/dir/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:41,221 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/dir/file1. blk_-8109993313104277561_1001
2011-08-09 19:43:41,224 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8109993313104277561_1001 src: /127.0.0.1:42923 dest: /127.0.0.1:36270
2011-08-09 19:43:41,226 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8109993313104277561_1001 src: /127.0.0.1:40486 dest: /127.0.0.1:54688
2011-08-09 19:43:41,232 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:40486, dest: /127.0.0.1:54688, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1835106556, offset: 0, srvID: DS-1808584663-10.0.62.238-54688-1312911820771, blockid: blk_-8109993313104277561_1001, duration: 3019510
2011-08-09 19:43:41,232 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-8109993313104277561_1001 terminating
2011-08-09 19:43:41,277 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:54688 is added to blk_-8109993313104277561_1001 size 2048
2011-08-09 19:43:41,278 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:36270 is added to blk_-8109993313104277561_1001 size 2048
2011-08-09 19:43:41,277 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:42923, dest: /127.0.0.1:36270, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1835106556, offset: 0, srvID: DS-674283241-10.0.62.238-36270-1312911821176, blockid: blk_-8109993313104277561_1001, duration: 5064840
2011-08-09 19:43:41,281 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-8109993313104277561_1001 terminating
2011-08-09 19:43:41,283 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/dir/file1 is closed by DFSClient_1835106556
2011-08-09 19:43:41,288 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/dir/subdir/file2	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:41,289 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/dir/subdir/file2. blk_5525056207163049818_1002
2011-08-09 19:43:41,291 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5525056207163049818_1002 src: /127.0.0.1:40487 dest: /127.0.0.1:54688
2011-08-09 19:43:41,293 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5525056207163049818_1002 src: /127.0.0.1:42926 dest: /127.0.0.1:36270
2011-08-09 19:43:41,297 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:42926, dest: /127.0.0.1:36270, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1835106556, offset: 0, srvID: DS-674283241-10.0.62.238-36270-1312911821176, blockid: blk_5525056207163049818_1002, duration: 2527111
2011-08-09 19:43:41,298 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5525056207163049818_1002 terminating
2011-08-09 19:43:41,298 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:40487, dest: /127.0.0.1:54688, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_1835106556, offset: 0, srvID: DS-1808584663-10.0.62.238-54688-1312911820771, blockid: blk_5525056207163049818_1002, duration: 2152361
2011-08-09 19:43:41,299 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:54688 is added to blk_5525056207163049818_1002 size 2048
2011-08-09 19:43:41,319 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:36270 is added to blk_5525056207163049818_1002 size 2048
2011-08-09 19:43:41,321 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5525056207163049818_1002 terminating
2011-08-09 19:43:41,322 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/dir/subdir/file2 is closed by DFSClient_1835106556
2011-08-09 19:43:41,327 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/new	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:41,481 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=rename	src=/test/hadoop/dir	dst=/test/new/newdir	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:41,486 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:41,488 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-8109993313104277561 is added to invalidSet of 127.0.0.1:54688
2011-08-09 19:43:41,488 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-8109993313104277561 is added to invalidSet of 127.0.0.1:36270
2011-08-09 19:43:41,489 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5525056207163049818 is added to invalidSet of 127.0.0.1:54688
2011-08-09 19:43:41,489 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5525056207163049818 is added to invalidSet of 127.0.0.1:36270
2011-08-09 19:43:41,490 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:41,535 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:41,535 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60911
2011-08-09 19:43:41,536 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 60911: exiting
2011-08-09 19:43:41,536 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 60911: exiting
2011-08-09 19:43:41,536 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 60911: exiting
2011-08-09 19:43:41,536 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 60911
2011-08-09 19:43:41,537 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:41,537 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:41,537 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:36270, storageID=DS-674283241-10.0.62.238-36270-1312911821176, infoPort=34536, ipcPort=60911):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:42,200 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:42,537 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:42,538 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:36270, storageID=DS-674283241-10.0.62.238-36270-1312911821176, infoPort=34536, ipcPort=60911):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:42,538 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 60911
2011-08-09 19:43:42,538 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:42,539 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:42,539 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:42,540 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:42,541 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:42,542 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35528
2011-08-09 19:43:42,543 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 35528
2011-08-09 19:43:42,543 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 35528: exiting
2011-08-09 19:43:42,543 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 35528: exiting
2011-08-09 19:43:42,544 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 35528: exiting
2011-08-09 19:43:42,544 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:42,544 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:54688, storageID=DS-1808584663-10.0.62.238-54688-1312911820771, infoPort=42741, ipcPort=35528):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:42,545 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:42,545 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:42,545 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:54688, storageID=DS-1808584663-10.0.62.238-54688-1312911820771, infoPort=42741, ipcPort=35528):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:42,546 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35528
2011-08-09 19:43:42,546 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:42,547 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:42,547 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:42,548 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:42,594 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:42,695 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:42,696 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:42,696 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 13 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:7 
2011-08-09 19:43:42,698 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 58502
2011-08-09 19:43:42,698 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 58502: exiting
2011-08-09 19:43:42,698 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 58502: exiting
2011-08-09 19:43:42,699 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 58502: exiting
2011-08-09 19:43:42,699 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 58502: exiting
2011-08-09 19:43:42,699 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 58502: exiting
2011-08-09 19:43:42,699 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 58502: exiting
2011-08-09 19:43:42,699 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 58502: exiting
2011-08-09 19:43:42,700 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 58502: exiting
2011-08-09 19:43:42,700 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 58502: exiting
2011-08-09 19:43:42,700 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 58502: exiting
2011-08-09 19:43:42,701 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 58502
2011-08-09 19:43:42,702 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:42,714 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:42,714 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:42,714 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:42,714 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:42,763 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:42,763 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:42,764 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:42,764 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:42,774 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:42,774 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:42,785 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:42,788 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:42,788 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:42,799 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:42,800 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:42,803 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:42,804 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:42,826 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:42,826 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:42,826 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:42,830 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:42,830 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:42,830 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:42,830 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:42,834 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:42,834 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:42,834 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:42,838 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:42,838 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:42,838 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:42,839 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:42,839 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:42,839 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:42,957 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:42,958 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 128 msecs
2011-08-09 19:43:42,959 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:42,962 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:42,963 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:42,963 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:42,963 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:42,963 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:42,965 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:42,967 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=59033
2011-08-09 19:43:42,968 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:59033
2011-08-09 19:43:42,969 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:42,969 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 59033: starting
2011-08-09 19:43:42,969 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 59033: starting
2011-08-09 19:43:42,969 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 59033: starting
2011-08-09 19:43:42,970 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 59033: starting
2011-08-09 19:43:42,970 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 59033: starting
2011-08-09 19:43:42,970 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 59033: starting
2011-08-09 19:43:42,970 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 59033: starting
2011-08-09 19:43:42,970 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 59033: starting
2011-08-09 19:43:42,971 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 59033: starting
2011-08-09 19:43:42,971 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 59033: starting
2011-08-09 19:43:42,971 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 59033: starting
2011-08-09 19:43:42,992 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:42,992 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:42,993 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:42,993 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:42,993 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:42,996 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:42,996 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:42,996 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 49060 webServer.getConnectors()[0].getLocalPort() returned 49060
2011-08-09 19:43:42,996 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 49060
2011-08-09 19:43:42,997 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:43,034 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:49060
2011-08-09 19:43:43,035 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:49060
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:43,041 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:43,041 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:43,058 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:43,059 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:43,279 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:43,280 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 46932
2011-08-09 19:43:43,281 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:43,283 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:43,284 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:43,284 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 52946 webServer.getConnectors()[0].getLocalPort() returned 52946
2011-08-09 19:43:43,284 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 52946
2011-08-09 19:43:43,284 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:43,350 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:52946
2011-08-09 19:43:43,350 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:43,355 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:43,358 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=45483
2011-08-09 19:43:43,359 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:43,360 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 45483: starting
2011-08-09 19:43:43,360 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 45483: starting
2011-08-09 19:43:43,361 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 45483: starting
2011-08-09 19:43:43,361 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:46932, storageID=, infoPort=52946, ipcPort=45483)
2011-08-09 19:43:43,362 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 45483: starting
2011-08-09 19:43:43,367 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:46932 storage DS-930289475-10.0.62.238-46932-1312911823364
2011-08-09 19:43:43,368 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:46932
2011-08-09 19:43:43,374 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-930289475-10.0.62.238-46932-1312911823364 is assigned to data-node 127.0.0.1:46932
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:43,375 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:46932, storageID=DS-930289475-10.0.62.238-46932-1312911823364, infoPort=52946, ipcPort=45483)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:43,376 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:43,415 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:43,418 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:46932 0 blocks shortCircuit first report.
2011-08-09 19:43:43,418 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:43,418 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:43,420 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:43,421 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:43,421 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:43,437 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:43,437 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:43,652 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:43,653 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 33754
2011-08-09 19:43:43,653 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:43,656 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:43,656 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:43,657 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48527 webServer.getConnectors()[0].getLocalPort() returned 48527
2011-08-09 19:43:43,657 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48527
2011-08-09 19:43:43,657 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:43,726 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48527
2011-08-09 19:43:43,726 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:43,731 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:43,733 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=57452
2011-08-09 19:43:43,734 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:43,735 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 57452: starting
2011-08-09 19:43:43,735 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 57452: starting
2011-08-09 19:43:43,735 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 57452: starting
2011-08-09 19:43:43,736 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:33754, storageID=, infoPort=48527, ipcPort=57452)
2011-08-09 19:43:43,736 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 57452: starting
2011-08-09 19:43:43,741 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:33754 storage DS-1569027763-10.0.62.238-33754-1312911823739
2011-08-09 19:43:43,741 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:33754
2011-08-09 19:43:43,748 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1569027763-10.0.62.238-33754-1312911823739 is assigned to data-node 127.0.0.1:33754
2011-08-09 19:43:43,749 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:33754, storageID=DS-1569027763-10.0.62.238-33754-1312911823739, infoPort=48527, ipcPort=57452)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:43,750 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:43,757 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:43,759 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:33754 0 blocks shortCircuit first report.
2011-08-09 19:43:43,761 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:43:43,764 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:43,765 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:43,774 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:43,779 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/new/newfile	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:43,783 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/new/newfile. blk_-1512046798874955446_1001
2011-08-09 19:43:43,784 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1512046798874955446_1001 src: /127.0.0.1:48342 dest: /127.0.0.1:33754
2011-08-09 19:43:43,787 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-1512046798874955446_1001 src: /127.0.0.1:41212 dest: /127.0.0.1:46932
2011-08-09 19:43:43,792 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:46932 is added to blk_-1512046798874955446_1001 size 2048
2011-08-09 19:43:43,792 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:41212, dest: /127.0.0.1:46932, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-589468527, offset: 0, srvID: DS-930289475-10.0.62.238-46932-1312911823364, blockid: blk_-1512046798874955446_1001, duration: 1337750
2011-08-09 19:43:43,793 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-1512046798874955446_1001 terminating
2011-08-09 19:43:43,794 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:48342, dest: /127.0.0.1:33754, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-589468527, offset: 0, srvID: DS-1569027763-10.0.62.238-33754-1312911823739, blockid: blk_-1512046798874955446_1001, duration: 2465909
2011-08-09 19:43:43,794 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:33754 is added to blk_-1512046798874955446_1001 size 2048
2011-08-09 19:43:43,795 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-1512046798874955446_1001 terminating
2011-08-09 19:43:43,799 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/new/newfile is closed by DFSClient_-589468527
2011-08-09 19:43:43,803 WARN  hdfs.StateChange (FSDirectory.java:unprotectedRenameTo(493)) - DIR* FSDirectory.unprotectedRenameTo: failed to rename /test/hadoop/dir to /test/new/newfile because destination exists
2011-08-09 19:43:43,807 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:43,810 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1512046798874955446 is added to invalidSet of 127.0.0.1:46932
2011-08-09 19:43:43,810 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-1512046798874955446 is added to invalidSet of 127.0.0.1:33754
2011-08-09 19:43:43,812 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:43,894 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:43,994 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57452
2011-08-09 19:43:43,995 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 57452: exiting
2011-08-09 19:43:43,995 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 57452: exiting
2011-08-09 19:43:43,995 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 57452: exiting
2011-08-09 19:43:43,996 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 57452
2011-08-09 19:43:43,996 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:43,996 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:43,997 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:33754, storageID=DS-1569027763-10.0.62.238-33754-1312911823739, infoPort=48527, ipcPort=57452):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:44,766 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:44,997 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:44,998 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:33754, storageID=DS-1569027763-10.0.62.238-33754-1312911823739, infoPort=48527, ipcPort=57452):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:44,999 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 57452
2011-08-09 19:43:44,999 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:45,000 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:45,000 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:45,001 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:45,002 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:45,003 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45483
2011-08-09 19:43:45,004 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 45483: exiting
2011-08-09 19:43:45,004 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 45483: exiting
2011-08-09 19:43:45,005 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 45483
2011-08-09 19:43:45,005 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 45483: exiting
2011-08-09 19:43:45,006 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:45,006 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:45,006 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:46932, storageID=DS-930289475-10.0.62.238-46932-1312911823364, infoPort=52946, ipcPort=45483):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:45,422 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:45,995 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:33754 to delete  blk_-1512046798874955446_1001
2011-08-09 19:43:46,007 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:46,007 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:46932, storageID=DS-930289475-10.0.62.238-46932-1312911823364, infoPort=52946, ipcPort=45483):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:46,008 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 45483
2011-08-09 19:43:46,008 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:46,008 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:46,009 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:46,009 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:46,011 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:46,012 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:46,012 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 8 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:6 
2011-08-09 19:43:46,012 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:46,015 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 59033
2011-08-09 19:43:46,015 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 59033: exiting
2011-08-09 19:43:46,015 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 59033: exiting
2011-08-09 19:43:46,015 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 59033: exiting
2011-08-09 19:43:46,016 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 59033: exiting
2011-08-09 19:43:46,016 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 59033: exiting
2011-08-09 19:43:46,016 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 59033: exiting
2011-08-09 19:43:46,016 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 59033: exiting
2011-08-09 19:43:46,016 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 59033: exiting
2011-08-09 19:43:46,017 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 59033: exiting
2011-08-09 19:43:46,017 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 59033: exiting
2011-08-09 19:43:46,018 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 59033
2011-08-09 19:43:46,019 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:46,033 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:46,034 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:46,034 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:46,034 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:46,041 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:46,042 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:46,042 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:46,042 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:46,050 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:46,050 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:46,061 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:46,063 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:46,064 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:46,074 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:46,075 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:46,102 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:46,102 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:46,102 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:46,103 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:46,103 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:46,106 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:46,106 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:46,107 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:46,107 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:46,110 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:46,110 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:46,111 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:46,114 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:46,115 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:46,115 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:46,115 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:46,115 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:46,116 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:46,273 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:46,274 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 168 msecs
2011-08-09 19:43:46,274 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:46,278 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:46,279 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:46,279 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:46,280 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:46,280 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:46,282 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:46,284 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=53753
2011-08-09 19:43:46,285 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:53753
2011-08-09 19:43:46,286 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:46,286 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 53753: starting
2011-08-09 19:43:46,286 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 53753: starting
2011-08-09 19:43:46,286 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 53753: starting
2011-08-09 19:43:46,287 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 53753: starting
2011-08-09 19:43:46,288 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 53753: starting
2011-08-09 19:43:46,288 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 53753: starting
2011-08-09 19:43:46,296 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:46,297 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:46,297 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:46,297 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:46,298 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:46,305 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:46,305 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:46,305 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 32850 webServer.getConnectors()[0].getLocalPort() returned 32850
2011-08-09 19:43:46,305 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 32850
2011-08-09 19:43:46,306 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:46,343 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:32850
2011-08-09 19:43:46,344 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:32850
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:46,350 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:46,350 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:46,366 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:46,366 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:46,556 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:46,558 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 34076
2011-08-09 19:43:46,558 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:46,560 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:46,561 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:46,561 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 39948 webServer.getConnectors()[0].getLocalPort() returned 39948
2011-08-09 19:43:46,561 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 39948
2011-08-09 19:43:46,562 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:46,647 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:39948
2011-08-09 19:43:46,648 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:46,688 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:46,691 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=35004
2011-08-09 19:43:46,692 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:46,693 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 35004: starting
2011-08-09 19:43:46,708 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 35004: starting
2011-08-09 19:43:46,709 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 35004: starting
2011-08-09 19:43:46,709 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:34076, storageID=, infoPort=39948, ipcPort=35004)
2011-08-09 19:43:46,710 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 35004: starting
2011-08-09 19:43:46,715 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:34076 storage DS-1580793159-10.0.62.238-34076-1312911826713
2011-08-09 19:43:46,716 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:34076
2011-08-09 19:43:46,722 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1580793159-10.0.62.238-34076-1312911826713 is assigned to data-node 127.0.0.1:34076
2011-08-09 19:43:46,723 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:34076, storageID=DS-1580793159-10.0.62.238-34076-1312911826713, infoPort=39948, ipcPort=35004)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:46,724 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:46,751 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:46,759 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:34076 0 blocks shortCircuit first report.
2011-08-09 19:43:46,760 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 9 msecs
2011-08-09 19:43:46,760 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:46,762 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:46,762 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:46,763 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:46,780 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:46,780 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:46,977 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:46,978 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38849
2011-08-09 19:43:46,978 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:46,981 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:46,981 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:46,982 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 48974 webServer.getConnectors()[0].getLocalPort() returned 48974
2011-08-09 19:43:46,982 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 48974
2011-08-09 19:43:46,982 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:47,053 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:48974
2011-08-09 19:43:47,053 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:47,058 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:47,061 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=37102
2011-08-09 19:43:47,061 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:47,062 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 37102: starting
2011-08-09 19:43:47,062 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 37102: starting
2011-08-09 19:43:47,063 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 37102: starting
2011-08-09 19:43:47,063 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38849, storageID=, infoPort=48974, ipcPort=37102)
2011-08-09 19:43:47,064 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 37102: starting
2011-08-09 19:43:47,068 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38849 storage DS-1684389809-10.0.62.238-38849-1312911827066
2011-08-09 19:43:47,069 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38849
2011-08-09 19:43:47,074 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1684389809-10.0.62.238-38849-1312911827066 is assigned to data-node 127.0.0.1:38849
2011-08-09 19:43:47,075 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38849, storageID=DS-1684389809-10.0.62.238-38849-1312911827066, infoPort=48974, ipcPort=37102)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:47,077 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:47,082 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:47,083 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38849 0 blocks shortCircuit first report.
2011-08-09 19:43:47,084 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:47,084 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:47,087 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:47,099 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop/dir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:47,106 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/dir/file1	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:47,110 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/dir/file1. blk_5315786735879626608_1001
2011-08-09 19:43:47,113 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5315786735879626608_1001 src: /127.0.0.1:55348 dest: /127.0.0.1:38849
2011-08-09 19:43:47,115 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_5315786735879626608_1001 src: /127.0.0.1:60196 dest: /127.0.0.1:34076
2011-08-09 19:43:47,120 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:60196, dest: /127.0.0.1:34076, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_370754220, offset: 0, srvID: DS-1580793159-10.0.62.238-34076-1312911826713, blockid: blk_5315786735879626608_1001, duration: 2138388
2011-08-09 19:43:47,121 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_5315786735879626608_1001 terminating
2011-08-09 19:43:47,122 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34076 is added to blk_5315786735879626608_1001 size 2048
2011-08-09 19:43:47,132 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:55348, dest: /127.0.0.1:38849, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_370754220, offset: 0, srvID: DS-1684389809-10.0.62.238-38849-1312911827066, blockid: blk_5315786735879626608_1001, duration: 12266667
2011-08-09 19:43:47,132 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_5315786735879626608_1001 terminating
2011-08-09 19:43:47,134 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:38849 is added to blk_5315786735879626608_1001 size 2048
2011-08-09 19:43:47,170 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/dir/file1 is closed by DFSClient_370754220
2011-08-09 19:43:47,175 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/dir/subdir/file2	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:47,178 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/dir/subdir/file2. blk_-2485181186332944741_1002
2011-08-09 19:43:47,179 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2485181186332944741_1002 src: /127.0.0.1:55350 dest: /127.0.0.1:38849
2011-08-09 19:43:47,181 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-2485181186332944741_1002 src: /127.0.0.1:60198 dest: /127.0.0.1:34076
2011-08-09 19:43:47,186 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:60198, dest: /127.0.0.1:34076, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_370754220, offset: 0, srvID: DS-1580793159-10.0.62.238-34076-1312911826713, blockid: blk_-2485181186332944741_1002, duration: 2651467
2011-08-09 19:43:47,186 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:34076 is added to blk_-2485181186332944741_1002 size 2048
2011-08-09 19:43:47,187 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-2485181186332944741_1002 terminating
2011-08-09 19:43:47,189 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:55350, dest: /127.0.0.1:38849, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_370754220, offset: 0, srvID: DS-1684389809-10.0.62.238-38849-1312911827066, blockid: blk_-2485181186332944741_1002, duration: 4687015
2011-08-09 19:43:47,189 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-2485181186332944741_1002 terminating
2011-08-09 19:43:47,190 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:38849 is added to blk_-2485181186332944741_1002 size 2048
2011-08-09 19:43:47,192 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/dir/subdir/file2 is closed by DFSClient_370754220
2011-08-09 19:43:47,197 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=mkdirs	src=/test/new/newdir	dst=null	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:47,200 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=rename	src=/test/hadoop/dir	dst=/test/new/newdir	perm=jeff:supergroup:rwxr-xr-x
2011-08-09 19:43:47,207 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:47,209 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5315786735879626608 is added to invalidSet of 127.0.0.1:34076
2011-08-09 19:43:47,209 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_5315786735879626608 is added to invalidSet of 127.0.0.1:38849
2011-08-09 19:43:47,210 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-2485181186332944741 is added to invalidSet of 127.0.0.1:34076
2011-08-09 19:43:47,210 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-2485181186332944741 is added to invalidSet of 127.0.0.1:38849
2011-08-09 19:43:47,212 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:47,267 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:47,368 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37102
2011-08-09 19:43:47,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 37102: exiting
2011-08-09 19:43:47,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 37102: exiting
2011-08-09 19:43:47,368 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 37102: exiting
2011-08-09 19:43:47,369 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 37102
2011-08-09 19:43:47,369 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:47,370 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:47,370 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38849, storageID=DS-1684389809-10.0.62.238-38849-1312911827066, infoPort=48974, ipcPort=37102):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:48,089 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:48,370 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:48,372 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38849, storageID=DS-1684389809-10.0.62.238-38849-1312911827066, infoPort=48974, ipcPort=37102):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:48,372 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 37102
2011-08-09 19:43:48,372 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:48,373 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:48,373 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:48,374 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:48,375 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:48,476 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35004
2011-08-09 19:43:48,476 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 35004: exiting
2011-08-09 19:43:48,476 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:48,477 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:48,477 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 35004
2011-08-09 19:43:48,478 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 35004: exiting
2011-08-09 19:43:48,478 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 35004: exiting
2011-08-09 19:43:48,478 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:34076, storageID=DS-1580793159-10.0.62.238-34076-1312911826713, infoPort=39948, ipcPort=35004):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:48,764 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:49,305 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:34076 to delete  blk_5315786735879626608_1001 blk_-2485181186332944741_1002
2011-08-09 19:43:49,477 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:49,478 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:34076, storageID=DS-1580793159-10.0.62.238-34076-1312911826713, infoPort=39948, ipcPort=35004):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:49,478 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 35004
2011-08-09 19:43:49,478 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:49,479 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:49,479 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:49,480 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:49,524 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:49,525 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:49,526 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 14 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:11  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:7 
2011-08-09 19:43:49,526 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:49,528 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 53753
2011-08-09 19:43:49,529 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 53753: exiting
2011-08-09 19:43:49,529 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 53753: exiting
2011-08-09 19:43:49,529 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 53753
2011-08-09 19:43:49,529 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 53753: exiting
2011-08-09 19:43:49,530 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 53753: exiting
2011-08-09 19:43:49,530 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 53753: exiting
2011-08-09 19:43:49,530 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 53753: exiting
2011-08-09 19:43:49,531 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 53753: exiting
2011-08-09 19:43:49,531 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 53753: exiting
2011-08-09 19:43:49,531 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 53753: exiting
2011-08-09 19:43:49,531 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 53753: exiting
2011-08-09 19:43:49,531 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:49,545 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:49,545 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:49,545 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:49,545 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:49,553 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:49,553 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:49,553 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:49,554 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:49,562 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:49,562 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:49,574 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:49,576 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:49,577 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:49,588 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:49,588 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:49,592 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:49,592 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:49,592 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:49,592 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:49,616 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:49,621 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:49,621 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:49,621 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:49,622 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:49,625 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:49,625 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:49,626 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:49,630 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:49,630 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:49,630 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:49,630 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:49,631 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:49,632 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:49,790 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:49,791 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 170 msecs
2011-08-09 19:43:49,791 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:49,795 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:49,795 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:49,795 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:49,795 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:49,796 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:49,797 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:49,800 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=44768
2011-08-09 19:43:49,801 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:44768
2011-08-09 19:43:49,801 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:49,801 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 44768: starting
2011-08-09 19:43:49,801 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 44768: starting
2011-08-09 19:43:49,802 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 44768: starting
2011-08-09 19:43:49,802 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 44768: starting
2011-08-09 19:43:49,802 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 44768: starting
2011-08-09 19:43:49,803 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 44768: starting
2011-08-09 19:43:49,803 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 44768: starting
2011-08-09 19:43:49,803 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 44768: starting
2011-08-09 19:43:49,803 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 44768: starting
2011-08-09 19:43:49,803 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 44768: starting
2011-08-09 19:43:49,804 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 44768: starting
2011-08-09 19:43:49,833 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:49,834 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:49,834 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:49,834 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:49,878 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:49,880 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:49,880 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:49,880 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 57955 webServer.getConnectors()[0].getLocalPort() returned 57955
2011-08-09 19:43:49,880 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 57955
2011-08-09 19:43:49,881 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:49,943 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:57955
2011-08-09 19:43:49,943 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:57955
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:49,950 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:49,950 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:49,965 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:49,966 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:50,179 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:50,180 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 38614
2011-08-09 19:43:50,180 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:50,183 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:50,184 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:50,184 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 33900 webServer.getConnectors()[0].getLocalPort() returned 33900
2011-08-09 19:43:50,184 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 33900
2011-08-09 19:43:50,184 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:50,307 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:33900
2011-08-09 19:43:50,308 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:50,313 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:50,315 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=33243
2011-08-09 19:43:50,316 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:50,317 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 33243: starting
2011-08-09 19:43:50,317 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 33243: starting
2011-08-09 19:43:50,318 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 33243: starting
2011-08-09 19:43:50,318 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:38614, storageID=, infoPort=33900, ipcPort=33243)
2011-08-09 19:43:50,319 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 33243: starting
2011-08-09 19:43:50,323 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:38614 storage DS-1892658419-10.0.62.238-38614-1312911830321
2011-08-09 19:43:50,324 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:38614
2011-08-09 19:43:50,329 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1892658419-10.0.62.238-38614-1312911830321 is assigned to data-node 127.0.0.1:38614
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:50,331 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:38614, storageID=DS-1892658419-10.0.62.238-38614-1312911830321, infoPort=33900, ipcPort=33243)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:50,333 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:50,377 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:50,378 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:38614 0 blocks shortCircuit first report.
2011-08-09 19:43:50,379 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 2 msecs
2011-08-09 19:43:50,379 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:50,380 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:50,419 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:50,419 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:50,434 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:50,435 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:50,629 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:50,630 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 59117
2011-08-09 19:43:50,631 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:50,633 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:50,634 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:50,634 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 44190 webServer.getConnectors()[0].getLocalPort() returned 44190
2011-08-09 19:43:50,634 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 44190
2011-08-09 19:43:50,635 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:50,702 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:44190
2011-08-09 19:43:50,703 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:50,708 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:50,710 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=47858
2011-08-09 19:43:50,712 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:50,713 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47858: starting
2011-08-09 19:43:50,714 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47858: starting
2011-08-09 19:43:50,714 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47858: starting
2011-08-09 19:43:50,714 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:59117, storageID=, infoPort=44190, ipcPort=47858)
2011-08-09 19:43:50,715 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47858: starting
2011-08-09 19:43:50,721 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:59117 storage DS-2044945012-10.0.62.238-59117-1312911830718
2011-08-09 19:43:50,721 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:59117
2011-08-09 19:43:50,728 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-2044945012-10.0.62.238-59117-1312911830718 is assigned to data-node 127.0.0.1:59117
2011-08-09 19:43:50,729 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:59117, storageID=DS-2044945012-10.0.62.238-59117-1312911830718, infoPort=44190, ipcPort=47858)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:50,730 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:50,735 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:50,736 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:59117 0 blocks shortCircuit first report.
2011-08-09 19:43:50,738 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:50,738 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:50,779 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:50,795 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:50,799 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_-8977171315694840933_1001
2011-08-09 19:43:50,801 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8977171315694840933_1001 src: /127.0.0.1:40865 dest: /127.0.0.1:59117
2011-08-09 19:43:50,803 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_-8977171315694840933_1001 src: /127.0.0.1:51996 dest: /127.0.0.1:38614
2011-08-09 19:43:50,809 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:51996, dest: /127.0.0.1:38614, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-150613625, offset: 0, srvID: DS-1892658419-10.0.62.238-38614-1312911830321, blockid: blk_-8977171315694840933_1001, duration: 2711549
2011-08-09 19:43:50,809 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_-8977171315694840933_1001 terminating
2011-08-09 19:43:50,811 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:40865, dest: /127.0.0.1:59117, bytes: 2048, op: HDFS_WRITE, cliID: DFSClient_-150613625, offset: 0, srvID: DS-2044945012-10.0.62.238-59117-1312911830718, blockid: blk_-8977171315694840933_1001, duration: 2459481
2011-08-09 19:43:50,812 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_-8977171315694840933_1001 terminating
2011-08-09 19:43:50,813 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:38614 is added to blk_-8977171315694840933_1001 size 2048
2011-08-09 19:43:50,814 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:59117 is added to blk_-8977171315694840933_1001 size 2048
2011-08-09 19:43:50,816 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-150613625
2011-08-09 19:43:50,820 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=open	src=/test/hadoop/file	dst=null	perm=null
2011-08-09 19:43:50,821 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:50,824 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-8977171315694840933 is added to invalidSet of 127.0.0.1:38614
2011-08-09 19:43:50,824 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_-8977171315694840933 is added to invalidSet of 127.0.0.1:59117
2011-08-09 19:43:50,826 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:50,827 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:50,828 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47858
2011-08-09 19:43:50,828 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47858: exiting
2011-08-09 19:43:50,829 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47858: exiting
2011-08-09 19:43:50,829 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47858: exiting
2011-08-09 19:43:50,829 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47858
2011-08-09 19:43:50,829 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:50,829 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:50,830 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:59117, storageID=DS-2044945012-10.0.62.238-59117-1312911830718, infoPort=44190, ipcPort=47858):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:51,780 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:51,830 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:51,831 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:59117, storageID=DS-2044945012-10.0.62.238-59117-1312911830718, infoPort=44190, ipcPort=47858):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:51,832 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47858
2011-08-09 19:43:51,832 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:51,833 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:51,833 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:51,834 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:51,835 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:51,836 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33243
2011-08-09 19:43:51,836 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 33243: exiting
2011-08-09 19:43:51,837 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 33243: exiting
2011-08-09 19:43:51,837 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 33243: exiting
2011-08-09 19:43:51,838 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 33243
2011-08-09 19:43:51,839 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:51,839 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:38614, storageID=DS-1892658419-10.0.62.238-38614-1312911830321, infoPort=33900, ipcPort=33243):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:51,839 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:52,381 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:52,839 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:52,839 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:38614, storageID=DS-1892658419-10.0.62.238-38614-1312911830321, infoPort=33900, ipcPort=33243):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:52,840 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 33243
2011-08-09 19:43:52,840 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:52,841 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:52,841 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:52,842 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:52,843 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:52,941 INFO  hdfs.StateChange (FSNamesystem.java:invalidateWorkForOneNode(3486)) - BLOCK* ask 127.0.0.1:38614 to delete  blk_-8977171315694840933_1001
2011-08-09 19:43:52,944 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:52,945 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:52,945 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:10  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:4 
2011-08-09 19:43:52,948 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 44768
2011-08-09 19:43:52,948 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 44768: exiting
2011-08-09 19:43:52,948 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 44768: exiting
2011-08-09 19:43:52,948 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 44768: exiting
2011-08-09 19:43:52,949 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 44768: exiting
2011-08-09 19:43:52,949 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 44768: exiting
2011-08-09 19:43:52,949 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 44768: exiting
2011-08-09 19:43:52,949 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 44768: exiting
2011-08-09 19:43:52,949 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 44768: exiting
2011-08-09 19:43:52,950 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 44768: exiting
2011-08-09 19:43:52,950 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 44768: exiting
2011-08-09 19:43:52,951 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 44768
2011-08-09 19:43:52,951 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:52,964 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:52,964 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:52,964 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:52,964 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:52,972 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:52,973 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:52,973 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:52,973 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:52,982 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:52,982 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:52,994 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1 has been successfully formatted.
2011-08-09 19:43:52,997 INFO  common.Storage (FSImage.java:saveFSImage(1268)) - Image file of size 95 saved in 0 seconds.
2011-08-09 19:43:52,997 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:53,008 INFO  common.Storage (FSImage.java:format(1394)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2 has been successfully formatted.
2011-08-09 19:43:53,009 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=NameNode, sessionId=null - already initialized
2011-08-09 19:43:53,012 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(145)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:53,012 INFO  util.GSet (BlocksMap.java:computeCapacity(342)) - VM type       = 64-bit
2011-08-09 19:43:53,012 INFO  util.GSet (BlocksMap.java:computeCapacity(343)) - 2% max memory = 9.89875 MB
2011-08-09 19:43:53,012 INFO  util.GSet (BlocksMap.java:computeCapacity(344)) - capacity      = 2^20 = 1048576 entries
2011-08-09 19:43:53,012 INFO  util.GSet (LightWeightGSet.java:<init>(79)) - recommended=1048576, actual=1048576
2011-08-09 19:43:53,040 WARN  namenode.FSNamesystem (ConfigManager.java:<init>(56)) - No whitelist file specified in dfs.namenode.whitelist.file. The namenode will allow deletion/renaming of any directory.
2011-08-09 19:43:53,040 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(521)) - fsOwner=jeff,jeff
2011-08-09 19:43:53,040 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(527)) - supergroup=supergroup
2011-08-09 19:43:53,040 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(528)) - isPermissionEnabled=true
2011-08-09 19:43:53,044 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(71)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
2011-08-09 19:43:53,044 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5940)) - Registered FSNamesystemStatusMBean
2011-08-09 19:43:53,044 INFO  namenode.NameNode (FSDirectory.java:<init>(126)) - Caching file names occuring more than 10 times 
2011-08-09 19:43:53,048 INFO  common.Storage (FSImage.java:loadFSImage(1034)) - Number of files = 1
2011-08-09 19:43:53,048 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1499)) - Number of files under construction = 0
2011-08-09 19:43:53,049 INFO  common.Storage (FSImage.java:loadFSImage(1144)) - Image file of size 95 loaded in 0 seconds.
2011-08-09 19:43:53,049 INFO  common.Storage (FSEditLog.java:loadFSEdits(886)) - Edits file /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
2011-08-09 19:43:53,049 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:53,050 INFO  namenode.FSNamesystem (FSEditLog.java:<init>(157)) - Edit Log preallocate size for /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits is 1048576 bytes  and initial size of edits buffer is 524288 bytes. Max number of buffered transactions is 10000
2011-08-09 19:43:53,050 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2011-08-09 19:43:53,050 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(372)) - Finished loading FSImage in 11 msecs
2011-08-09 19:43:53,218 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(5294)) - initializing replication queues
2011-08-09 19:43:53,222 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4047)) - Total number of blocks = 0
2011-08-09 19:43:53,223 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4048)) - Number of invalid blocks = 0
2011-08-09 19:43:53,223 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4049)) - Number of under-replicated blocks = 0
2011-08-09 19:43:53,223 INFO  namenode.FSNamesystem (FSNamesystem.java:processMisReplicatedBlocks(4050)) - Number of  over-replicated blocks = 0
2011-08-09 19:43:53,223 INFO  hdfs.StateChange (FSNamesystem.java:leave(5269)) - STATE* Leaving safe mode after 0 secs.
2011-08-09 19:43:53,225 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:53,227 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=NameNode, port=47914
2011-08-09 19:43:53,228 INFO  namenode.NameNode (NameNode.java:startServerForClientRequests(396)) - Namenode up at: localhost/127.0.0.1:47914
2011-08-09 19:43:53,228 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:53,228 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 47914: starting
2011-08-09 19:43:53,229 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 47914: starting
2011-08-09 19:43:53,229 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 47914: starting
2011-08-09 19:43:53,229 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 47914: starting
2011-08-09 19:43:53,230 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 3 on 47914: starting
2011-08-09 19:43:53,230 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 4 on 47914: starting
2011-08-09 19:43:53,230 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 5 on 47914: starting
2011-08-09 19:43:53,230 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 6 on 47914: starting
2011-08-09 19:43:53,230 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 7 on 47914: starting
2011-08-09 19:43:53,231 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 8 on 47914: starting
2011-08-09 19:43:53,231 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 9 on 47914: starting
2011-08-09 19:43:53,261 WARN  fs.Trash (Trash.java:<init>(232)) - The configured interval for checkpoint is 0 minutes. Using interval of 0 minutes that is used for deletion instead
2011-08-09 19:43:53,262 INFO  hdfs.StateChange (FSNamesystem.java:leave(5283)) - STATE* Network topology has 0 racks and 0 datanodes
2011-08-09 19:43:53,262 INFO  hdfs.StateChange (FSNamesystem.java:leave(5286)) - STATE* UnderReplicatedBlocks has 0 blocks
2011-08-09 19:43:53,262 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(388)) - Skip counting items in the file tree
2011-08-09 19:43:53,263 INFO  util.HostsFileReader (HostsFileReader.java:refresh(80)) - Refreshing hosts (include/exclude) list
2011-08-09 19:43:53,265 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:53,265 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:53,265 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 43360 webServer.getConnectors()[0].getLocalPort() returned 43360
2011-08-09 19:43:53,265 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 43360
2011-08-09 19:43:53,266 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:53,310 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:43360
2011-08-09 19:43:53,310 INFO  namenode.NameNode (NameNode.java:startHttpServer(329)) - Web-server up at: localhost:43360
Starting DataNode 0 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2
2011-08-09 19:43:53,317 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1 is not formatted.
2011-08-09 19:43:53,317 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:53,334 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2 is not formatted.
2011-08-09 19:43:53,335 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:53,533 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:53,534 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 42752
2011-08-09 19:43:53,534 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:53,537 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:53,537 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:53,537 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 42027 webServer.getConnectors()[0].getLocalPort() returned 42027
2011-08-09 19:43:53,538 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 42027
2011-08-09 19:43:53,538 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:53,612 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:42027
2011-08-09 19:43:53,613 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:53,619 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:53,633 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=34528
2011-08-09 19:43:53,634 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:53,635 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 34528: starting
2011-08-09 19:43:53,646 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 34528: starting
2011-08-09 19:43:53,647 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 34528: starting
2011-08-09 19:43:53,647 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:42752, storageID=, infoPort=42027, ipcPort=34528)
2011-08-09 19:43:53,648 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 34528: starting
2011-08-09 19:43:53,652 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:42752 storage DS-1818294384-10.0.62.238-42752-1312911833650
2011-08-09 19:43:53,653 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:42752
2011-08-09 19:43:53,659 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1818294384-10.0.62.238-42752-1312911833650 is assigned to data-node 127.0.0.1:42752
Starting DataNode 1 with dfs.data.dir: /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4
2011-08-09 19:43:53,660 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:42752, storageID=DS-1818294384-10.0.62.238-42752-1312911833650, infoPort=42027, ipcPort=34528)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:53,661 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:53,668 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3 is not formatted.
2011-08-09 19:43:53,668 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:53,668 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:53,670 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:42752 0 blocks shortCircuit first report.
2011-08-09 19:43:53,671 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 3 msecs
2011-08-09 19:43:53,671 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:53,674 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:53,685 INFO  common.Storage (DataStorage.java:recoverTransitionRead(124)) - Storage directory /home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4 is not formatted.
2011-08-09 19:43:53,685 INFO  common.Storage (DataStorage.java:recoverTransitionRead(125)) - Formatting ...
2011-08-09 19:43:53,910 INFO  datanode.DataNode (FSDataset.java:registerMBean(1597)) - Registered FSDatasetStatusMBean
2011-08-09 19:43:53,911 INFO  datanode.DataNode (DataNode.java:startDataNode(327)) - Opened info server at 37038
2011-08-09 19:43:53,911 INFO  datanode.DataNode (DataXceiverServer.java:<init>(75)) - Balancing bandwith is 1048576 bytes/s
2011-08-09 19:43:53,914 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(297)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2011-08-09 19:43:53,914 INFO  http.HttpServer (HttpServer.java:start(437)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
2011-08-09 19:43:53,915 INFO  http.HttpServer (HttpServer.java:start(442)) - listener.getLocalPort() returned 40575 webServer.getConnectors()[0].getLocalPort() returned 40575
2011-08-09 19:43:53,915 INFO  http.HttpServer (HttpServer.java:start(475)) - Jetty bound to port 40575
2011-08-09 19:43:53,915 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2011-08-09 19:43:53,981 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started SelectChannelConnector@localhost:40575
2011-08-09 19:43:53,981 INFO  jvm.JvmMetrics (JvmMetrics.java:init(66)) - Cannot initialize JVM Metrics with processName=DataNode, sessionId=null - already initialized
2011-08-09 19:43:53,986 INFO  ipc.Server (Server.java:run(307)) - Starting SocketReader
2011-08-09 19:43:53,988 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(59)) - Initializing RPC Metrics with hostName=DataNode, port=36766
2011-08-09 19:43:53,989 INFO  ipc.Server (Server.java:run(581)) - IPC Server Responder: starting
2011-08-09 19:43:53,990 INFO  ipc.Server (Server.java:run(408)) - IPC Server listener on 36766: starting
2011-08-09 19:43:53,990 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 0 on 36766: starting
2011-08-09 19:43:53,990 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 1 on 36766: starting
2011-08-09 19:43:53,991 INFO  datanode.DataNode (DataNode.java:startDataNode(418)) - dnRegistration = DatanodeRegistration(m3vm6.tuenti.local:37038, storageID=, infoPort=40575, ipcPort=36766)
2011-08-09 19:43:53,991 INFO  ipc.Server (Server.java:run(1044)) - IPC Server handler 2 on 36766: starting
2011-08-09 19:43:53,997 INFO  hdfs.StateChange (FSNamesystem.java:registerDatanode(2757)) - BLOCK* NameSystem.registerDatanode: node registration from 127.0.0.1:37038 storage DS-1025594134-10.0.62.238-37038-1312911833994
2011-08-09 19:43:53,997 INFO  net.NetworkTopology (NetworkTopology.java:add(328)) - Adding a new node: /default-rack/127.0.0.1:37038
2011-08-09 19:43:54,003 INFO  datanode.DataNode (DataNode.java:register(592)) - New storage id DS-1025594134-10.0.62.238-37038-1312911833994 is assigned to data-node 127.0.0.1:37038
2011-08-09 19:43:54,005 INFO  datanode.DataNode (DataNode.java:run(1274)) - DatanodeRegistration(127.0.0.1:37038, storageID=DS-1025594134-10.0.62.238-37038-1312911833994, infoPort=40575, ipcPort=36766)In DataNode.run, data = FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:54,006 INFO  datanode.DataNode (DataNode.java:offerService(756)) - using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2011-08-09 19:43:54,011 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:54,013 INFO  hdfs.StateChange (FSNamesystem.java:processReport(3701)) - BLOCK* NameSystem.processReport: from 127.0.0.1:37038 0 blocks shortCircuit first report.
2011-08-09 19:43:54,014 INFO  datanode.DataNode (DataNode.java:offerService(839)) - BlockReport of 0 blocks got processed in 4 msecs
2011-08-09 19:43:54,014 INFO  datanode.DataNode (DataNode.java:offerService(864)) - Starting Periodic block scanner.
2011-08-09 19:43:54,051 INFO  datanode.DataNode (FSDataset.java:getBlockInfo(601)) - Finished generating block report for 2 volumes in 0 seconds
2011-08-09 19:43:54,063 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file	dst=null	perm=jeff:supergroup:rw-r--r--
2011-08-09 19:43:54,069 INFO  hdfs.StateChange (FSNamesystem.java:allocateBlock(1930)) - BLOCK* NameSystem.allocateBlock: /test/hadoop/file. blk_7724838595181513742_1001
2011-08-09 19:43:54,071 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_7724838595181513742_1001 src: /127.0.0.1:40857 dest: /127.0.0.1:42752
2011-08-09 19:43:54,074 INFO  datanode.DataNode (DataXceiver.java:writeBlock(254)) - Receiving block blk_7724838595181513742_1001 src: /127.0.0.1:52903 dest: /127.0.0.1:37038
2011-08-09 19:43:54,080 INFO  DataNode.clienttrace (BlockReceiver.java:lastDataNodeRun(820)) - src: /127.0.0.1:52903, dest: /127.0.0.1:37038, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_-406305591, offset: 0, srvID: DS-1025594134-10.0.62.238-37038-1312911833994, blockid: blk_7724838595181513742_1001, duration: 1917339
2011-08-09 19:43:54,082 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:37038 is added to blk_7724838595181513742_1001 size 2
2011-08-09 19:43:54,082 INFO  DataNode.clienttrace (BlockReceiver.java:run(953)) - src: /127.0.0.1:40857, dest: /127.0.0.1:42752, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_-406305591, offset: 0, srvID: DS-1818294384-10.0.62.238-42752-1312911833650, blockid: blk_7724838595181513742_1001, duration: 4925389
2011-08-09 19:43:54,083 INFO  hdfs.StateChange (FSNamesystem.java:addStoredBlock(3893)) - BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:42752 is added to blk_7724838595181513742_1001 size 2
2011-08-09 19:43:54,084 INFO  datanode.DataNode (BlockReceiver.java:run(1023)) - PacketResponder 1 for block blk_7724838595181513742_1001 terminating
2011-08-09 19:43:54,093 INFO  datanode.DataNode (BlockReceiver.java:lastDataNodeRun(851)) - PacketResponder 0 for block blk_7724838595181513742_1001 terminating
2011-08-09 19:43:54,095 INFO  hdfs.StateChange (FSNamesystem.java:completeFileInternal(1886)) - DIR* NameSystem.completeFile: file /test/hadoop/file is closed by DFSClient_-406305591
2011-08-09 19:43:54,097 WARN  hdfs.DFSClient (DFSClient.java:deleteUsingTrash(323)) - File /test is being deleted only through Trash org.apache.hadoop.fs.FsShell.delete because all deletes must go through Trash.
2011-08-09 19:43:54,100 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_7724838595181513742 is added to invalidSet of 127.0.0.1:37038
2011-08-09 19:43:54,100 INFO  hdfs.StateChange (FSNamesystem.java:addToInvalidates(1995)) - BLOCK* NameSystem.addToInvalidates: blk_7724838595181513742 is added to invalidSet of 127.0.0.1:42752
2011-08-09 19:43:54,102 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditEvent(136)) - ugi=jeff,jeff	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null
Deleted /test
Shutting down the Mini HDFS Cluster
Shutting down DataNode 1
2011-08-09 19:43:54,103 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:54,104 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36766
2011-08-09 19:43:54,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 36766: exiting
2011-08-09 19:43:54,104 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 36766
2011-08-09 19:43:54,104 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 36766: exiting
2011-08-09 19:43:54,105 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 36766: exiting
2011-08-09 19:43:54,106 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:37038, storageID=DS-1025594134-10.0.62.238-37038-1312911833994, infoPort=40575, ipcPort=36766):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:54,105 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:54,105 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:54,107 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:54,107 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:37038, storageID=DS-1025594134-10.0.62.238-37038-1312911833994, infoPort=40575, ipcPort=36766):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data3/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data4/current'}
2011-08-09 19:43:54,108 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 36766
2011-08-09 19:43:54,108 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:54,109 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:54,109 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:54,110 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
Shutting down DataNode 0
2011-08-09 19:43:54,111 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:54,212 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34528
2011-08-09 19:43:54,212 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 34528: exiting
2011-08-09 19:43:54,213 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 34528: exiting
2011-08-09 19:43:54,213 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 34528: exiting
2011-08-09 19:43:54,213 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 34528
2011-08-09 19:43:54,214 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 1
2011-08-09 19:43:54,214 WARN  datanode.DataNode (DataXceiverServer.java:run(138)) - DatanodeRegistration(127.0.0.1:42752, storageID=DS-1818294384-10.0.62.238-42752-1312911833650, infoPort=42027, ipcPort=34528):DataXceiveServer: java.nio.channels.AsynchronousCloseException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:185)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:152)
	at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:84)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:131)
	at java.lang.Thread.run(Thread.java:662)

2011-08-09 19:43:54,215 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:54,675 INFO  datanode.DataBlockScanner (DataBlockScanner.java:run(604)) - Exiting DataBlockScanner thread.
2011-08-09 19:43:55,215 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:55,215 INFO  datanode.DataNode (DataNode.java:run(1294)) - DatanodeRegistration(127.0.0.1:42752, storageID=DS-1818294384-10.0.62.238-42752-1312911833650, infoPort=42027, ipcPort=34528):Finishing DataNode in: FSDataset{dirpath='/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data1/current,/home/jeff/hadoop-20-warehouse/build/test/data/dfs/data/data2/current'}
2011-08-09 19:43:55,216 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 34528
2011-08-09 19:43:55,216 INFO  datanode.DataNode (DataNode.java:shutdown(632)) - Waiting for threadgroup to exit, active threads is 0
2011-08-09 19:43:55,217 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(128)) - Shutting down all async disk service threads...
2011-08-09 19:43:55,217 INFO  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(137)) - All async disk service threads have been shut down.
2011-08-09 19:43:55,219 WARN  datanode.FSDatasetAsyncDiskService (FSDatasetAsyncDiskService.java:shutdown(125)) - AsyncDiskService has already shut down.
2011-08-09 19:43:55,274 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped SelectChannelConnector@localhost:0
2011-08-09 19:43:55,375 WARN  namenode.FSNamesystem (FSNamesystem.java:run(3042)) - ReplicationMonitor thread received InterruptedException.java.lang.InterruptedException: sleep interrupted
2011-08-09 19:43:55,375 INFO  namenode.DecommissionManager (DecommissionManager.java:waitForWork(254)) - Interrupted Monitor
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.waitForWork(DecommissionManager.java:244)
	at org.apache.hadoop.hdfs.server.namenode.DecommissionManager$Monitor.run(DecommissionManager.java:267)
	at java.lang.Thread.run(Thread.java:662)
2011-08-09 19:43:55,376 INFO  namenode.FSNamesystem (FSEditLog.java:printStatistics(1125)) - Number of transactions: 6 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms):  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name1/current/edits:7  /home/jeff/hadoop-20-warehouse/build/test/data/dfs/name2/current/edits:3 
2011-08-09 19:43:55,378 INFO  ipc.Server (Server.java:stop(1226)) - Stopping server on 47914
2011-08-09 19:43:55,379 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 1 on 47914: exiting
2011-08-09 19:43:55,379 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 0 on 47914: exiting
2011-08-09 19:43:55,379 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 2 on 47914: exiting
2011-08-09 19:43:55,380 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 4 on 47914: exiting
2011-08-09 19:43:55,380 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 3 on 47914: exiting
2011-08-09 19:43:55,380 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 5 on 47914: exiting
2011-08-09 19:43:55,381 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 6 on 47914: exiting
2011-08-09 19:43:55,381 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 7 on 47914: exiting
2011-08-09 19:43:55,381 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 8 on 47914: exiting
2011-08-09 19:43:55,381 INFO  ipc.Server (Server.java:run(1110)) - IPC Server handler 9 on 47914: exiting
2011-08-09 19:43:55,383 INFO  ipc.Server (Server.java:run(646)) - Stopping IPC Server Responder
2011-08-09 19:43:55,383 INFO  ipc.Server (Server.java:run(447)) - Stopping IPC Server listener on 47914
------------- ---------------- ---------------

Testcase: testWorkingDirectory took 4.567 sec
Testcase: testMkdirs took 1.946 sec
Testcase: testMkdirsFailsForSubdirectoryOfExistingFile took 2.959 sec
Testcase: testGetFileStatusThrowsExceptionForNonExistentFile took 3.212 sec
Testcase: testListStatusReturnsNullForNonExistentFile took 3.917 sec
Testcase: testListStatus took 3.5 sec
Testcase: testWriteReadAndDeleteEmptyFile took 1.429 sec
Testcase: testWriteReadAndDeleteHalfABlock took 3.642 sec
Testcase: testWriteReadAndDeleteOneBlock took 2.634 sec
Testcase: testWriteReadAndDeleteOneAndAHalfBlocks took 2.839 sec
Testcase: testWriteReadAndDeleteTwoBlocks took 2.992 sec
Testcase: testOverwrite took 2.655 sec
Testcase: testWriteInNonExistentDirectory took 2.709 sec
Testcase: testDeleteNonExistentFile took 3.676 sec
Testcase: testDeleteRecursively took 3.439 sec
Testcase: testDeleteEmptyDirectory took 2.28 sec
Testcase: testRenameNonExistentPath took 2.573 sec
Testcase: testRenameFileMoveToNonExistentDirectory took 2.221 sec
Testcase: testRenameFileMoveToExistingDirectory took 3.485 sec
Testcase: testRenameFileAsExistingFile took 3.309 sec
Testcase: testRenameFileAsExistingDirectory took 3.476 sec
Testcase: testRenameDirectoryMoveToNonExistentDirectory took 3.639 sec
Testcase: testRenameDirectoryMoveToExistingDirectory took 2.605 sec
Testcase: testRenameDirectoryAsExistingFile took 3.319 sec
Testcase: testRenameDirectoryAsExistingDirectory took 3.512 sec
Testcase: testInputStreamClosedTwice took 3.419 sec
Testcase: testOutputStreamClosedTwice took 2.431 sec
